[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis comparativo del desempeño en métodos para el pronóstico de series temporales",
    "section": "",
    "text": "Resumen\n\nEsta tesis presenta un análisis comparativo de métodos de pronóstico para datos de series temporales, centrándose en la aplicación del método Holt-Winters y de las redes neuronales Perceptrón Multicapa (MLP). El estudio abarca una revisión exhaustiva de la teoría del análisis de series temporales y los fundamentos de las redes neuronales, proporcionando una sólida base teórica para comprender las metodologías empleadas.\nLa investigación examina el desempeño del método de Holt-Winters, una técnica clásica de suavizado exponencial, y MLP, un enfoque potente de modelado no lineal, en el pronóstico del número de casos confirmados y fallecidos debido al COVID-19 en Irán. Al aplicar estos métodos a datos del mundo real, la tesis evalúa su precisión, robustez y eficiencia computacional en la captura de la compleja dinámica de la progresión de la pandemia.\nA través del análisis empírico y las evaluaciones comparativas, este estudio tiene como objetivo proporcionar información sobre las fortalezas y limitaciones de cada enfoque de pronóstico, contribuyendo así al avance de las metodologías de pronóstico para datos de series temporales, especialmente en el contexto de crisis de salud pública.",
    "crumbs": [
      "Resumen"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introducción",
    "section": "",
    "text": "La creciente disponibilidad de datos temporales en una amplia gama de campos ha impulsado la necesidad de desarrollar métodos eficaces para pronosticar su comportamiento futuro. En particular, el análisis y pronóstico de series temporales desempeña un papel crucial en la toma de decisiones en áreas como la economía, la meteorología, la ingeniería y la salud pública. Con la aparición de la pandemia de COVID-19, la capacidad de prever la evolución de la enfermedad se ha convertido en una prioridad urgente para los responsables de la salud y los planificadores de políticas.\nEste trabajo se centra en el análisis comparativo de métodos de pronóstico para series temporales, con un enfoque específico en el método de Holt-Winters y las redes neuronales Perceptrón Multicapa (MLP). Para comprender en profundidad estos enfoques, se presenta una revisión exhaustiva de la teoría del análisis de series temporales y los fundamentos de las redes neuronales, estableciendo así las bases teóricas necesarias para su aplicación.\nEl método de Holt-Winters, basado en el suavizado exponencial, y MLP, una técnica de modelado no lineal, son seleccionados como enfoques principales debido a su amplia aplicación y capacidad para capturar patrones complejos en los datos temporales. Se busca evaluar el desempeño de estos métodos en la predicción del número de casos confirmados y fallecidos por COVID-19 en Irán, utilizando datos reales recopilados durante el curso de la pandemia.\nEl estudio se estructura en torno al desarrollo de modelos de pronóstico basados en Holt-Winters y MLP, seguido de una comparación exhaustiva de su precisión, robustez y eficiencia computacional. Además, se explora el potencial de estas técnicas para proporcionar información valiosa en la gestión de crisis de salud pública y la planificación de recursos.\nEn última instancia, se espera que este trabajo contribuya al avance de las metodologías de pronóstico para datos de series temporales, ofreciendo perspectivas significativas para la mejora de la capacidad predictiva en situaciones críticas como la pandemia de COVID-19.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "objetivos.html",
    "href": "objetivos.html",
    "title": "Objetivos",
    "section": "",
    "text": "Objetivo General",
    "crumbs": [
      "Objetivos"
    ]
  },
  {
    "objectID": "objetivos.html#objetivo-general",
    "href": "objetivos.html#objetivo-general",
    "title": "Objetivos",
    "section": "",
    "text": "El objetivo principal de este estudio es comparar el método de pronóstico Holt-Winters con el pronóstico realizado mediante una red MLP (Perceptrón Multicapa), utilizando métricas de error relevantes para evaluar su desempeño.",
    "crumbs": [
      "Objetivos"
    ]
  },
  {
    "objectID": "objetivos.html#objetivos-específicos",
    "href": "objetivos.html#objetivos-específicos",
    "title": "Objetivos",
    "section": "Objetivos Específicos",
    "text": "Objetivos Específicos\n\n\nIdentificar y comprender las técnicas de pronóstico, incluyendo el suavizado exponencial y el aprendizaje profundo mediante una red MLP.\nEvaluar y contrastar la eficacia de las implementaciones de Holt-Winters y la red MLP en los lenguajes de programación Python y R. Este análisis incluirá la identificación de ventajas y desventajas asociadas con cada implementación.\nReconocer y abordar las dificultades inherentes al pronóstico de datos epidemiológicos iniciales, particularmente en el contexto de una pandemia causada por un virus de propagación vectorial, como es el caso del COVID-19, que inicialmente es prácticamente desconocido.",
    "crumbs": [
      "Objetivos"
    ]
  },
  {
    "objectID": "tconjuntos.html",
    "href": "tconjuntos.html",
    "title": "1  Teoría de conjuntos",
    "section": "",
    "text": "En esta sección, se abordan algunas de las ideas y conceptos elementales de la teoría de conjuntos que son necesarios para una introducción moderna a la teoría de la probabilidad.\nConsidere una colección de objetos en la que cada objeto se denomina punto o elemento. Se asume que dicha colección de objetos es lo suficientemente amplia como para incluir todos los puntos considerados en una discusión específica. La totalidad de estos puntos se conoce como espacio, universo o conjunto universal.\n\\(\\Omega = \\mathbb{R}^2\\), donde \\(\\mathbb{R}^2\\) es la colección de puntos \\(\\omega\\) en el plano y \\(\\omega=(x,y)\\) es cualquier par de números reales \\(x\\) e \\(y\\).\nPor lo general, se utilizarán letras latinas mayúsculas al comienzo del alfabeto, con o sin subíndices, para denotar conjuntos. Si \\(\\omega\\) es un punto o elemento que pertenece al conjunto \\(A\\), se escribirá \\(\\omega \\in A\\); si \\(\\omega\\) no es un elemento de \\(A\\), se escribirá \\(\\omega \\notin A\\).\n\n\nDefinición 1.1 (Subconjunto) Si cada elemento de un conjunto \\(A\\) también es un elemento de un conjunto \\(B\\), entonces se define que \\(A\\) es un subconjunto de \\(B\\), y se escribirá \\(A\\subset B\\) o \\(B\\supset A\\); se lee como “\\(A\\) está contenido en \\(B\\)” o “\\(B\\) contiene a \\(A\\)”.\n\n\nDefinición 1.2 (Conjuntos equivalentes) Dos conjuntos \\(A\\) y \\(B\\) se definen como equivalentes, o iguales, si \\(A\\subset B\\) y \\(B\\subset A\\). Esto se indicará escribiendo \\(A=B\\).\n\n\nDefinición 1.3 (Conjunto vacío) Si un conjunto \\(A\\) no contiene puntos, se le llamará conjunto nulo o conjunto vacío, y se denotará por \\(\\emptyset\\).\n\n\nDefinición 1.4 (Complemento) El complemento de un conjunto \\(A\\) con respecto al espacio \\(\\Omega\\), denotado por \\(\\overline{A}\\), \\(A^c\\) o \\(\\Omega-A\\), es el conjunto de todos los puntos que están en \\(\\Omega\\) pero no en \\(A\\).\n\n\nDefinición 1.5 (Unión) Sea \\(A\\) y \\(B\\) dos subconjuntos cualesquiera de \\(\\Omega\\); entonces el conjunto que consiste en todos los puntos que están en \\(A\\), en \\(B\\) o en ambos se define como la unión de \\(A\\) y \\(B\\), y se escribe \\(A \\cup B\\).\n\n\nDefinición 1.6 (Intersección) Sean \\(A\\) y \\(B\\) dos subconjuntos cualesquiera de \\(\\Omega\\); entonces el conjunto formado por todos los puntos que están tanto en \\(A\\) como en \\(B\\) se define como la intersección de \\(A\\) y \\(B\\), y se escribe \\(A \\cap B\\).\n\n\nDefinición 1.7 (Diferencia de conjuntos) Sean \\(A\\) y \\(B\\) dos subconjuntos cualesquiera de \\(\\Omega\\). El conjunto de todos los puntos en \\(A\\) que no están en \\(B\\) se denotará por \\(A-B\\) y se define como la diferencia de conjuntos.\n\n\nLas operaciones de complemento, unión e intersección de conjuntos se han introducido en las definiciones Definición 1.4 a Definición 1.6, respectivamente. Estas operaciones de conjuntos satisfacen varias leyes, que a continuación se sintetizan. (Ash y Doleans-Dade 2000)\n\n\nTeorema 1.1 (Leyes del álgebra de conjuntos)  \n\nLeyes de idempotencia \\[\\begin{split}A\\cup A &= A \\\\A\\cap A &=A\\end{split}\\]\nLeyes asociativas \\[\\begin{split}           (A\\cup B)\\cup C &= A \\cup (B\\cup C)\\\\ (A\\cap B)\\cap C &= A\\cap (B \\cap C)\\end{split}\\]\nLeyes conmutativas \\[\\begin{split}            A\\cup B &= B\\cup A\\\\            A\\cap B &= B \\cap A        \\end{split}\\]\nLeyes distributivas \\[\\begin{split}            A\\cup (B\\cap C) &= (A\\cup B)\\cap (A\\cup C)\\\\            A\\cap (B\\cup C) &= (A\\cap B)\\cup (A\\cap C)        \\end{split} \\]\nLeyes de identidad \\[\\begin{split}            A\\cup \\emptyset &= A\\\\            A\\cap \\Omega &= A\\\\            A\\cup \\Omega &= \\Omega\\\\            A\\cap \\emptyset &= \\emptyset        \\end{split} \\]\nLeyes de complemento \\[\\begin{split}            A\\cup A^c &= \\Omega\\\\            A\\cap A^c &= \\emptyset\\\\            (A^c)^c &= A\\\\            \\Omega^c&=\\emptyset\\\\            \\emptyset^c&= \\Omega        \\end{split} \\]\nLeyes de De Morgan \\[\\begin{split}            (A\\cup B)^c &=A^c \\cap B^c\\\\            (A\\cap B)^c &=A^c \\cup B^c        \\end{split} \\]\n\n\n\n\n\n\n\n\nFigura 1.1: Diagramas de Venn\n\n\n\n\nAlgunas de las leyes mencionadas anteriormente se ilustran en los diagramas de Venn en la Figura 1.1. Aunque se utilizará libremente cualquiera de las leyes mencionadas, podría resultar instructivo proporcionar una prueba de una de ellas para ilustrar la técnica. Se considera el siguiente ejemplo:\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\nDemostrar que \\((A \\cup B)^c = A^c \\cap B^c\\).\n\nPrueba. Según la definición, dos conjuntos son iguales si cada uno está contenido en el otro. Primero se demuestra que \\((A\\cup B)^c \\subset A^c\\cap B^c\\) al probar que si \\(\\omega \\in (A\\cup B)^c\\), entonces \\(\\omega \\in A^c \\cap B^c\\). Ahora bien, \\(\\omega \\in (A\\cup B)^c\\) implica que \\(\\omega \\notin A \\cup B\\), lo cual implica que \\(\\omega \\notin A\\) y \\(\\omega \\notin B\\), lo que a su vez implica que \\(\\omega \\in A^c\\) y \\(\\omega \\in B^c\\); es decir, \\(\\omega \\in A^c\\cap B^c\\). A continuación se demuestra que \\(A^c \\cap B^c \\subset (A\\cup B)^c\\). Sea \\(\\omega \\in A^c \\cap B^c\\), lo que significa que \\(\\omega\\) pertenece tanto a \\(A^c\\) como a \\(B^c\\). Entonces, \\(\\omega \\notin A \\cup B\\), ya que de lo contrario \\(\\omega\\) debería pertenecer al menos a uno de los conjuntos \\(A\\) o \\(B\\), lo cual contradice que \\(\\omega\\) pertenezca tanto a \\(A^c\\) como a \\(B^c\\); sin embargo, \\(\\omega \\notin A \\cup B\\) implica que \\(\\omega \\in (A\\cup B)^c\\), lo que completa la prueba.\n\n\n\n\n\nSe han introducido la unión y la intersección de dos conjuntos; estas definiciones se extienden inmediatamente a más de dos conjuntos, de hecho, a un número arbitrario de conjuntos. Es costumbre distinguir entre los conjuntos en una colección de subconjuntos de \\(\\Omega\\) asignándoles nombres en forma de subíndices.\nSe considera el conjunto de índices \\(\\Lambda\\) como el catálogo de nombres o índices. A \\(\\Lambda\\) también se le denomina conjunto de índices. Por ejemplo, si se tiene interés únicamente en dos conjuntos, entonces el conjunto de índices \\(\\Lambda\\) incluye solo dos índices, por ejemplo, 1 y 2; así, \\(\\Lambda=\\{1,2\\}\\).\n\n\nDefinición 1.8 (Unión e intersección de conjuntos) Sea \\(\\Lambda\\) un conjunto de índices y \\(\\{A_\\lambda: \\lambda \\in \\Lambda\\}= \\{A_\\lambda\\}\\), una colección de subconjuntos de \\(\\Omega\\) indexados por \\(\\Lambda\\). El conjunto de puntos que consiste en todos los puntos que pertenecen a \\(A_\\lambda\\) para al menos un \\(\\lambda\\) se denomina unión de los conjuntos \\(\\{A_\\lambda\\}\\) y se denota como \\(\\bigcup\\limits_{\\lambda\\in \\Lambda} A_\\lambda\\). El conjunto de puntos que consiste en todos los puntos que pertenecen a \\(A_\\lambda\\) para cada \\(\\lambda\\) se denomina intersección de los conjuntos \\(\\{A_\\lambda\\}\\) y se denota como \\(\\bigcap\\limits_{\\lambda\\in\\Lambda} A_\\lambda\\). Si \\(\\Lambda\\) está vacío, entonces se define \\(\\bigcup\\limits_{\\lambda\\in \\Lambda} A_\\lambda = \\emptyset\\) y \\(\\bigcap\\limits_{\\lambda\\in\\Lambda} A_\\lambda=\\Omega\\).\n\n\nUno de los teoremas más fundamentales que relaciona las uniones, intersecciones y complementos para una colección arbitraria de conjuntos se debe a De Morgan.\n\n\nTeorema 1.2 (Teorema de De Morgan) Sea \\(\\Lambda\\) un conjunto de índices y \\(\\{A_\\lambda\\}\\) una colección de subconjuntos de \\(\\Omega\\) indexados por \\(\\Lambda\\). Entonces,\n\n\\(\\left(\\bigcup\\limits_{\\lambda\\in\\Lambda} A_\\lambda\\right)^c = \\bigcap\\limits_{\\lambda\\in\\Lambda} A_\\lambda^c\\)\n\\(\\left(\\bigcap\\limits_{\\lambda\\in\\Lambda} A_\\lambda\\right)^c = \\bigcup\\limits_{\\lambda\\in\\Lambda} A_\\lambda^c\\)\n\n\n\nDefinición 1.9 (Disjuntos o mutuamente excluyentes) Los subconjuntos \\(A\\) y \\(B\\) de \\(\\Omega\\) se definen como mutuamente excluyentes o disjuntos si \\(A\\cap B=\\emptyset\\). Los subconjuntos \\(A_1, A_2, \\ldots\\) se definen como mutuamente excluyentes si \\(A_i\\cap A_j=\\emptyset\\) para cada \\(i\\neq j\\).\n\n\n\n\n\nAsh, R. B., y C. A. Doleans-Dade. 2000. Probability and Measure Theory. Elsevier Science. https://books.google.com.mx/books?id=GkqQoRpCO2QC.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Teoría de conjuntos</span>"
    ]
  },
  {
    "objectID": "probabilidad.html",
    "href": "probabilidad.html",
    "title": "2  Probabilidad",
    "section": "",
    "text": "2.1 Espacio muestral y eventos",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#espacio-muestral-y-eventos",
    "href": "probabilidad.html#espacio-muestral-y-eventos",
    "title": "2  Probabilidad",
    "section": "",
    "text": "A continuación, se presentarán algunas definiciones que resultarán de gran utilidad para adquirir un mayor conocimiento sobre el concepto de probabilidad. Se usará como referencia (Lipschutz 1996).\n\n\nDefinición 2.3 (Espacio muestral) El espacio muestral, denotado por \\(\\Omega\\), es la colección o totalidad de todos los posibles resultados de un experimento conceptual.\n\n\nUn resultado particular, es decir, un elemento del espacio muestral \\(\\Omega\\), se denomina un punto muestral o una muestra.\n\n\nDefinición 2.4 (Evento) Un evento \\(A\\) es un subconjunto del espacio muestral \\(\\Omega\\), es decir, es un conjunto de resultados.\n\n\nDefinición 2.5 (Espacio de eventos) La clase de todos los eventos asociados a un experimento dado se define como el espacio de eventos y se denotará por \\(\\mathfrak{F}\\).\n\n\nDefinición 2.6 (Evento particular) El evento \\(\\{\\omega\\}\\), que está constituido por un solo punto \\(\\omega \\in \\Omega\\), se denomina evento muestral o punto muestral.\n\n\nLas definiciones anteriores no definen con precisión lo que es un evento. Un evento siempre será un subconjunto del espacio muestral, pero para espacios muestrales suficientemente grandes, no todos los subconjuntos serán eventos. Por lo tanto, la clase de todos los subconjuntos del espacio muestral no necesariamente corresponderá al espacio de eventos. Sin embargo, se observará que la clase de todos los eventos siempre se puede seleccionar lo suficientemente grande como para incluir todos aquellos subconjuntos (eventos) cuya probabilidad se desee analizar. Si el espacio muestral consta solo de un número finito de puntos, entonces el espacio de eventos correspondiente será la clase de todos los subconjuntos del espacio muestral.\nLos conceptos presentados se ilustran con unos ejemplos muy simples;\n\n\n\n\n\n\n\nEjemplo (Lanzamiento de una moneda)\n\n\n\n\n\nConsiderando el experimento de lanzar una moneda, este experimento es uno de los más sencillos, pero permite representar claramente los conceptos. El espacio muestral estaría conformado por \\(\\Omega = \\{A, S\\}\\), donde \\(A\\) representa el resultado de que caiga águila y \\(S\\) representa el resultado de que caiga sol. El conjunto \\(\\mathfrak{F}\\) podría estar representado por \\(\\{\\{A\\}, \\{S\\}\\}\\), que también es un subconjunto de \\(\\Omega\\).\nEs importante destacar que el conjunto vacío \\(\\emptyset\\) y el conjunto completo \\(\\Omega\\) también son subconjuntos de \\(\\Omega\\), pero generalmente no se consideran eventos de interés en este contexto.\n\n\n\n\n\n\n\n\n\nEjemplo (Lanzamiento de un dado)\n\n\n\n\n\nConsiderando el experimento de lanzar un dado de \\(6\\) caras. El espacio muestral \\(\\Omega\\) se define como\n\\[ \\Omega = \\{1,2,3,4,5,6\\}. \\]\nUn punto muestral podría ser un resultado específico, por ejemplo, \\(\\{1\\}\\). Todos los subconjuntos posibles de resultados constituirían el conjunto \\(\\mathfrak{F}\\). Se definen los eventos \\(A\\), que representa el evento de obtener un resultado par; \\(B\\), que representa el evento de obtener un resultado impar; y \\(C\\), que representa el evento de obtener un resultado mayor a 3. Por lo tanto, se tiene:\n\\[ A= \\{2,4,6\\},\\quad B=\\{1,3,5\\},\\quad C=\\{4,5,6\\}. \\]\nSe observa que el evento de la unión de los eventos \\(B\\) y \\(C\\), denotado como \\(B\\cup C\\), es igual a \\(\\{1, 3, 4, 5, 6\\}\\), el cual también es un evento en el espacio muestral \\(\\Omega\\). Finalmente, se destaca que los eventos \\(A\\) y \\(B\\) no tienen elementos en común, es decir, \\(A \\cap B = \\emptyset\\). Por lo tanto, se dice que estos eventos son ajenos, mutuamente excluyentes o disjuntos.\n\n\n\n\nLa definición de espacio muestral es precisa y satisfactoria, mientras que las definiciones de evento y espacio de eventos no son completamente satisfactorias. Se mencionó que si el espacio muestral era “suficientemente grande”, no todos los subconjuntos del espacio muestral serían eventos; sin embargo, no se especificó exactamente qué subconjuntos serían eventos y cuáles no lo serían. En lugar de desarrollar las matemáticas necesarias para definir con precisión qué subconjuntos de \\(\\Omega\\) constituyen nuestro espacio de eventos \\(\\mathfrak{F}\\), se pueden enunciar algunas propiedades de \\(\\mathfrak{F}\\) que parecen razonables requerir.\n\n\\(\\Omega \\in \\mathfrak{F}\\).\nSi \\(A\\in\\mathfrak{F}\\), entonces \\(A^c\\in \\mathfrak{F}\\).\nSi \\(A_1\\) y \\(A_2\\in \\mathfrak{F}\\), entonces \\(A_1\\cup A_2\\in \\mathfrak{F}\\).\n\nSe mencionó anteriormente que el interés principal radica en los eventos debido a la probabilidad de que ocurran. Por lo tanto, es deseable que \\(\\mathfrak{F}\\) incluya \\(\\Omega\\), el evento seguro. Además, si \\(A\\) es un evento, lo que significa que se puede hablar sobre la probabilidad de que ocurra \\(A\\), entonces \\(A^c\\) también debería ser un evento para poder hablar sobre la probabilidad de que \\(A\\) no ocurra. De manera similar, si \\(A_1\\) y \\(A_2\\) son eventos, entonces \\(A_1\\cup A_2\\) también debería ser un evento.\nCualquier colección de eventos con propiedades (i.) y (iii.) se denomina álgebra booleana, o simplemente álgebra, de eventos. Cabe señalar que la colección de todos los subconjuntos de \\(\\Omega\\) satisface necesariamente las propiedades mencionadas anteriormente. Varios resultados se derivan de las propiedades asumidas anteriormente de \\(\\mathfrak{F}\\).",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#definición-de-probabilidad",
    "href": "probabilidad.html#definición-de-probabilidad",
    "title": "2  Probabilidad",
    "section": "2.2 Definición de probabilidad",
    "text": "2.2 Definición de probabilidad\n\nEn esta sección se presenta la definición axiomática de probabilidad. Aunque esta definición formal de probabilidad por sí sola no permite asignar probabilidades reales a eventos que consisten en ciertos resultados de experimentos aleatorios, es otra de una serie de definiciones que conducen a ese objetivo. Dado que la probabilidad, al igual que los conceptos que se presentarán, se define como una función particular, se inicia esta subsección con una revisión del concepto de función\n\n\nDefinición 2.7 (Función) Una función, llamada \\(f(\\cdot)\\), con dominio \\(A\\) y contradominio \\(B\\), es una colección de pares ordenados, llamados \\((a,b)\\), que cumplen las siguientes condiciones:\n\n\\(a\\in A\\) y \\(b\\in B\\)\nCada \\(a\\in A\\) aparece como el primer elemento de algún par ordenado en la colección (cada \\(b\\in B\\) no necesariamente es el segundo elemento de algún par ordenado)\nNingún par ordenado en la colección tiene el mismo primer elemento que otro par ordenado distinto.\n\n\n\nSi \\((a,b)\\in f(\\cdot)\\), se escribe \\(b=f(a)\\) (se lee “\\(b\\) es igual a \\(f\\) de \\(a\\)”) y se denomina \\(f(a)\\) como el valor de \\(f(\\cdot)\\) en \\(a\\). Para cualquier \\(a\\in A\\), \\(f(a)\\) es un elemento de \\(B\\); mientras que \\(f(\\cdot)\\) es un conjunto de pares ordenados. El conjunto de todos los valores de \\(f(\\cdot)\\) se denomina rango de \\(f(\\cdot)\\); es decir, el rango de \\(f(\\cdot)=\\{b\\in B:b=f(a) \\text{ para algún } a\\in A\\}\\) y siempre es un subconjunto del contradominio \\(B\\), pero no necesariamente igual a él. \\(f(a)\\) también se denomina imagen de \\(a\\) bajo \\(f(\\cdot)\\), y \\(a\\) se denomina preimagen de \\(f(a)\\).\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\nSean \\(f_1(\\cdot)\\) y \\(f_2(\\cdot)\\) dos funciones con la recta real como su dominio y contradominio, definidas por\n\\[ f_1(\\cdot)=\\{(x,y): y=x^3+1, -\\infty&lt; x&lt; \\infty\\} \\]\ny\n\\[ f_2(\\cdot)=\\{(x,y): y=x^2, -\\infty&lt;x&lt; \\infty\\} \\]\nEl rango de \\(f_1(\\cdot)\\) es el contradominio, que es toda la recta real, pero el rango de \\(f_2(\\cdot)\\) son todos los números reales no negativos, que no es igual al contradominio.\n\n\n\n\nDe particular interés será una clase de funciones conocidas como funciones indicadoras.\n\n\nDefinición 2.8 (Función indicadora) Sea \\(\\Omega\\) cualquier espacio con puntos \\(\\omega\\) y \\(A\\) cualquier subconjunto de \\(\\Omega\\). La función indicadora de \\(A\\), denominada \\(I_A(\\cdot)\\), es la función con dominio \\(\\Omega\\) y contradominio formado por dos números reales, 0 y 1, definida por\n\\[ I_A(\\omega)= \\left\\{\\begin{array}{lcc} 1 & si & \\omega \\in A\\\\ \\\\0 & si & \\omega \\notin A \\end{array}\\right. \\]\n\\(I_A(\\cdot)\\) claramente “indica” el conjunto \\(A\\).\n\n\nPropiedades de la función indicadora.\nSea \\(\\Omega\\) cualquier espacio y \\(\\mathfrak{F}\\) cualquier colección de subconjuntos de \\(\\Omega\\):\n\n\\(I_A(\\omega)= 1- I_{A^c}(\\omega)\\) para cada \\(A\\in \\mathfrak{F}\\).\n\\(I_{A_1A_2\\cdots A_n}(\\omega)= I_{A_1}(\\omega)\\cdot I_{A_2}(\\omega)\\cdots I_{A_n}(\\omega)\\) para \\(A_1,\\ldots, A_n\\in \\mathfrak{F}\\).\n\\(I_{A_1\\cup A_2\\cup\\cdots\\cup A_n}(\\omega)= \\max{[I_{A_1}(\\omega), I_{A_2}(\\omega),\\ldots, I_{A_n}(\\omega)]}\\) para \\(A_1, \\ldots, A_n \\in\\mathfrak{F}\\).\n\\(I_A^2(\\omega)= I_A(\\omega)\\) para cada \\(A\\in\\mathfrak{F}\\).\n\nLa función indicadora será utilizada para “indicar” subconjuntos de la recta real; por ejemplo;\n\\[I_{\\{[0,1)\\}}(x)= I_{[0,1)}(x)=\\left\\{ \\begin{array}{lcc} 1 & \\text{si} & 0\\leq x&lt;1\\\\ \\\\ 0 & \\text{ otro caso} \\end{array} \\right. \\]\ny si \\(I^+\\) denota el conjunto de números enteros positivos,\n\\[ I_{I^+}(X)=\\left\\{\\begin{array}{lcc} 1 & \\text{si $x$ es algún entero positivo}\\\\ \\\\ 0 & \\text{otro caso}\\end{array}\\right. \\]\nOtro tipo de función del cual se tendrá ocasión de discutir es la función de conjunto definida como cualquier función que tiene como dominio una colección de conjuntos y como contradominio la recta real, incluyendo posiblemente el infinito. A continuación se muestra un ejemplos de función de conjunto.\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\nSea \\(\\Omega\\) el espacio muestral correspondiente al experimento de lanzar dos dados, y sea \\(\\mathfrak{F}\\) la colección de todos los subconjuntos de \\(\\Omega\\). Para cualquier \\(A\\in\\mathfrak{F}\\), se define \\(N(A)\\) como el número de resultados, o puntos en \\(\\Omega\\), que están en \\(A\\). Entonces, \\(N(\\emptyset)=0\\), \\(N(\\Omega)=36\\) y \\(N(A)=6\\) si \\(A\\) es el evento que contiene aquellos resultados que tienen un total de siete puntos arriba.\n\n\n\n\nLa función de tamaño del conjunto aludida en el ejemplo anterior puede ser definida, en general, para cualquier conjunto \\(A\\) como el número de puntos en \\(A\\), donde \\(A\\) es un miembro de una colección arbitraria de conjuntos \\(\\mathfrak{F}\\).\nLa función de probabilidad que se definirá será una función de conjunto particular.\n\n\nDefinición 2.9 (Función de probabilidad) Sea \\(A\\) un evento del espacio muestral \\(\\Omega\\). Una función \\(P: \\mathfrak{F} \\to [0,1]\\) es llamada función de probabilidad y \\(P(A)\\) se denomina la probabilidad del evento \\(A\\) si se cumplen los siguientes axiomas:\n\nNo negatividad: Para todo evento \\(A\\) en \\(\\mathfrak{F}\\), la probabilidad \\(P(A)\\) es un número no negativo, es decir, \\(P(A) \\geq 0\\).\nProbabilidad unitaria: La probabilidad del espacio muestral completo \\(\\Omega\\) es igual a 1, es decir, \\(P(\\Omega) = 1\\).\nAditividad: Para cualquier colección de eventos mutuamente excluyentes \\(A_1, A_2, A_3, \\ldots\\), la probabilidad de la unión de estos eventos es igual a la suma de las probabilidades individuales, es decir, \\[P\\left(\\bigcup_{i=1}^\\infty A_i\\right) = \\sum_{i=1}^\\infty P(A_i)\\]\n\n\n\nEstos axiomas establecen las propiedades esenciales que debe cumplir una función de probabilidad para ser considerada válida. Cumplir con estos axiomas garantiza que la función de probabilidad asigna valores coherentes y consistentes a los eventos en el espacio muestral.\nA partir de los axiomas, se derivan otras propiedades que ayudan a calcular las probabilidades de varios eventos.\n\n\\(P(\\emptyset)=0\\).\nSi \\(A_1, \\ldots, A_n\\) son eventos mutuamente excluyentes en \\(\\mathfrak{F}\\), entonces \\[P\\left(\\bigcup\\limits_{i=1}^n A_i\\right)= \\sum\\limits_{i=1}^n P(A_i).\\]\nSi \\(A\\) es un evento en \\(\\mathfrak{F}\\), entonces \\[P(A^c)= 1-P(A).\\]\nSi \\(A,B\\in\\mathfrak{F}\\), entonces\n\\[P(A)= P(A\\cap B)+ P(A\\cap B^c)\\]\ny \\[P(A-B)=P(A\\cap B^c)= P(A)-P(A\\cap B).\\]\nSi \\(A,B\\in \\mathfrak{F}\\) y \\(A\\subset B\\), entonces \\(P(A)\\leq P(B)\\).\nPara cualesquiera dos eventos \\(A,B\\in \\mathfrak{F}\\); \\[P(A\\cup B)= P(A)+P(B)-P(A\\cap B).\\]Más generalmente, para eventos \\(A_1, A_2, \\ldots, A_n\\in \\mathfrak{F}\\)\n\n\\[ \\begin{split}P\\left(\\bigcup\\limits_{i=1}^n A_i\\right) & = \\sum_{j=1}^nP(A_j)-{\\sum\\sum}_{i&lt;j} P(A_i\\cap A_j)\\\\ &+\\sum\\sum\\sum_{i&lt;j&lt;k}P(A_i\\cap A_j\\cap A_k) -\\cdots+(-1)^{n+1}P(A_1\\cap \\ldots\\cap A_n)\\end{split} \\]\n\n\nTeorema 2.1 (Desigualdad de Boole) Si \\(A_1, A_2, \\ldots, A_n\\in\\mathfrak{F}\\), entonces\n\\[P\\left(\\bigcup_{i=1}^n A_i\\right)\\leq \\sum_{i=1}^n P(A_i)\\]\n\n\nFinalmente se concluye esta subsección con la siguiente definición;\n\n\nDefinición 2.10 (Espacio de probabilidad) Un espacio de probabilidad es la terna \\((\\Omega, \\mathfrak{F}, P)\\), donde \\(\\Omega\\) es un espacio muestral, \\(\\mathfrak{F}\\) es una colección (asumida como un álgebra) de eventos (cada uno un subconjunto de \\(\\Omega\\)), y \\(P\\) es una función de probabilidad con dominio \\(\\mathfrak{F}\\).",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#probabilidad-condicional",
    "href": "probabilidad.html#probabilidad-condicional",
    "title": "2  Probabilidad",
    "section": "2.3 Probabilidad condicional",
    "text": "2.3 Probabilidad condicional\n\nEn ocasiones, es de interés conocer la probabilidad de un evento, dado que haya ocurrido otro. En este sentido, se define la probabilidad condicional.\n\n\nDefinición 2.11 (Probabilidad condicional) Sean \\(A\\) y \\(B\\) dos eventos en \\(\\mathfrak{F}\\) del espacio de probabilidad dado \\((\\Omega, \\mathfrak{F}, P)\\). La probabilidad condicional del evento \\(A\\) dado el evento \\(B\\), denotada por \\(P(A|B)\\), se define como sigue;\n\\[P(A|B)= \\frac{P(A\\cap B)}{P(B)}\\qquad\\text{si }\\quad P(B)&gt;0,\\]\ny se deja sin definir si \\(P(B)=0\\).\n\n\nObservación. Una fórmula que es evidente a partir de la definición es \\[P(A\\cap B)= P(A|B)P(B)=P(B|A)P(A)\\] si tanto \\(P(A)\\) como \\(P(B)\\) son diferentes de cero. Esta fórmula relaciona \\(P(A|B)\\) con \\(P(B|A)\\) en términos de las probabilidades incondicionales \\(P(A)\\) y \\(P(B)\\).\n\n\nDe la definición anterior, se desprenden las siguientes propiedades de la función de probabilidad condicional. Se asume que el espacio de probabilidad \\((\\Omega, \\mathfrak{F}, P)\\) está dado, y se considera que \\(B\\in\\mathfrak{F}\\) cumple con \\(P(B)&gt;0\\).\n\n\\(P(\\emptyset| B)=0\\).\nSi \\(A_1, A_2, \\ldots, A_n\\) son eventos mutuamente excluyentes en \\(\\mathfrak{F}\\), entonces\n\\[P\\left(\\bigcup_{i=1}^n A_i|B\\right)= \\sum_{i=1}^n P(A_i|B).\\]\nSi \\(A\\) es un evento en \\(\\mathfrak{F}\\), entonces \\(P(A^c| B)=1-P(A|B)\\).\nSi \\(A_1, A_2\\in \\mathfrak{F}\\), entonces \\(P(A_1|B)=P(A_1\\cap A_2|B)+ P(A_1\\cap A_2^c|B)\\).\nPara cualesquiera dos eventos \\(A_1,A_2\\in \\mathfrak{F}\\)\n\\[P(A_1\\cup A_2|B)=P(A_1|B)+P(A_2|B)-P(A_1\\cap A_2|B).\\]\nSi \\(A_1, A_2\\in\\mathfrak{F}\\) y \\(A_1\\subset A_2\\), entonces \\(P(A_1|B)\\leq P(A_2|B)\\).\nSi \\(A_1, A_2,\\ldots, A_n\\in\\mathfrak{F}\\), entonces\n\\[P\\left(\\bigcup_{i=1}^n A_i|B\\right)\\leq \\sum_{i=1}^n P(A_i|B).\\]\n\nA continuación se mencionan unos teoremas de gran importancia. La aplicación de dichos teoremas se ilustran con unos ejemplos.\n\n\nTeorema 2.2 (Teorema de probabilidades totales) Para un espacio de probabilidad dado \\((\\Omega, \\mathfrak{F}, P)\\), si \\(B_1, B_2, \\ldots, B_n\\) es una colección de eventos mutuamente disjuntos en \\(\\mathfrak{F}\\) que satisfacen \\(\\Omega = \\bigcup\\limits_{j=1}^n B_j\\) y \\(P(B_j)&gt;0\\) para \\(j=1,\\ldots, n\\), entonces para cada \\(A\\in \\mathfrak{F}\\), \\[P(A)=\\sum_{j=1}^n P(A|B_j)P(B_j).\\]\n\nPrueba. Se observa que \\(A=\\bigcup\\limits_{j=1}^n A\\cap B_j\\) y los conjuntos \\(A\\cap B_j\\) son mutuamente disjuntos; por lo tanto,\n\\[P(A)=P\\left(\\bigcup_{j=1}^n A\\cap B_j\\right)=\\sum_{j=1}^n P(A\\cap B_j)= \\sum_{j=1}^n P(A|B_j)P(B_j)\\]\n\n\n\n\n\n\n\n\nEjemplo (Seleccionar una pelota de varias urnas)\n\n\n\n\n\nHay dos urnas con pelotas de diferentes colores, todas del mismo tamaño. En la primera urna, hay tres pelotas rojas, tres blancas y cuatro negras; en la segunda urna, hay cuatro pelotas rojas, tres blancas y una negra. Se elige una urna al azar y se saca una pelota de ella. ¿Cuál es la probabilidad de que la pelota extraída sea blanca?\n\nSolución. Se debe observar que la elección de las urnas constituye dos eventos mutuamente excluyentes, ya que la unión de ambos eventos constituye el espacio muestral (todas las pelotas están en la primera o segunda urna). Se denomina \\(B_1\\) al evento de seleccionar la primera urna, y \\(B_2\\) al evento de seleccionar la segunda urna.\nEl evento de extraer una pelota blanca puede tener lugar tanto al elegir la primera urna como al elegir la segunda urna, lo que permite la aplicación de la fórmula del teorema de probabilidades totales. Se designa como \\(A\\) al evento de seleccionar una pelota blanca.\nDe esta manera,\n\\[ P(A)= \\sum_{j=1}^2 P(A|B_j)P(B_j)=P(A|B_1)P(B_1)+P(A|B_2)P(B_2) \\]\nBajo la premisa de probabilidades equivalentes, se tiene que \\(P(B_1)=P(B_2)=\\frac{1}{2}\\), \\(P(A|B_1)=\\frac{3}{10}\\) y \\(P(A|B_2)=\\frac{3}{8}\\), por lo que la probabilidad de elegir una pelota blanca es \\(0.3375\\).\n\n\n\n\n\nTeorema 2.3 (Teorema de Bayes) Para un espacio de probabilidad dado \\((\\Omega, \\mathfrak{F}, P)\\), si \\(B_1, B_2, \\ldots, B_n\\) es una colección de eventos mutuamente disjuntos en \\(\\mathfrak{F}\\) que satisfacen \\(\\Omega=\\bigcup\\limits_{j=1}^n B_j\\) y \\(P(B_j)&gt;0\\) para \\(j=1,\\ldots, n\\), entonces para cada \\(A\\in\\mathfrak{F}\\) para el cual \\(P(A)&gt;0\\)\n\\[P(B_k|A)= \\frac{P(A|B_k)P(B_k)}{\\sum\\limits_{j=1}^n P(A|B_j)P(B_j)}.\\]\n\nPrueba. Se observa que\n\\[P(B_k|A)= \\frac{P(B_k\\cap A)}{P(A)}=\\frac{P(A|B_k)P(B_k)}{\\sum\\limits_{j=1}^n P(A|B_j)P(B_j)}\\]\nutilizando tanto la definición de probabilidad condicional como el teorema de probabilidad total.\n\n\n\n\n\n\n\n\nEjemplo (Seleccionar una pelota de varias urnas)\n\n\n\n\n\nConsidérese el problema de las urnas. Teniendo en cuenta que la pelota extraída fue blanca, ¿cuál es la probabilidad de que haya provenido de la primera urna?\n\nSolución. Debe calcularse la probabilidad \\(P(B_1|A)\\). Al utilizar el teorema de Bayes, solo se realiza la sustitución en la fórmula y se obtiene que la probabilidad resultante es \\(0.4444\\).\n\n\n\n\n\nTeorema 2.4 (Regla de multiplicación) Para un espacio de probabilidad dado \\((\\Omega, \\mathfrak{F}, P)\\), sean \\(A_1, A_2, \\ldots, A_n\\) eventos pertenecientes a \\(\\mathfrak{F}\\) para los cuales \\(P(A_1\\cdots A_{n-1})&gt;0\\); entonces\n\\[P(A_1A_2\\cdots A_n)= P(A_1)P(A_2|A_1)P(A_3|A_1A_2)\\cdots P(A_n|A_1\\cdots A_{n-1})\\]",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#independencia-de-eventos",
    "href": "probabilidad.html#independencia-de-eventos",
    "title": "2  Probabilidad",
    "section": "2.4 Independencia de eventos",
    "text": "2.4 Independencia de eventos\n\nSi \\(P(A|B)\\) no depende del evento \\(B\\), es decir, \\(P(A|B)=P(A)\\), entonces parecería natural decir que el evento \\(A\\) es independiente del evento \\(B\\). Esto se establece en la siguiente definición.\n\n\nDefinición 2.12 (Eventos independientes) Para un espacio de probabilidad dado \\((\\Omega, \\mathfrak{F}, P)\\), sean \\(A\\) y \\(B\\) dos eventos en \\(\\mathfrak{F}\\). Los eventos \\(A\\) y \\(B\\) se definen como independientes si y solo si se cumple alguna de las siguientes condiciones:\n\n\\(P(A\\cap B)= P(A)P(B)\\).\n\\(P(A|B)=P(A)\\) si \\(P(B)&gt;0\\).\n\\(P(B|A)=P(B)\\) si \\(P(A)&gt;0\\).\n\n\nDe la definición anterior, se desprende lo siguiente\n\nSi \\(A\\) y \\(B\\) son dos eventos independientes definidos en un espacio de probabilidad dado \\((\\Omega, \\mathfrak{F}, P)\\), entonces los siguientes eventos también son independientes\n\n\\(A\\) y \\(B^c\\),\n\\(A^c\\) y \\(B\\),\n\\(A^c\\) y \\(B^c\\).\n\n\n\nObservación. No debe confundirse los términos eventos independientes y eventos disjuntos. De hecho, los eventos disjuntos suelen ser muy dependientes por que la ocurrencia de uno implica la no ocurrencia del otro. El único evento que es independiente y ajeno es el vacío \\(\\emptyset\\).\n\n\nLa noción de eventos independientes puede ser extendido a más de dos eventos como se sigue;\n\n\nDefinición 2.13 (Independencia de varios eventos) Para un espacio de probabilidad dado \\((\\Omega, \\mathfrak{F}, P)\\), sean \\(A_1, A_2, \\ldots, A_n\\) eventos en \\(\\mathfrak{F}\\). Los eventos \\(A_1, A_2, \\ldots, A_n\\) se definen como independientes si y solo si \\(P\\left(\\bigcap\\limits_{i=1}^n A_i\\right)=\\prod\\limits_{i=1}^n P(A_i)\\)",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#variables-aleatorias",
    "href": "probabilidad.html#variables-aleatorias",
    "title": "2  Probabilidad",
    "section": "2.5 Variables aleatorias",
    "text": "2.5 Variables aleatorias\n\nHasta el momento se conoce cómo asignar probabilidades a eventos del espacio muestral, sin embargo en la práctica esto no siempre es posible ya que sería complicado mencionar o enumerar todos los elementos del espacio muestral.\nPor esta razón es necesario “traducir” dichos eventos a números reales. Esto es posible mediante el uso de variables aleatorias.\n\n\nDefinición 2.14 (Variable aleatoria) Para un espacio de probabilidad dado \\((\\Omega, \\mathfrak{F}, P)\\), una variable aleatoria, denotada por \\(X\\) o \\(X(\\cdot)\\), es una función con dominio \\(\\Omega\\) y contradominio la recta real. La función \\(X(\\cdot)\\) debe ser tal si \\(\\omega\\in\\Omega\\) entonces \\(X(\\omega)\\in\\mathbb R\\). Si \\(B\\subset \\mathbb R\\) entonces \\(X^{-1}(B)\\in\\mathfrak{F}\\), donde \\[X^{-1}(B)=\\{\\omega\\in\\Omega| X(\\omega\\in B)\\}.\\]\n\n\nExisten dos tipos de variables aleatorias: discretas y continuas. Las variables aleatorias discretas toman sus valores en un conjunto finito o numerable, por ejemplo, el conjunto de los números naturales \\(\\mathbb N\\). A este conjunto de valores se le conoce como conjunto de valores posibles o \\(D_X\\). Las variables aleatorias continuas, por el contrario, toman sus valores en el conjunto de los números reales \\(\\mathbb R\\).\n\n\n2.5.1 Función de distribución\n\nPara describir el comportamiento de una variable aleatoria, se debe conocer cómo se comportan sus probabilidades, esto puede realizarse mediante la función de distribución.\n\n\nDefinición 2.15 (Función de distribución acumulada) La función de distribución acumulada de una variable aleatoria \\(X\\), denotada por \\(F_X(\\cdot)\\), se define como aquella función con dominio la recta real y contradominio el intervalo \\([0,1]\\), que satisface \\(F_X(x)=P(X\\leq x)=P({\\omega: X(\\omega)\\leq x})\\) para cada número real \\(x\\).\n\n\nUna función de distribución definida es única para cada variable y siempre existirá, es importante conocerla por que con ella se pueden calcular probabilidades de la variable aleatoria.\nA continuación, se presentan ejemplos y propiedades de la función de distribución acumulada.\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\nSe considera el experimento de lanzar una moneda. Supongamos que la moneda es justa. Sea \\(X\\) el número de caras obtenidas. Entonces,\n\\[F_X(x)=\\left\\{ \\begin{array}{lcc} 0 & \\text{si} & x&lt;0\\\\ \\\\ \\frac{1}{2} & \\text{si} & 0\\leq x&lt;1 \\\\ \\\\1 & \\text{si} & 1\\leq x \\end{array} \\right. \\]\nO \\(F_X(x)=\\frac{1}{2}I_{[0,1)}(x)+ I_{[1,\\infty)}(x)\\) en nuestra notación de función indicadora.\n\n\n\n\n2.5.1.1 Propiedades de la función de distribución acumulada.\n\n\n\\(F_X(-\\infty)\\equiv \\lim\\limits_{x\\to-\\infty} F_X(x)=0\\), y \\(F_X(+\\infty)\\equiv \\lim\\limits_{x\\to+\\infty} F_X(x)=1\\).\n\\(F_X(\\cdot)\\) es una función monótona creciente; es decir, para toda \\(a&lt; b\\) entonces \\(F_X(a)\\leq F_X(b)\\).\n\\(F_X(\\cdot)\\) es continua por la derecha, esto es \\(\\lim\\limits_{0&lt;h\\to 0} F_X(x+h)=F_X(x)\\).\n\n\n\nDefinición 2.16 (Función de distribución acumulada) Cualquier función \\(F(\\cdot)\\) con dominio la recta real y contradominio el intervalo \\([0,1]\\), que satisface las tres propiedades mencionadas anteriormente, se define como una función de distribución acumulada.\n\n\n\n\n\n\n\nEjemplo (Lanzar 3 monedas)\n\n\n\n\n\nConsidérese el ejemplo del lanzamiento de tres monedas. Sea \\(X\\) el número de águilas en tres lanzamientos.\nLa función de distribución es la siguiente:\n\\[ F_X(x)=\\begin{cases}0 & \\text{ si } x&lt;0\\\\ \\frac{1}{8} & \\text{ si } 0\\leq x&lt; 1\\\\ \\frac{1}{2} & \\text{ si  } 1\\leq x&lt; 2\\\\ \\frac{7}{8} & \\text{ si  } 2\\leq x&lt;3\\\\ 1 & \\text{ si } 3\\leq x\\end{cases} \\]\nA continuación se muestra una gráfica de la función\n\n\n\n\n\n\n\n\n\nPor ejemplo, la probabilidad de que se obtenga 0 a 1 aguilas es \\(\\frac{1}{8}\\).\n\n\n\n\n\n\n\n\n\nEjemplo (Duración de una llamada telefónica)\n\n\n\n\n\nPara las variables aleatorias continuas, la froma de la función de distribución es un poco distinta, pero sigue cumpliendo las mismas propiedades.\nA continuación se representa una función de distribución acumulada de la variable aleatoria \\(X\\) que podría ser usada para modelar la duración de las llamadas telefónicas.\n\\[ F_X(x)=\\begin{cases}0 & \\text{ si } x\\leq0\\\\ 1-e^{-x} & \\text{ si } 0&lt; x\\end{cases} \\]\nEn este caso, se puede ver que la probabilidad de que la variable aleatoria \\(X\\) sea menor a cero es 0, ya que el soporte de la distribución son los números reales positivos.\nComo puede apreciarse, conociendo la función de distribución es posible obtener las probabilidades de cualquier evento, simplemente evaluando los valores en la función, por ejemplo:\n\n\\(P(X&lt;2)=1-e^{-2}=0.8646\\)\n\\(P(X&gt;5)=1-(1-e^{-5})=0.0067\\)\n\\(P(1&lt;X&lt;3)=P(X&lt;3)-P(X&lt;1)=0.3180\\)\n\n\n\n\n\nObservación. Se debe tener cuidado cuando se calcula probabilidades de variables aleatorias discretas ya que en general no es lo mismo \\(P(X&lt; x)\\) que \\(P(X\\leq x)\\).\n\n\n\n\n2.5.2 Función de densidad\n\nOtra función relacionada con las variables aleatorias es la función de densidad.\nA diferencia de la función de distribución, esta función es distinta según si la variable aleatoria es discreta o continua. Primero se definirá para el caso discreto y posteriormente para el caso continuo.\n\n\n\n2.5.3 Variables aleatorias discretas\n\nDefinición 2.17 (Variable aleatoria discreta) Se definirá una variable aleatoria \\(X\\) como discreta si el rango de \\(X\\) es numerable. Si una variable aleatoria \\(X\\) es discreta, entonces su función de distribución acumulada correspondiente \\(F_X(\\cdot)\\) se definirá como discreta.\n\n\nDefinición 2.18 (Función de densidad discreta de una variable aleatoria discreta) Si \\(X\\) es una variable aleatoria discreta con \\(D_x=x_1,x_2,\\ldots\\) entonces la función, denotada por \\(f_X(\\cdot)\\) y definida por\n\\[ f_X(x)=\\begin{cases}P(X=x_j) & \\text{ si } x\\in D_x\\\\ 0 & \\text{ cualquier otro caso. }\\end{cases} \\]\nes la función de densidad discreta de \\(X\\).\n\n\nObservación. En ocasiones se usa la función indicadora \\(I_{D_x}(x)=1\\) si \\(x\\in D_x\\) y \\(I_{D_x}(x)=0\\) si \\(x\\notin D_x\\) para expresar la función de densidad en una sola línea.\n\n\nTeorema 2.5 Sea \\(X\\) una variable aleatoria discreta. \\(F_X(\\cdot)\\) puede ser obtenido a partir de \\(f_X(\\cdot)\\), y viceversa.\n\n\nDefinición 2.19 (Función de densidad discreta) Cualquier función \\(f(\\cdot)\\) con dominio \\(\\mathbb R\\) y contradominio \\([0,1]\\) se define como una función de densidad discreta si para algún conjunto contable \\(D=\\{x_1, x_2,\\ldots\\}\\) se cumple lo siguiente;\n\n\\(f(x_j)&gt;0\\) para \\(j=1,2,\\ldots.\\)\n\\(f(x)=0\\) para \\(x\\neq x_j\\) con \\(j=1,2,\\ldots.\\)\n\\(\\sum_D f(x_j)=1\\)\n\n\n\n\n2.5.4 Variables aleatorias continuas\n\nDefinición 2.20 (Variable aleatoria continua) Se llama variable aleatoria continua a \\(X\\) si existe una función \\(f_X(\\cdot)\\) tal que \\(F_X(x)=\\int_{-\\infty}^x f_X(u) du\\) para cada número real \\(x\\). La función de distribución acumulada \\(F_X(\\cdot)\\) de una variable aleatoria continua \\(X\\) se llama absolutamente continua.\n\n\nDefinición 2.21 (Función de densidad de una variable aleatoria continua) Si \\(X\\) es una variable aleatoria continua, la función \\(f_X(\\cdot)\\) en \\(F_X(x)=\\int_{-\\infty}^x f_X(u)du\\) se llama función de densidad de \\(X\\).\n\n\nObservación. En ocasiones se usa la función indicadora \\(I_{(a,b)}(x)=1\\) si \\(x\\in (a,b)\\) y \\(I_{(a,b)}(x)=0\\) si \\(x\\notin (a,b)\\) para expresar la función de densidad en una sola línea.\n\n\nTeorema 2.6 Si \\(X\\) es una variable aleatoria continua, entonces \\(F_X(\\cdot)\\) se puede obtener a partir de una función \\(f_X(\\cdot)\\), y viceversa.\n\n\nLas demostraciones del Teorema 2.5 y Teorema 2.6 pueden ser consultados en (Mood, Graybill, y Boes 1986).\n\n\n\n\n\n\n\nEjemplo (Duración de una llamada telefónica)\n\n\n\n\n\nUsando el teorema fundamental del cálculo, se puede probar la propiedad anterior. Se ilustrará para el ejemplo de la duración de llamadas telefónicas.\nSupóngase que la función de distribución para modelar la duración de las llamadas telefónicas es\n\\[ F_X(x)=\\begin{cases}0 & \\text{ si } x \\le 0\\\\ 1-e^{-x} & \\text{ si } 0&lt; x\\end{cases} \\]\nSe observa que \\(F_X(x)\\) está definida en dos partes, por lo que la función no es absolutamente continua en cero, por lo que solo será diferenciable en el intervalo de los reales positivos.\n\\[ f_X(x)=\\frac{dF_X(x)}{dx}=\\frac{d (1-e^{-x})}{dx}=-\\frac{d e^{-x}}{dx}=e^{-x} \\]\nes decir;\n\\[ f_X(x)=e^{-x}I_{(0,\\infty)}(x). \\]\nPor otro lado, se observa que\n\\[ F_X(x)= \\int_{\\infty}^x e^{-u}du=\\int_0^x e^{-u}du=1-e^{-x}, \\]\nes decir\n\\[ F_X(x)=1-e^{-x} I_{(0,\\infty)}(x) \\]\nDe esta manera, se comprueba la propiedad.\n\n\n\n\nObservación. Se utilizará el término “función de densidad” sin el modificador de “discreta” o “de probabilidad” para representar cualquier tipo de densidad.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#vectores-aleatorios",
    "href": "probabilidad.html#vectores-aleatorios",
    "title": "2  Probabilidad",
    "section": "2.6 Vectores aleatorios",
    "text": "2.6 Vectores aleatorios\n\nDefinición 2.22 (Vector aleatorio \\(n-\\)dimensional) Sean \\(X_1,X_2,\\cdots, X_n\\) variables aleatorias reales definidas sobre el mismo espacio de probabilidad \\((\\Omega, \\mathfrak F, P)\\). La función \\(\\mathbf X:\\Omega\\to\\mathbb R^n\\) definida como\n\\[ \\mathbf X(\\omega)= (X_1(\\omega),\\cdots,X_n(\\omega)) \\]\nse denomina vector aleatorio \\(n-\\)dimensional.\n\n\nDefinición 2.23 (Distribución de un vector aleatorio) Sea \\(\\mathbf X\\) un vector aleatorio \\(n-\\)dimensional. La medida de probabilidad definida por\n\\[ P_{\\mathbf X} (B) := P(\\mathbf X\\in B); B\\in \\mathcal B_n \\]\ndonde \\(\\mathcal B_n\\) representa la sigma álgebra del Borel sobre \\(\\mathbb R^n\\), es denominada la distribución del vector aleatorio \\(\\mathbf X\\).\n\n\nDefinición 2.24 (Función de masa de probabilidad conjunta) Sea \\(\\mathbf X= (X_1,X_2,\\cdots,X_n)\\) un vector aleatorio de \\(n\\) dimensiones. Si las variables aleatorias \\(X_i\\), donde \\(i=1,\\cdots,n\\), son todas discretas, se afirma que el vector aleatorio \\(\\mathbf X\\) es discreto. En esta situación, la función de densidad de \\(\\mathbf X\\), también conocida como la función de densidad conjunta de las variables aleatorias \\(X_1, X_2, \\cdots, X_n\\), queda definida por\n\\[ p_\\mathbf{X}(x):=\\begin{cases}P(\\mathbf X=x) & \\text{ si } x \\text{  pertenece a la imagen de } \\mathbf X\\\\ 0 & \\text{ en caso contrario. } \\end{cases} \\]\n\n\nDefinición 2.25 (Función de distribución acumulada conjunta) Sea \\(\\mathbf X=(X_1,X_2,\\cdots, X_n)\\) un vector aleatorio de \\(n\\) dimensiones. La función definida por\n\\[ F(x_1,x_2,\\cdots,x_n):= P(X_1\\leq x_1, X_2\\leq x_2,\\cdots, X_n\\leq x_n), \\]\npara todo \\((x_1,x_2,\\cdots,x_n)\\in\\mathbb R^n\\) recibe el nombre de función de distribución acumulativa conjunta de las variables aleatorias \\(X_1, X_2, \\cdots, X_n\\), o simplemente la función de distribución del vector aleatorio \\(n-\\)dimensional \\(\\mathbf X\\).\n\n\n\n\n\nLipschutz, S. 1996. Probabilidad. McGraw-Hill. https://books.google.com.mx/books?id=vndlwgEACAAJ.\n\n\nMood, A. M. F., F. A. Graybill, y D. C. Boes. 1986. Introduction to the Theory of Statistics. McGraw-Hill series en Probability y Statistics. https://books.google.com.mx/books?id=bKHBjgEACAAJ.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probabilidad</span>"
    ]
  },
  {
    "objectID": "estadistica.html",
    "href": "estadistica.html",
    "title": "3  Estadística",
    "section": "",
    "text": "3.1 Datos univariados",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estadística</span>"
    ]
  },
  {
    "objectID": "estadistica.html#datos-univariados",
    "href": "estadistica.html#datos-univariados",
    "title": "3  Estadística",
    "section": "",
    "text": "En esta sección se definirán conceptos básicos de la estadística univariada. Se comienza con los siguientes conceptos;\n\n\nDefinición 3.2 (Población) Una población consiste en todos los elementos (individuos, elementos u objetos) cuyas características se están estudiando. La población que se está estudiando también se denomina población objetivo.\n\n\nDefinición 3.3 (Parámetro) Un parámetro es una característica numérica o descriptiva de una población o probabilidad distribución.\n\n\n3.1.1 Valor Esperado y momentos\n\nUn concepto sumamente útil en problemas que implican variables aleatorias o distribuciones es el de la esperanza (valor esperado). En esta subsección, se presentan definiciones y resultados relacionados con la esperanza.\n\n\nDefinición 3.4 (Media) Sea \\(X\\) una variable aleatoria. La media de \\(X\\), denotada como \\(\\mu_X\\) o \\(\\mathrm E[X]\\), se define de la siguiente manera:\n\\[ \\mathrm E[X]= \\sum x_jf_X(x_j) \\]\nSi \\(X\\) es discreta con puntos de densidad \\(x_1, x_2, \\ldots, x_j, \\ldots\\)\n\\[ \\mathrm E[X]=\\int_{-\\infty}^\\infty x f_X(x)dx \\]\nSi \\(X\\) es continua con una función de densidad de probabilidad \\(f_X(x)\\)\n\\[ \\mathrm E[X]=\\int_0^\\infty [1-F_X(x)]dx-\\int_{-\\infty}^0 F_X(x) dx \\]\npara cualquier variable aleatoria \\(X\\).\n\n\nObservación. \\(\\mathrm E[X]\\) representa el centro de gravedad (o centroide) de la región unitaria determinada por la función de densidad de \\(X\\). De esta manera, la media de \\(X\\) proporciona una medida de la ubicación central de los valores de la variable aleatoria \\(X\\).\n\n\nLa media de una variable aleatoria \\(X\\) es una medida de ubicación central de la densidad de \\(X\\). La varianza de una variable aleatoria \\(X\\) es una medida de la dispersión o propagación de la densidad de \\(X\\).\n\n\nDefinición 3.5 (Varianza) Sea \\(X\\) una variable aleatoria, y se define \\(\\mu_X\\) como \\(\\mathrm E[X]\\), la varianza de \\(X\\), denotada como \\(\\sigma_X^2\\) o \\(\\mathrm{Var}[X]\\), se define de la siguiente manera\n\\[ \\mathrm{Var}[X]= \\sum_j (x_j-\\mu_X)^2 f_X(x_j) \\]\nsi \\(X\\) es discreta con puntos \\(x_1, x_2, \\ldots, x_j, \\ldots\\).\n\\[ \\mathrm{Var}[X]=\\int_{-\\infty}^\\infty (x-\\mu_X)^2f_X(x)dx \\]\nSi \\(X\\) es continua con una función de densidad de probabilidad \\(f_X(x)\\)\n\\[ \\mathrm{Var}[X]=\\int_0^\\infty 2x[1-F_X(x)+F_X(-x)]dx - \\mu_X^2 \\]\npara una variable aleatoria \\(X\\) arbitraria.\n\n\nSe vio que una media era el centro de gravedad de una densidad; de manera similar, la varianza representa el momento de inercia de la misma densidad con respecto a un eje perpendicular que pasa por el centro de gravedad.\n\n\nDefinición 3.6 (Desviación estándar) Si \\(X\\) es una variable aleatoria, la desviación estándar de \\(X\\), denotada por \\(\\sigma_X\\), se define como \\(+\\sqrt{\\mathrm{Var}[X]}\\).\n\n\nLa desviación estándar de una variable aleatoria, al igual que la varianza, es una medida de la dispersión o propagación de los valores de la variable aleatoria. En muchas aplicaciones, es preferible a la varianza como medida, ya que tendrá las mismas unidades de medida que la propia variable aleatoria.\n\n\n3.1.1.1 Valor esperado de una función de una variable aleatoria\n\nSe definió la esperanza de una variable aleatoria arbitraria \\(X\\), llamada la media de \\(X\\). En esta subsección, se definirá la esperanza de una función de una variable aleatoria para variables aleatorias discretas o continuas\n\n\nDefinición 3.7 (Valor esperado) Sea \\(X\\) una variable aleatoria y \\(g(\\cdot)\\) una función con dominio y codominio en la recta real. La esperanza o valor esperado de la función \\(g(\\cdot)\\) de la variable aleatoria \\(X\\), denotada por \\(\\mathrm E[g(X)]\\), se define de la siguiente manera:\n\\[ \\mathrm E[g(X)]=\\sum_j g(x_j)f_X(x_j)  \\tag{3.1}\\]\nSi \\(X\\) es discreta con puntos \\(x_1, x_2, \\ldots, x_j, \\ldots\\) (siempre que esta serie sea absolutamente convergente).\n\\[ \\mathrm E[g(X)]=\\int_{-\\infty}^\\infty g(x)f_X(x)dx  \\tag{3.2}\\]\nSi \\(X\\) es continua con función de densidad de probabilidad \\(f_X(x)\\) (siempre que \\(\\int_{-\\infty}^\\infty |g(x)|f_X(x)dx &lt; \\infty\\)).\n\n\nObservación. Si \\(g(x)=x\\), entonces \\(\\mathrm E[g(X)]=\\mathrm E[X]\\) es la media de \\(X\\). Si \\(g(x)=(x-\\mu_X)^2\\), entonces \\(\\mathrm E[g(X)]=\\mathrm E[(X-\\mu_X)^2]=\\mathrm{Var}[X]\\).\n\n\nTeorema 3.1 A continuación se presentan las propiedades del valor esperado,\n\n\\(\\mathrm E[c]=c\\) para una constante \\(c\\).\n\\(\\mathrm E[cg(X)]=c\\mathrm E[g(X)]\\) para una constante \\(c\\).\n\\(\\mathrm E[c_1 g_1(X)+c_2 g_2(X)]=c_1\\mathrm E[g_1(X)]+c_2\\mathrm E[g_2(X)]\\).\n\\(\\mathrm E[g_1(X)]\\leq \\mathrm E[g_2(X)]\\) si \\(g_1(x)\\leq g_2(x)\\) para todo \\(x\\).\n\n\n\nTeorema 3.2 Si \\(X\\) es una variable aleatoria, entonces\n\\[\\mathrm{Var}[X] = \\mathrm E[(X-\\mathrm E[X])^2] = \\mathrm E[X^2] - (\\mathrm E[X])^2, \\tag{3.3}\\] siempre que \\(\\mathrm E[X^2]\\) exista.\n\n\nLas pruebas de los teoremas anteriores se pueden consultar en (Mood, Graybill, y Boes 1986).\n\n\n\n3.1.1.2 Momentos\n\nLos momentos de una variable aleatoria o de una distribución son los valores esperados de las potencias de la variable aleatoria que tiene la distribución dada.\n\n\nDefinición 3.8 (Momento) Si \\(X\\) es una variable aleatoria, el \\(r-\\)ésimo momento de \\(X\\), generalmente denotado por \\(\\mu_r'\\), se define como\n\\[ \\mu_r'=\\mathrm E[X^r] \\] si el valor esperado existe.\n\n\nNote que \\(\\mu_1' = \\mathrm E[X] = \\mu_X\\), que es la media de \\(X\\).\n\n\nDefinición 3.9 (Cuantil) El \\(q-\\)ésimo cuantil de una variable aleatoria \\(X\\) o de su distribución correspondiente se denota como \\(\\xi_q\\) y se define como el número más pequeño \\(\\xi\\) que cumple con la condición \\(F_X(\\xi) \\geq q\\).\n\n\nSi \\(X\\) es una variable aleatoria continua, entonces el \\(q-\\)ésimo cuantil de \\(X\\) se calcula como el número más pequeño \\(\\xi\\) que cumple con la condición \\(F_X(\\xi) = q\\).\n\n\nDefinición 3.10 (Mediana) La mediana de una variable aleatoria \\(X\\), denotada como \\(\\mathrm{med}_X\\), \\(\\mathrm{med}(x)\\) o \\(\\xi_{0.5}\\), es el cuantil \\(0.5\\).\n\n\n\n\n3.1.2 Muestreo\n\nDefinición 3.11 (Muestra) Una porción de la población seleccionada para el estudio es conocida como una muestra.\n\n\nUna muestra puede ser aleatoria o no aleatoria. En una muestra aleatoria, cada elemento de la población tiene la posibilidad de ser incluido en la muestra. Sin embargo, en una muestra no aleatoria este puede no ser el caso.\n\n\nDefinición 3.12 (Muestra aleatoria) Sean \\(X_1, X_2, \\ldots, X_n\\) variables aleatorias con una densidad conjunta \\(f_{(X_1,\\ldots, X_n)}(\\cdot,\\ldots, \\cdot)\\) que se descompone de la siguiente manera:\n\\[f_{X_1,X_2,\\ldots, X_n}(x_1,x_2,\\ldots,x_n)=f(x_1)f(x_2)\\cdots f(x_n),\\] donde \\(f(\\cdot)\\) es la densidad (común) de cada \\(X_i\\). Entonces, se define que \\(X_1, X_2, \\ldots, X_n\\) es una muestra aleatoria de tamaño \\(n\\) de una población con densidad \\(f(\\cdot)\\).\n\n\nDefinición 3.13 (Media Muestral) El primer momento de la muestra es la media muestral, definida como\n\\[ \\bar{X}= \\bar{X_n}=\\frac{1}{n}\\sum_{i=1}^n X_i, \\]\ndonde \\(X_1, X_2, \\ldots, X_n\\) es una muestra aleatoria de una densidad \\(f(\\cdot)\\). \\(\\bar{X}\\) es una función de las variables aleatorias \\(X_1, \\ldots, X_n\\), y por lo tanto, en teoría se puede determinar la distribución de \\(\\bar{X}\\).\n\n\nDefinición 3.14 (Varianza muestral) Sea \\(X_1, X_2, \\ldots, X_n\\) una muestra aleatoria con densidad \\(f(\\cdot)\\), entonces\n\\[ S_n^2=S^2=\\frac{1}{n-1}\\sum_{i=1}^n (X_i-\\bar{X})^2\\qquad \\text{para  } n&gt;1 \\]\nse define como la varianza muestral.\n\n\nTeorema 3.3 Sea \\(X_1, X_2, \\ldots, X_n\\) una muestra aleatoria con densidad \\(f(\\cdot)\\), la cual tiene una media \\(\\mu\\) y una varianza finita \\(\\sigma^2\\), y sea \\(\\bar{X} = \\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\). Luego,\n\\[ \\mathrm{E}[\\bar X]=\\mu_{\\bar X}=\\mu\\qquad \\text{ y }\\qquad \\mathrm{Var}[\\bar X]=\\sigma_{\\bar X}^2 =\\frac{1}{n}\\sigma^2.\\]\n\nPrueba. Vea Mood, Graybill, y Boes (1986).\n\n\n\nTeorema 3.4 (Teorema del límite central) Supongamos que \\(f(\\cdot)\\) es una densidad con media \\(\\mu\\) y varianza finita \\(\\sigma^2\\). Si \\(\\bar{X}_n\\) es el promedio de una muestra aleatoria de tamaño \\(n\\) extraída de \\(f(\\cdot)\\) y definimos la variable aleatoria \\(Z_n\\) como\n\\[ Z_n = \\frac{\\bar{X_n}-\\mathrm E[\\bar X_n]}{\\sqrt{\\mathrm{Var}[\\bar X_n]}}=\\frac{\\bar X_n-\\mu}{\\sigma/\\sqrt n} \\] Entonces, la distribución de \\(Z_n\\) se acerca a la distribución normal estándar a medida que \\(n\\) tiende a infinito.\n\nPrueba. Vea Wackerly et al. (2009).",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estadística</span>"
    ]
  },
  {
    "objectID": "estadistica.html#datos-multivariados",
    "href": "estadistica.html#datos-multivariados",
    "title": "3  Estadística",
    "section": "3.2 Datos multivariados",
    "text": "3.2 Datos multivariados\n\nCuando dos o más variables aleatorias son observadas en miembros de una muestra aleatoria, los datos resultantes se denominan datos multivariados. El caso especial de dos variables se refiere como datos bivariados.\n\n\n\n\n\n\n\nEjemplo (Calificaciones finales)\n\n\n\n\n\nConsidere los datos en la Tabla 3.1 que representan una muestra de 30 estudiantes en una universidad grande que fueron asignados al azar a un curso de Introducción a la Informática. En la Tabla se muestran las puntuaciones del cuestionario, además de la calificación del examen final de cada estudiante.\n\n\n\nTabla 3.1: Puntuaciones y calificación final.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEst.\nPuntuación\nFinal\nEst.\nPuntuación\nFinal\nEst.\nPuntuación\nFinal\n\n\n\n\n1\n7.4\n79.8\n11\n7.6\n80.7\n21\n8.0\n84.2\n\n\n2\n8.4\n82.0\n12\n8.8\n94.5\n22\n9.0\n87.8\n\n\n3\n8.8\n76.1\n13\n6.1\n50.1\n23\n8.9\n94.1\n\n\n4\n6.4\n62.7\n14\n7.2\n68.3\n24\n7.5\n78.2\n\n\n5\n10.0\n98.2\n15\n6.6\n64.4\n25\n5.5\n62.4\n\n\n6\n5.5\n43.0\n16\n7.0\n67.2\n26\n8.5\n85.1\n\n\n7\n7.3\n76.5\n17\n5.3\n53.9\n27\n7.4\n77.8\n\n\n8\n5.9\n61.4\n18\n7.9\n78.8\n28\n6.3\n67.6\n\n\n9\n7.1\n78.5\n19\n8.1\n85.7\n29\n7.7\n70.2\n\n\n10\n7.9\n88.7\n20\n7.6\n81.7\n30\n6.9\n73.6\n\n\n\n\n\n\n\n\nSuma\n222.6\n2253.2\n\n\n\n\n\n\nLos valores medios y las desviaciones estándar se proporcionan a continuación. Las puntuaciones del cuestionario están en el vector \\(x\\) y las puntuaciones del examen final están en \\(y\\). Se tienen los siguientes resultados:\n\n\nMedia(x) = 7.42\n\n\nDesviación estándar(x) = 1.15\n\n\nMedia(y) = 75.11\n\n\nDesviación estándar(y) = 13.15\n\n\nLos histogramas de estas dos variables se muestran en la Figura 3.1. Allí se puede observar que los histogramas de ambas variables tienen una forma aproximadamente en campana, con las puntuaciones del examen final ligeramente sesgadas hacia la izquierda. Al examinar el histograma en la Figura 3.1(b), se observa que la media de las puntuaciones del examen final parece ser de alrededor de 75, lo cual es coherente con los resultados anteriores. La mayoría de las puntuaciones están entre 60 y 90, con algunas por encima de 90 y algunas por debajo de 60.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 3.1: Puntajes y calificaciones finales para una muestra aleatoria de 30 estudiantes inscritos al curso.\n\n\n\n\n\n\n\nLos histogramas, las medias y las desviaciones estándar no proporcionan información sobre cómo dos variables están relacionadas entre sí. Como ejemplo, un instructor probablemente quisiera saber si los estudiantes que les fue bien en el cuestionario también tendieron a desempeñarse bien en el examen final, y viceversa. También podría querer saber si algunos estudiantes que les fue mal en el cuestionario mejoraron drásticamente su calificación en el examen final. Los histogramas y las estadísticas de muestra mostrados anteriormente no responden a estas preguntas.\nLo que se necesita son medidas de la relación entre las dos variables. Los parámetros poblacionales más comunes utilizados para medir tales relaciones son la covarianza, \\(\\gamma_{XY}\\), y la correlación, \\(\\rho_{XY}\\).\n\n\nDefinición 3.15 (Covarianza) Si \\(X\\) e \\(Y\\) son dos variables aleatorias definidas en el mismo espacio de probabilidad, la covarianza de \\(X\\) e \\(Y\\), denotada como \\(\\mathrm{Cov}[X,Y]\\) o \\(\\gamma_{XY}\\), se define como \\[\\gamma_{XY}=\\mathrm{Cov}[X,Y]=\\mathrm E[(X-\\mu_X)(Y-\\mu_Y)]\\] siempre que la esperanza indicada exista.\n\n\nDefinición 3.16 (Correlación) La correlación, denotada como \\(\\rho[X,Y]\\) o \\(\\rho_{XY}\\), de las variables aleatorias \\(X\\) e \\(Y\\), se define como\n\\[ \\rho_{XY}=\\frac{\\gamma_{XY}}{\\sigma_X \\sigma_Y} \\]\nsiempre que \\(\\gamma_{XY}, \\sigma_X\\) y \\(\\sigma_Y\\) existan, con \\(\\sigma_X, \\sigma_Y&gt;0\\).\n\n\nTécnicamente, la covarianza es el valor esperado (o promedio teórico) del producto cruzado \\((X-\\mu_X)(Y-\\mu_Y)\\). Es una medida de cómo dos variables “se mueven juntas”. Para facilitar la interpretación, generalmente se usa la correlación, que es una versión “estandarizada” de la covarianza que tiene la propiedad \\(-1 \\leq \\rho_{XY}\\leq 1\\) para cualquier par de variables aleatorias \\(X\\) e \\(Y\\).\n\n\nObservación. \n\n\\(\\gamma_{XX}=\\mathrm E[(X-\\mu_X)(X-\\mu_X)]=\\mathrm E[(X-\\mu_X)^2]=\\sigma_X^2\\).\n\\(\\rho_{XX}=\\frac{\\sigma_X^2}{\\sigma_X \\sigma_X}=1\\).\n\n\n\nCorolario 3.1 Si \\(X\\) e \\(Y\\) son independientes, entonces \\(\\gamma_{XY}=0\\).\n\nPrueba. Observe que\n\\[ \\begin{split}\\mathrm{Cov}[X,Y]=\\mathrm E[(X-\\mu_X)(Y-\\mu_Y)]=\\mathrm E[X-\\mu_X]\\mathrm E[Y-\\mu_Y]=0\\end{split} \\]\nYa que \\(\\mathrm E[(X-\\mu_X)]=0\\).\n\n\n\nTeorema 3.5 Sean \\(X\\) e \\(Y\\) variables aleatorias definidas sobre el mismo espacio de probabilidad tal que \\(E(X^2) &lt; \\infty\\) y \\(E(Y^2) &lt; \\infty\\). Entonces:\n\n\\(\\mathrm{Cov}[X, Y]= \\mathrm{E}[XY]-\\mathrm{E}[X]\\mathrm{E}[Y]\\).\n\\(\\mathrm{Cov}[X, Y]= \\mathrm{Cov}[Y,X]\\).\n\\(\\mathrm{Var}[X]= \\mathrm{Cov}[X,X]\\).\n\\(\\mathrm{Cov}[aX+b, Y]= a\\mathrm{Cov}[X, Y]\\) para cualquier \\(a,b \\in\\mathbb{R}\\).\n\n\nPrueba. Vea Castañeda, Arunachalam, y Dharmaraja (2014).\n\n\n\nDefinición 3.17 (Variables aleatorias no correlacionadas) Las variables aleatorias \\(X\\) e \\(Y\\) se definen como no correlacionadas si y solo si \\(\\mathrm{Cov}[X,Y]=0\\).\n\n\nObservación. La afirmación contraria al corolario anterior no siempre es cierta; es decir, \\(\\mathrm{Cov}[X,Y]=0\\) no siempre implica que \\(X\\) e \\(Y\\) sean independientes.\n\n\n\n\n\nCastañeda, L. B., V. Arunachalam, y S. Dharmaraja. 2014. Introduction to Probability and Stochastic Processes with Applications. Wiley. https://books.google.com.mx/books?id=M0hYBAAAQBAJ.\n\n\nMann, P. S. 2010. Introductory Statistics. John Wiley & Sons. https://books.google.com.mx/books?id=N_mEBiCYaqkC.\n\n\nMood, A. M. F., F. A. Graybill, y D. C. Boes. 1986. Introduction to the Theory of Statistics. McGraw-Hill series en Probability y Statistics. https://books.google.com.mx/books?id=bKHBjgEACAAJ.\n\n\nWackerly, D. D., D. D. Wackerly, W. Mendenhall, y R. L. Scheaffer. 2009. Estadı́stica Matemática Con Aplicaciones. CENGAGE Learning. https://books.google.com.mx/books?id=8bTfwAEACAAJ.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estadística</span>"
    ]
  },
  {
    "objectID": "procesos.html",
    "href": "procesos.html",
    "title": "4  Procesos estocásticos",
    "section": "",
    "text": "Los procesos estocásticos desempeñan un papel fundamental en la modelización y análisis de una amplia gama de fenómenos en diversas disciplinas, desde la física hasta la economía. Estos procesos son esenciales para comprender y predecir el comportamiento de sistemas que involucran aleatoriedad y variabilidad en el tiempo.\nUn proceso estocástico (o probabilístico) puede considerarse una generalización de una muestra aleatoria, en el sentido de que las variables aleatorias no son necesariamente independientes y su distrbución podría cambiar. (Castañeda, Arunachalam, y Dharmaraja 2014) proporciona la siguiente definición para proceso estocástico.\n\n\nDefinición 4.1 (Proceso estocástico) Un proceso estocástico real es una colección de variables aleatorias \\(\\{X_t; t\\in T\\}\\) definida en un espacio de probabilidad común \\((\\Omega, \\mathfrak{F}, P)\\) con valores en \\(\\mathbb{R}\\). \\(T\\) se le llama al conjunto índice del proceso o espacio paramétrico, que generalmente es un subconjunto de \\(\\mathbb R\\). El conjunto de valores que la variable aleatoria \\(X_t\\) puede tomar se denomina espacio de estado del proceso y es denotado por \\(S\\).\n\n\nDe la definición anterior se entiende que las variables dependerán del parámetro \\(t\\) (usualmente el tiempo) y están ordenadas. Además el conjunto \\(T\\) puede ser discreto o continuo. Si el conjunto de índices \\(T\\) es discreto, se le conoce como proceso estocástico de tiempo discreto mientras que si \\(T\\) es continuo, se le conoce como proceso estocástico de tiempo continuo. Las variables aleatorias \\(X_t\\) pueden tomar tanto valores continuos o valores discretos. Note que si se fija un punto \\(t\\), se tiene \\(X_t\\) una variable aleatoria (Ross 1995).\n\n\nDefinición 4.2 (Trayectoria) La asignación definida para cada \\(\\omega\\in\\Omega\\) fijo, \\[\\begin{split}X(\\omega): & T\\to S\\\\ &t\\mapsto X_t(\\omega)\\end{split}\\] se denomina una trayectoria de muestra del proceso a lo largo del tiempo o una realización del proceso estocástico.\n\n\nDefinición 4.3 (Proceso completamente específicado) Se dice que un proceso estocástico \\(\\{X(t):t\\in T\\}\\) está completamente especificado si para cualquier valor del tiempo \\(t_1&lt;t_2&lt;\\cdots&lt;t_n\\) con \\(n\\in\\mathbb N\\), la distribución conjunta de \\((X_{t_1}, X_{t_2},\\cdots,X_{t_n})\\) es conocida.\n\n\nDefinición 4.4 (Proceso estocástico con incrementos independientes) Si, para todo \\(t_0,t_1,t_2,\\ldots,t_n\\) tal que \\(t_0&lt;t_1&lt;t_2&lt;\\cdots&lt;t_n\\), las variables aleatorias \\(X_{t_0}, X_{t_1}-X_{t_0}, X_{t_2}-X_{t_1},\\ldots,X_{t_n}-X_{t_{n-1}}\\) son independientes (o de manera equivalente, \\(X_{t+\\tau}-X_\\tau\\) es independiente de \\(X_s\\) para \\(s&lt; \\tau\\)), entonces se dice que el proceso \\(\\{X_t; t\\in T\\}\\) es un proceso con incrementos independientes.\n\n\nObservación. No resulta pertinente afirmar que \\(X_{t_1}\\) sea inferior a \\(X_{t_2}\\) dado que las variables aleatorias no se encuentran ordenadas.\n\n\nDefinición 4.5 (Proceso estocástico con incrementos estacionarios) Se dice que un proceso estocástico \\({X_t; t\\in T}\\) tiene incrementos estacionarios si \\(X_{t_2+\\tau}-X_{t_1+\\tau}\\) tiene la misma distribución que \\(X_{t_2}-X_{t_1}\\) para todas las elecciones de \\(t_1,t_2\\) y \\(\\tau&gt;0\\).\n\n\nDefinición 4.6 (Proceso estacionario) Si para cualquier conjunto de \\(t_1, t_2, \\ldots , t_n\\) arbitrarios, tal que \\(t_1&lt; t_2 &lt; \\cdots &lt; t_n\\), las distribuciones conjuntas de las variables aleatorias vectoriales \\((X_{t_1}, X_{t_2},\\ldots, X_{t_n})\\) y \\((X_{t_1+h}, X_{t_2+h},\\ldots , X_{t_n+h})\\) son iguales para todo \\(h &gt; 0\\), entonces se dice que el proceso estocástico \\(\\{X_t, t \\in T\\}\\) es un proceso estacionario estocástico de orden \\(n\\) (o simplemente un proceso estacionario). El proceso estocástico \\(\\{X_t, t \\in T\\}\\) se dice que es un proceso estocástico fuertemente estacionario o estrictamente estacionario si la propiedad anterior se cumple para todo \\(n\\).\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\nSuponga que \\(\\{X_n; n \\geq 1\\}\\) es una secuencia de variables aleatorias independientes e idénticamente distribuidas. Se define la secuencia \\(\\{Y_n, n \\geq 1\\}\\) como\n\\[\nY_n=X_n+aX_{n-1}\n\\]\ndonde \\(a\\) es una constante real. Entonces, es fácil observar que \\(\\{Y_n; n \\geq 1\\}\\) es estrictamente estacionaria.\n\n\n\n\n\nDefinición 4.7 (Proceso de segundo orden) Un proceso estocástico \\(\\{X_t; t\\in T\\}\\) se dice un proceso de segundo orden si\n\\[\n\\mathrm{E}((X_t)^2)&lt; \\infty\n\\]\npara todo \\(t\\in T\\).\n\n\nDefinición 4.8 (Proceso estacionario por covarianza) Un proceso estocástico de segundo orden \\(\\{X_t, t \\in T\\}\\) se denomina estacionario por covarianza o estacionario débil si su función de media \\(m(t) = \\mathrm{E}[X_t]\\) es independiente de \\(t\\) y su función de covarianza \\(\\mathrm{Cov}(X_s, X_t)\\) depende únicamente de la diferencia \\(|t - s|\\) para todos \\(s, t \\in T\\). Es decir:\n\\[\n\\mathrm{Cov}(X_s,X_t)=f(|t-s|).\n\\]\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\nSea \\(\\{X_n; n \\geq 1\\}\\) un conjunto de variables aleatorias no correlacionadas con media cero y varianza uno. Entonces, la covarianza \\(\\mathrm{Cov}(X_m, X_n) = \\mathrm{E}(X_mX_n)\\) es igual a \\(0\\) si \\(m \\ne n\\) y \\(1\\) si \\(m = n\\). Esto demuestra que \\(\\{X_n, n \\ge 1\\}\\) es un proceso estacionario por covarianza.\n\n\n\n\nDefinición 4.9 (Proceso evolutivo) Un proceso estocástico que no es estacionario (en ningún sentido), se dice ser un proceso estocástico evolutivo.\n\n\n\n\n\nCastañeda, L. B., V. Arunachalam, y S. Dharmaraja. 2014. Introduction to Probability and Stochastic Processes with Applications. Wiley. https://books.google.com.mx/books?id=M0hYBAAAQBAJ.\n\n\nRoss, S. M. 1995. Stochastic Processes. Wiley series en probability y mathematical statistics. Wiley. https://books.google.com.mx/books?id=qiLdCQAAQBAJ.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Procesos estocásticos</span>"
    ]
  },
  {
    "objectID": "series.html",
    "href": "series.html",
    "title": "5  Series de Tiempo",
    "section": "",
    "text": "5.1 Conceptos básicos y manipulación de series de tiempo",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Series de Tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#conceptos-básicos-y-manipulación-de-series-de-tiempo",
    "href": "series.html#conceptos-básicos-y-manipulación-de-series-de-tiempo",
    "title": "5  Series de Tiempo",
    "section": "",
    "text": "Definición 5.1 (Serie de tiempo) Un proceso estocástico \\(X(t); t\\in T\\) se define como una colección de variables aleatorias, donde \\(T\\) es un conjunto de índices para el cual todas las variables aleatorias, \\(X(t)\\), donde \\(t\\) pertenece a \\(T\\), están definidas en el mismo espacio muestral. Cuando \\(T\\) representa el tiempo, se hace referencia al proceso estocástico como una serie de tiempo.\n\n\nSi \\(T\\) toma un rango continuo de valores (por ejemplo, \\(T=(-\\infty,\\infty)\\) o \\(T=(0,\\infty)\\)) , el proceso se dice que es un proceso de parámetro continuo. Si, por otro lado, \\(T\\) toma un conjunto discreto de valores (por ejemplo, \\(T = \\{0, 1, 2,\\ldots\\}\\) o \\(T = \\{0, \\pm 1, \\pm 2,\\ldots \\}\\)), el proceso se dice que es un proceso de parámetro discreto. De hecho, es común referirse a estos como procesos continuos y discretos, respectivamente.\nSe utilizará la notación de subíndice, \\(X_t\\), cuando se esté tratando específicamente con un proceso de parámetro discreto. Sin embargo, cuando el proceso involucrado sea de parámetro continuo o de tipo no especificado, se utilizará la notación de función, \\(X(t)\\). Además, cuando no haya confusión, a menudo se utiliza la notación \\(\\{X(t)\\}\\) o simplemente \\(X(t)\\) para denotar una serie de tiempo. De manera similar, a menudo se acortará \\(\\{X_t;t=0,\\pm 1,\\ldots \\}\\) a \\(X_t,t=\\{0,\\pm 1,\\ldots\\}\\) o simplemente se usará \\(X_t\\).\nNótese que una variable aleatoria, \\(\\gamma\\) , es una función definida en un espacio muestral \\(\\Omega\\) cuyo rango son los números reales. Un valor observado de la variable aleatoria \\(\\gamma\\) es un número real \\(y=\\gamma(\\omega)\\) para algún \\(\\omega\\in\\Omega\\). Para una serie de tiempo \\(\\{X(t)\\}\\), su “valor” \\(\\{X(t,\\omega);t\\in T\\}\\) para algún \\(\\omega\\in\\Omega\\) fijo es una colección de números reales. Esto lleva a la siguiente definición.\n\n\nDefinición 5.2 (Realización) Una realización de la serie de tiempo \\(\\{X(t);t\\in T\\}\\) es el conjunto de resultados de valores reales, \\(\\{X(t,\\omega);t\\in T\\}\\) para un valor fijo de \\(\\omega \\in \\Omega\\).\n\n\nLa colección de todas las posibles realizaciones se denomina conjunto, y, para un valor dado de \\(t\\), la expectativa de la variable aleatoria \\(X(t)\\) se denomina media del conjunto y se denotará como \\(\\mathrm E[X(t)]=\\mu(t)\\) . La varianza de \\(X(t)\\) se expresa como\n\\[\n\\mathrm{Var}[X(t)]:=\\mathrm{E}[(X(t)-\\mu(t))^2]\n\\]\ny a menudo se denota como \\(\\sigma^2(t)\\) ya que también puede depender de \\(t\\).\n\n\nDe especial interés en el análisis de una serie temporal es la covarianza entre \\(X(t_1)\\) y \\(X(t_2)\\), donde \\(t_1, t_2\\in T\\). Dado que esta es la covarianza (Definición 3.15) dentro de la misma serie temporal, se refiere a ella como autocovarianza. De igual manera, se refiere a correlación (Definición 3.16) como autocorrelación y se denotan por\n\\[\n\\gamma(t_1,t_2):=\\mathrm{E}[(X(t_1)-\\mu(t_1))(X(t_2)-\\mu(t_2))]\n\\tag{5.1}\\]\ny\n\\[\n\\rho(t_1,t_2):= \\frac{\\gamma(t_1,t_2)}{\\sigma(t_1)\\sigma(t_2)}\n\\tag{5.2}\\]\nrespectivamente.\n\n\n5.1.1 Series de tiempo estacionarias\n\nEn el estudio de una serie de tiempo, es común que solo se tenga disponible una única realización de la serie. El análisis de una serie temporal basado únicamente en una realización es análogo a analizar las propiedades de una variable aleatoria en función de una sola observación. Los conceptos de estacionariedad y ergodicidad jugarán un papel importante en mejorar la capacidad de análisis de una serie temporal basada en una única realización de manera efectiva. Un proceso se considera estacionario si está en un estado de “equilibrio estadístico”. El comportamiento básico de dicha serie de tiempo no cambia con el tiempo. Como ejemplo, para dicho proceso, \\(\\mu(t)\\) no dependería del tiempo y, por lo tanto, podría ser denotado como \\(\\mu\\) para todo \\(t\\). Parecería que, dado que \\(x(t)\\) para cada \\(t\\in T\\) proporciona información sobre la media del conjunto, \\(\\mu\\), podría ser posible estimar \\(\\mu\\) en función de una única realización. Un proceso ergódico es aquel para el cual promedios de conjunto como \\(\\mu\\) pueden estimarse consistentemente a partir de una sola realización. En esta sección, se presentarán definiciones más formales de estacionariedad. La noción más restrictiva de estacionariedad es la de estacionariedad estricta, que se define de la siguiente manera.\n\n\nDefinición 5.3 (Proceso estrictamente estacionario) Se dice que un proceso \\(\\{X(t); t \\in T\\}\\) es estrictamente estacionario si para cualquier \\(t_1, t_2,\\ldots, t_k \\in T\\) y cualquier \\(h \\in T\\), la distribución conjunta de \\(\\{X(t_1), X(t_2),\\ldots , X(t_k)\\}\\) es idéntica a la de \\(\\{X(t_1 + h), X(t_2 + h),\\ldots, X(t_k + h)\\}\\).\n\n\nLa estacionariedad estricta requiere, entre otras cosas, que para cualquier \\(t_1, t_2 \\in T\\), las distribuciones de \\(X(t_1)\\) y \\(X(t_2)\\) deben ser las mismas, y además que todas las distribuciones bivariadas de pares \\(\\{X(t), X(t + h)\\}\\) sean iguales para todos los \\(h\\), etc. El requisito de estacionariedad estricta es riguroso y suele ser difícil de establecer matemáticamente. De hecho, para la mayoría de las aplicaciones, las distribuciones involucradas no se conocen. Por esta razón, se han desarrollado nociones menos restrictivas de estacionariedad. La más común de ellas es la estacionariedad por covarianza.\n\n\nDefinición 5.4 (Estacionariedad por covarianza) La serie de tiempo \\(\\{X(t); t \\in T\\}\\) se considera estacionaria por covarianza si\n\n\\(\\mu_{_{X_t}}=\\mathrm E[X(t)] = \\mu\\) (media constante para todo \\(t\\))\n\\(\\sigma^2_{_{X_t}}=\\mathrm{Var}[X(t)] = \\sigma^2 &lt; \\infty\\) (es decir, una constante finita para todo \\(t\\))\n\\(\\gamma_{_{X_{t_1},X_{t_2}}}\\) y \\(\\rho_{_{X_{t_1},X_{t_2}}}\\) depende solo de \\(t_2 − t_1\\).\n\n\n\nSi se cumple la condición iii., no habrá confusión al reemplazar la notación, \\(\\gamma_{_{X_{t_1},X_{t_2}}}\\), con \\(\\gamma_{_{t_1-t_2}}\\), y de manera similar, al denotar \\(\\rho_{_{X_{t_1},X_{t_2}}}\\) como \\(\\rho_{_{t_1-t_2}}\\). Cuando se establece \\(t_2-t_1=k\\), se hace referencia a \\(\\gamma_{_k}\\) y \\(\\rho_{_k}\\) como la autocovarianza y la autocorrelación con un rezago de \\(k\\), respectivamente.\nLa función de autocovarianza de una serie de tiempo estacionaria satisface las siguientes propiedades:\n\n\\(\\gamma_{_0}=\\mathrm E[(X_{t}-\\mu)(X_{t}-\\mu)]=\\mathrm E[(X_{t}-\\mu)^2]=\\sigma^2\\).\n\\(|\\gamma_{_k}|\\leq \\gamma_{_0}\\) para todo \\(k\\).\n\\(\\gamma_{_k}=\\mathrm{E}[(X_{t-k}-\\mu)(X_t-\\mu)]=\\mathrm{E}[(X_t-\\mu)(X_{t-k}-\\mu)]=\\gamma_{_{-k}}\\).\nLa función \\(\\gamma_{_k}\\) es semidefinida positiva. Esto es, para cualquier conjunto de puntos de tiempo \\(t_1, t_2,\\ldots,t_k\\in T\\) y para los reales \\(b_1,b_2,\\ldots, b_k\\), se tiene\n\\[\\sum_{i=1}^k \\sum_{j=1}^k \\gamma(t_i-t_j)b_i b_j\\geq 0.\n\\]\n\nLa función de autocorrelación satisface las siguientes propiedades análogas:\n\n\\(\\rho_{_0} = 1\\).\n\\(|\\rho_{_k}|\\leq 1\\) para todo \\(k\\).\n\\(\\rho_{_k}=\\rho_{_{-k}}\\).\nLa función \\(\\rho_{_k}\\) es semidefinida positiva, y para series de tiempo discretas definidas en \\(t = 0, 1, 2,\\ldots\\), la matriz\n\\[\n\\boldsymbol{\\rho}_k = \\begin{pmatrix}1 & \\rho_1 & \\ldots & \\rho_{_k}\\\\\n\\rho_1 & 1 & \\ldots & \\rho_{k-1}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n\\rho_{_k} & \\rho_{k+1}&\\ldots & 1\\end{pmatrix}\n\\]\nes semidefinida positiva para cada \\(k\\).\n\n\n\nObservación. La estacionariedad por covarianza también se conoce como estacionariedad débil, estacionariedad en el sentido amplio y estacionariedad de segundo orden. En el resto de esta tesis, a menos que se especifique lo contrario, el término estacionariedad se referirá a la estacionariedad por covarianza.\n\n\nEn las series de tiempo, al igual que en la mayoría de las otras áreas de la estadística, los datos no correlacionados desempeñan un papel importante. No hay dificultad en definir dicho proceso en el caso de una serie temporal de parámetro discreto. Es decir, la serie temporal \\(\\{X_t; t = 0, \\pm 1, \\pm 2,\\ldots\\}\\) se llama “proceso puramente aleatorio” si los \\(X_t\\) son variables aleatorias no correlacionadas. Al considerar procesos puramente aleatorios, solo nos interesará el caso en el que los \\(X_t\\) también estén distribuidos de manera idéntica. En esta situación, es más común referirse a la serie de tiempo como ruido blanco. La siguiente definición resume estas observaciones.\n\n\nDefinición 5.5 (Proceso de ruido blanco) Se dice que un proceso \\(X_t\\) es ruido blanco si se cumplen las siguientes condiciones.\n\nLos \\(X_t\\) están distribuidos de manera idéntica.\n\\(\\gamma_{_{t_2-t_1}} = 0\\) cuando \\(t_2 \\ne t_1\\).\n\\(\\gamma_{_{t-t}} = \\sigma^2\\), donde \\(0 &lt; \\sigma^2 &lt; \\infty\\) .\n\n\n\nEn un proceso de ruido blanco, cada observación está no correlacionada con todas las demás observaciones. Un hecho importante es que los procesos de ruido blanco son estacionarios.\n\n\n5.1.1.1 Estimación de los parámetros de un proceso estacionario.\n\n5.1.1.1.1 Estimación de \\(\\mu\\).\n\nDada la realización \\(\\{x_t, t = 1, 2,\\ldots , n\\}\\) de una serie temporal estacionaria, la estimación natural de la media común \\(\\mu\\) es la media muestral.\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{t=1}^n x_t\n\\tag{5.3}\\]\nEs evidente que el estimador \\(\\bar{X}\\) es imparcial para \\(\\mu\\).\nPara una serie temporal estacionaria, se puede emplear los datos a lo largo del tiempo para estimar la media, dado que se asume que la media es constante para cada instante de tiempo, \\(t\\).\n\n\n5.1.1.1.1.1 Ergodicidad de \\(X\\).\n\nSe dice que \\(X\\) es ergódico para \\(\\mu\\) si \\(X\\) converge en el sentido de la media cuadrática hacia \\(\\mu\\) a medida que \\(n\\) aumenta, es decir, si \\(\\lim\\limits_{n\\to\\infty}\\mathrm{E}[(\\bar X -\\mu)^2]=0\\).\n\n\nTeorema 5.1 Sea \\(\\{X_t; t=0,\\pm 1,\\pm 2, \\ldots\\}\\) una serie de tiempo estacionaria. Entonces, \\(\\bar X = \\frac{1}{n}\\sum\\limits_{t=1}^n X_t\\) es ergódica para \\(\\mu\\) si y solo si\n\\[\n\\lim\\limits_{k\\to \\infty} \\frac{1}{k} \\sum_{j=0}^{k-1} \\gamma_j =0.\n\\tag{5.4}\\]\n\nPrueba. Vea Yaglom (1962).\n\n\n\nCorolario 5.1 Sea \\(X_t\\) es una serie de tiempo estacionaria con parámetros discretos, como se establece en el Teorema 5.1 . Entonces, \\(\\bar X\\) es ergódico para \\(\\mu\\) si\n\\[\n\\lim\\limits_{k\\to\\infty} \\gamma_{_k}=0,\n\\tag{5.5}\\]\no equivalentemente si\n\\[\n\\lim\\limits_{k\\to\\infty} \\rho_{_k}=0.\n\\tag{5.6}\\]\n\n\nLa condición suficiente para la ergodicidad de \\(\\bar X\\), dada en el Corolario 5.1 , resulta muy útil y es una condición que se cumple para la amplia clase de series temporales autorregresivas de media móvil, ARMA\\((p,q)\\) , estacionarias, que se discutirán más adelante. A pesar de que \\(X_t\\)’s “cercanos” en el tiempo pueden tener una correlación sustancial, la condición en el Corolario 5.1 asegura que para una “gran” separación, están casi no correlacionados.\n\n\n\n5.1.1.1.1.2 Varianza de \\(\\bar X\\).\n\nAntes de abandonar el tema de estimar \\(\\mu\\) a partir de una realización de un proceso estacionario, en el Teorema 5.2 se proporciona una fórmula útil para la Varianza de \\(\\bar X\\).\n\nTeorema 5.2 Si \\(X_t\\) es una serie de tiempo estacionaria, entonces la varianza de \\(\\bar X\\) basada en una realización de longitud \\(n\\) está dada por\n\\[\n\\mathrm{Var}(\\bar X)=\\frac{\\sigma_X^2}{n}\\left(1+2\\sum_{k=1}^{n-1}\\left(1-\\frac{|k|}{n}\\right)\\rho_{_k}\\right)\n\\tag{5.7}\\]\n\n\n\nEl resultado en la Ecuación 5.7 muestra el efecto de la autocorrelación en la varianza de \\(\\bar X\\), y si \\(X_t\\) es ruido blanco, es decir, \\(\\gamma_{_{k}} = 0\\) si \\(k \\ne 0\\), entonces la Ecuación 5.7 se convierte en el conocido resultado \\(Var(\\bar X) = \\sigma^2/n\\).\nUtilizando la notación \\(\\hat \\rho_{_k}\\) para denotar las autocorrelaciones estimadas (muestra) y \\(\\hat\\sigma^2=\\hat{\\gamma_0}\\) para denotar la varianza muestral, es práctica común obtener intervalos de confianza aproximados del \\(95\\%\\) para \\(\\mu\\) usando\n\\[\n\\left(\\bar X- 1.96\\sqrt{\\frac{\\hat\\sigma^2}{n}\\sum_{k=-(n-1)}^{n-1}\\left(1-\\frac{|k|}{n}\\right)\\hat\\rho_{_k}}, \\bar X+ 1.96\\sqrt{\\frac{\\hat\\sigma^2}{n}\\sum_{k=-(n-1)}^{n-1}\\left(1-\\frac{|k|}{n}\\right)\\hat\\rho_{_k}}\\right).\n\\tag{5.8}\\]\n\n\n\n\n5.1.1.1.2 Estimación de \\(\\gamma_{_k}\\).\n\nDebido a la estacionariedad, \\(\\mathrm E[(X_t − \\mu)(X_{t+k} − \\mu)] = \\gamma_{_k}\\) no depende de \\(t.\\) Como consecuencia, parece razonable estimar \\(\\gamma_{_k}\\) a partir de una sola realización, por\n\\[\n\\begin{split}\\hat{\\gamma}_{_k}&= \\frac{1}{n}\\sum_{t=1}^{n-k}(X_t-\\bar X)(X_{t+k}-\\bar X), \\quad 0\\leq k\\leq n\\\\\n&=0,\\qquad k\\ge n\\\\\n&=\\hat{\\gamma}_{_{-k}},\\quad k&lt;0\\end{split}\n\\tag{5.9}\\]\n\n\nObservación. Usando Ecuación 5.9 se deduce que\n\\[\n\\hat{\\gamma}_{_0}= \\frac{1}{n}\\sum_{t=1}^{n}(X_t-\\bar X)^2\n\\tag{5.10}\\]\n\n\n\n5.1.1.1.3 Estimación de \\(\\rho_{_k}\\).\n\nDefinición 5.6 (Autocorrelación muestral) El estimador de la autocorrelación, \\(\\rho_{_{k}}\\) se obtiene mediante\n\\[\n\\hat\\rho_{_{k}}=\\hat\\gamma_{_{k}}/\\hat\\gamma_{_{0}}\n\\tag{5.11}\\]\nA este estimador se le conoce como la autocorrelación muestral.\n\n\nA partir del examen de la Ecuación 5.9 , es evidente que los valores de \\(\\hat\\gamma_{_{k}}\\) (y \\(\\hat\\rho_{_{k}}\\)) tenderán a ser “pequeños” cuando \\(k\\) sea grande en relación con \\(n\\).\n\n\n\n\n\n5.1.2 Conjuntos de datos de series temporales.\n\nLos comportamientos exhibidos por los datos de series temporales son diversos y se analizarán en las secciones subsiguientes. Dichos tipos de comportamiento se ilustrarán mediante ejemplos provenientes de la realidad, tales como los datos intrigantes de manchas solares, registros de temperatura, el índice Dow Jones, precios de acciones individuales, datos de ventas (tanto mensuales como diarios), entre otros. El análisis comenzará con una discusión sobre datos que presenten algún tipo de patrón cíclico (Woodward, Sadler, y Robertson (2022)).\n\n\n5.1.2.1 Datos Cíclicos\n\nMuchos conjuntos de datos de series temporales muestran un patrón cíclico, lo que significa que los datos presentan aumentos y disminuciones de manera algo repetitiva. Estos datos a veces se denominan “pseudo-periódicos”, un término que usaremos de manera sinónima con “cíclico”. Los datos de manchas solares en la Figura 5.1 es un ejemplo de datos cíclicos.\n\nObservación. Los datos verdaderamente periódicos exhiben un comportamiento que se replica de manera precisa a lo largo de un período de tiempo establecido. Un caso ilustrativo de datos puramente periódicos se encuentra en la forma de la curva sinusoidal. De este modo, los datos pseudoperiódicos (o cíclicos) se refieren a aquellos conjuntos de datos que tienden a mostrar repeticiones en sus comportamientos.\n\n\n\nEjemplo 5.1  \n\n\n\n\n\n\nDatos de manchas solares\n\n\n\n\n\nLa Figura 5.1 muestra datos anuales de manchas solares para los años 1700-2020. Las manchas solares son áreas de explosiones solares o disturbios atmosféricos extremos en el sol. En 1848, el astrónomo suizo Rudolf Wolf introdujo un método para contar la actividad de las manchas solares, y los datos mensuales utilizando su método están disponibles desde 1749. (Waldmeier (1961)).\n\nCódigo\nlibrary(tswge)\nplot(sunspot2.0, xlab='Año', ylab='Manchas solares')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 5.1: Número anual de manchas solares desde 1700 hasta 2020.\n\n\n\nLas manchas solares han generado un considerable interés en la comunidad científica por dos razones principales:\n\nLa actividad de las manchas solares tiende a afectarnos aquí en la Tierra. Por ejemplo, una alta actividad de manchas solares provoca interferencias en la comunicación por radio y se asocia con una mayor intensidad de luz ultravioleta y actividad de auroras boreales.\nLa actividad de las manchas solares tiene un comportamiento cíclico que tiene una duración de ciclo de aproximadamente 11 años. Al examinar la Figura 5.1 se observa que hay 29 ciclos en los 321 años, con una duración media del ciclo de aproximadamente 11 años. De hecho, las duraciones de los ciclos tienden a variar aleatoriamente entre 9 y 13 años.\n\nSi bien el comportamiento cíclico en la Figura 5.1 es claro, a menudo es útil examinar fragmentos cortos de los datos para visualizar mejor el comportamiento específico. La Figura 5.2 muestra el número de manchas solares desde 1867 hasta 1950. Las líneas verticales identifican los años en los que hubo un pico en los números de manchas solares y las flechas horizontales representan el tiempo entre los picos. Para los años representados en la Figura 5.2, las duraciones de los ciclos fueron de 13, 10, 12, 12, 11, 9 y 10 años, respectivamente. Las duraciones de los ciclos parecen variar aleatoriamente y no parece haber un “ajuste a una duración de ciclo fija”. De hecho, según la comprensión de estos autores, los científicos no tienen una explicación física para el ciclo de aproximadamente 11 años. Los datos de las manchas solares son un ejemplo clásico de datos cíclicos con duraciones de ciclo variables. De hecho, Yule (1971) desarrolló el proceso autorregresivo como un medio para describir el comportamiento periódico “perturbado” de los datos de las manchas solares.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 5.2: Fragmento de la Figura 5.1 que muestra los años 1867-1950\n\n\n\n\n\n\n\n\nEjemplo 5.2  \n\n\n\n\n\n\nDatos de pasajeros aéreos\n\n\n\n\n\nLa Figura 5.3 es un conjunto de datos que contiene el número total (en miles) de pasajeros de líneas aéreas internacionales por mes durante los 12 años, desde 1949 hasta 1960. Estos datos han sido analizados exhaustivamente y son un conjunto de datos clásico en la literatura de series temporales. Los datos siguen un patrón cíclico de 12 meses que es similar de un año a otro y está basado en el año calendario. Por lo tanto, los datos de Pasajeros Aéreos son otro ejemplo de datos estacionales. Además, los datos tienden a mostrar una tendencia al alza con el tiempo. Es decir, el número de pasajeros de líneas aéreas está aumentando con el tiempo. El comportamiento de tendencia en series temporales se discutirá en la Sección 5.1.2.2. También hay una variabilidad creciente dentro del año. Este tipo de comportamiento, conocido como estacionalidad multiplicativa.\n\nCódigo\nlibrary(tswge)\nplot(AirPassengers, xlab='Año', ylab='Número de pasajeros')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 5.3: Número de Pasajeros Internacionales en Aerolíneas de 1949 a 1960\n\n\n\nLa Figura 5.4 muestra un fragmento de los datos de pasajeros aéreos desde 1957 hasta 1960. Se observa que el viaje aéreo es ligero desde Enero hasta Abril, aumenta durante los meses de verano y comienza a disminuir en septiembre hasta noviembre con un ligero aumento en diciembre. Este patrón, aunque no es sinusoidal, se repite de un año a otro. El comportamiento cíclico de los datos de pasajeros aéreos se repite anualmente y es un ejemplo de datos estacionales que no son seudosenoidales.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 5.4: Fragmento de la Figura 5.3 que muestra los años 1957-1960\n\n\n\n\n\n\n\n\n\n5.1.2.2 Tendencias\n\nUna tendencia en un contexto de análisis de datos se refiere a la inclinación de una serie de datos a experimentar un incremento o disminución constante a lo largo del tiempo. En el caso específico de los datos de Pasajeros Aéreos mostrados en la Figura 5.3, se identifica un patrón de crecimiento además del patrón estacional previamente observado. Una tendencia lineal se caracteriza por el aumento o la disminución de los datos de manera constante y progresiva, tal como se ilustra en la Figura 5.5 (a). Las tendencias pueden seguir una curva, como lo ejemplifica la tendencia exponencial en la Figura 5.5 (b). Por otro lado, la Figura 5.5 (c) exhibe una serie temporal con una tendencia descendente, pero su naturaleza es más irregular en comparación con las tendencias representadas en las Figuras (a) y (b). Un patrón común en conjuntos de datos es un comportamiento de tendencia aleatoria, como se muestra en la Figura 5.5 (d), la cual sugiere una trayectoria sin un rumbo definido. Esto implica que pueden existir tendencias de corta o larga duración, en ocasiones en direcciones opuestas.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Tendencia lineal\n\n\n\n\n\n\n\n\n\n\n\n(b) Tendencia exponencial\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Tendencia descendente\n\n\n\n\n\n\n\n\n\n\n\n(d) Comportamiento deambulante\n\n\n\n\n\n\n\nFigura 5.5: Gráficos que muestran (a) una tendencia lineal, (b) una tendencia exponencial, (c) una tendencia descendente irregular y (d) un patrón de deambulación.\n\n\n\n\nDefinición 5.7 La función \\(g(t)\\) es periódica con periodo (o longitud del ciclo) \\(p &gt; 0\\) si \\(p\\) es el valor más pequeño tal que \\(g(t) = g(t + kp)\\) para todo \\(t\\) y enteros \\(k\\). Se dice que una función \\(g(t)\\) es aperiódica si no existe tal \\(p\\).\n\n\nDefinición 5.8 (Frecuencia) La frecuencia, denotada por \\(f\\), puede ser descrita de las siguientes dos maneras;\n\n\\(f=1/\\text{periodo}\\) (tamaño del ciclo)\nEl número de ciclos en la función a través de una unidad de tiempo.\n\n\n\nObservación. Los datos con comportamiento de tendencia y deambulación aleatoria no son cíclicos por naturaleza. A veces se les llama aperiódicos debido a la ausencia de un comportamiento regular de ascenso y descenso.\n\n\n\n5.1.2.3 Definición y propiedades del espectro y densidad espectral\n\nDefinición 5.9 Sea \\(X_{_t}\\) una serie de tiempo estacionaria con autocovarianza \\(\\gamma_{_k}\\) y autocorrelación \\(\\rho_{_k}\\). Entonces para \\(|f|\\le 0.5\\):\n\nEl espectro de \\(X_{_t}\\) se define como\n\\[\nP_{_X}(f)=\\sum_{k=-\\infty}^\\infty e^{-2\\pi ifk}\\gamma_{_k}.\n\\tag{5.12}\\]\nLa densidad espectral de \\(X_{_t}\\) se define como\n\\[\nS_{_X}(f)=\\sum_{k=-\\infty}^\\infty e^{-2\\pi ifk}\\rho_{_k}.\n\\tag{5.13}\\]\n\n\n\nUsando la fórmula de Euler, se obtienen las fórmulas “más agradables”.\n\\[\nP_{_X}(f)=\\sigma_{_X}^2+2\\sum_{k=1}^\\infty\\gamma_{_k}\\cos(2\\pi fk)\n\\]\nY\n\\[\nS_{_X}(f)=1+2\\sum_{k=1}^\\infty \\rho_{_k}\\cos(2\\pi fk)\n\\]\nEstas fórmulas enfatizan que el espectro y la densidad espectral son funciones de valor real, lo que no es evidente en Ecuación 5.12 y Ecuación 5.13.\nPropiedades importantes de densidades espectrales\n\n\\(S_{_X}(f)\\geq 0\\).\n\\(S_{_X}(f)=S_{_X}(-f)\\).\n\\(S_{_X}(f)=1+2\\sum\\limits_{k=1}^\\infty \\rho_{_k}\\cos(2\\pi fk)\\), donde \\(|f|\\le 0.5\\) .\n\\(\\sum\\limits_{-0.5}^{0.5}S_{_X}(f)e^{2\\pi ifk}df=\\rho_{_k}\\)\nLas propiedades i y ii muestran que \\(S_{_X}(f)\\) es una función par no negativa.\n\n\n\n\n\n5.1.3 Suavizado de datos de series temporales.\n\nExisten varios métodos para “suavizar” el comportamiento ruidoso (posiblemente poco importante) de una serie temporal para que se pueda entender mejor una señal importante subyacente. Se comienza discutiendo el método de suavizado de promedio móvil centrado, que es el más básico.\n\n\n5.1.3.1 Suavizado de datos utilizando un suavizador de promedio móvil centrado\n\nEl suavizador de promedio móvil centrado es un método para reemplazar los valores de datos en una serie temporal con un promedio de los valores de datos que rodean (e incluyen) ese punto de datos. Por ejemplo, un suavizador de promedio móvil centrado de orden tres reemplaza un valor de datos \\(x_{_t}\\) en el tiempo \\(t\\) con \\(s_{_t} = (x_{_{t-1}}+x_{_t}+x_{_{t+1}})/3\\). Es decir, se asigna el valor promedio al punto de tiempo medio. Por lo tanto, un suavizador de promedio móvil centrado de orden tres no puede asignarse al primer o último punto de tiempo de una serie temporal. Se sigue que a mayor orden, más valores faltarán al principio y al final del conjunto de datos suavizado. Para un promedio móvil centrado de tercer orden, la fórmula de promediado se desplaza a lo largo del conjunto de datos de la serie temporal, considerando tres valores de datos consecutivos juntos hasta llegar a los últimos tres puntos temporales.\n\n\nDefinición 5.10 (Suavizador de Promedio Móvil Centrado) Sea \\(x_{_t}, t=1,\\ldots,n\\) un conjunto de datos de series temporales. El suavizador de promedio móvil centrado se define de la siguiente manera:\nCaso 1: \\(m\\) es un número impar\nSea \\(k= (m−1)/2\\). Para \\(k &lt;t&lt; n - k\\), el valor de los datos suavizados, \\(s_{_t}\\), en el tiempo \\(t\\) se da por\n\\[\ns_{_t}=\\frac{1}{m}\\sum_{i=t-k}^{t+k}x_{_i}\n\\tag{5.14}\\]\nCaso 2: \\(m\\) es un número par\nSea \\(k= m/2\\) Para \\(k &lt;t&lt; n - k\\), el valor de los datos suavizados, \\(s_{_t}\\), en el tiempo \\(t\\) se da por\n\\[\ns_{_t}= \\frac{x_{_{t-k}}}{2m}+\\frac{1}{m}\\sum_{i=t-k+1}^{t+k-1}x_{_i}+\\frac{x_{_{t+k}}}{2m}\n\\tag{5.15}\\]\n\n\n\n\n\n\n\nEjemplos\n\n\n\n\n\n\nPara un promedio móvil centrado de quinto orden en tiempos \\(2 &lt;t &lt; n -2\\) , se tiene\n\\[\ns_{_t}=(x_{_{t-2}}+x_{_{t-1}}+x_{_t}+x_{_{t+1}}+x_{_{t+2}})/5.\n\\]\nEl suavizador de promedio móvil de cuarto orden en tiempos \\(2 &lt;t &lt; n -2\\) , está dado por\n\\[\ns_{_t}=\\frac{x_{_{t-2}}}{8}+\\frac{x_{_{t-1}}+x_{_t}+x_{_{t+1}}}{4}+\\frac{x_{_{t+2}}}{8}\n\\]\n\nEl suavizador de promedio móvil centrado tiene dos usos básicos:\n\nSuavizado diseñado para eliminar fluctuaciones (potencialmente sin sentido) de los datos.\nEliminar el comportamiento cíclico de datos estacionales u otros datos cíclicos con longitudes de ciclo fijas.\n\n\n\n\n\nEl Ejemplo 5.3 muestra el uso del suavizado de promedio móvil centrado con el propósito de detectar o comprender mejor señales subyacentes y fundamentales en los datos.\n\nEjemplo 5.3  \n\n\n\n\n\n\nSuavizando los datos de temperatura de Tesla y DFW.\n\n\n\n\n\nLos precios de las acciones de Tesla desde el 1 de enero de 2020 hasta el 30 de abril de 2021 se muestran en la Figura 5.6 (a) . Se observa el hecho de que hubo un aumento constante hasta principios de 2021, momento en el cual el precio se estabilizó y disminuyó. Sin embargo, hay una considerable fluctuación de un día para otro, especialmente en 2021. La Figura 5.6 (d) muestra las temperaturas medias anuales de DFW (Dallas Ft. Worth) desde 1900 hasta 2020. Allí se observa una considerable fluctuación de un año a otro, pero algo de aumento a partir de aproximadamente 2000. La Figura 5.6 (b), (c), (e) y (f) muestran versiones suavizadas de las Figuras Figura 5.6 (a) y (d). Al utilizar el suavizador de promedio móvil centrado, las fluctuaciones de un día para otro se suavizan; se nota que el orden 8 produce más suavizado que el orden 3. El comportamiento fundamental, incluida la estabilización y disminución a principios de 2021, se ve con más claridad al minimizar los cambios ruidosos de un día para otro. El efecto del suavizado es más evidente en los datos de temperatura de DFW. La fluctuación de un año a otro es bastante dramática en el conjunto de datos original en la Figura 5.6 (d) . Un suavizado de orden 3 proporciona cierta claridad, pero el suavizado de orden 8 mostrado en la Figura 5.6 (e) muestra claramente un comportamiento casi estable desde 1900 hasta aproximadamente 1985. Desde entonces, ha habido un aumento que puede haberse estabilizado o no en los últimos años. Es particularmente notable en la Figura 5.6 (e) que el suavizado ha eliminado los extremos. Específicamente, las temperaturas extremadamente altas en 2012, 2016 y 2017 se ven moderadas por las temperaturas más bajas en los años circundantes. (Tomado de Woodward, Sadler, y Robertson (2022))\n\n\n\n\n\n\n\n\n\n\n\n(a) Precios de las acciones de Tesla\n\n\n\n\n\n\n\n\n\n\n\n(b) MA Smoother Tesla: Orden=3\n\n\n\n\n\n\n\n\n\n\n\n(c) MA Smoother Tesla: Orden=8\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Temperatura anual DFW\n\n\n\n\n\n\n\n\n\n\n\n(e) MA Smoother DFW: Orden=3\n\n\n\n\n\n\n\n\n\n\n\n(f) MA Smoother DFW: Orden=8\n\n\n\n\n\n\n\nFigura 5.6: Precios de las acciones de Tesla y datos de temperatura anual de DFW antes y después de aplicar suavizadores de promedio móvil de orden 3 y 8",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Series de Tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#análisis-y-técnicas-de-descomposición.",
    "href": "series.html#análisis-y-técnicas-de-descomposición.",
    "title": "5  Series de Tiempo",
    "section": "5.2 Análisis y técnicas de descomposición.",
    "text": "5.2 Análisis y técnicas de descomposición.\n\n5.2.1 Descomposición de datos estacionales\n\nEn el Ejemplo 5.2 se aborda la naturaleza de los datos estacionales, entendidos como una serie de datos cíclicos con periodos consistentes y un patrón que guarda relación con el calendario. El conjunto de datos de AirPassengers presentado en la Figura 5.3 se clasifica como un ejemplo paradigmático de datos estacionales. Este conjunto de datos exhibe un comportamiento estacional anual, además de una tendencia de crecimiento, que se aproxima a ser lineal. Es convencional considerar que los datos estacionales, denotados como \\(x_{_t}\\), comprenden:\n\nUn componente estacional intrínseco anual, identificado como \\(s_{_t}\\),\nUn componente de tendencia a largo plazo, referido como \\(tr_{_t}\\), y\nUn componente de variabilidad aleatoria, conocido como \\(z_{_t}\\).\n\nSe ha observado esta estructura en el conjuntos de datos ya mencionado. Los expertos en análisis de series temporales se enfocan en dos categorías de modelos estacionales:\nDatos estacionales aditivos\nLos datos \\(x_{_t}\\), en el tiempo \\(t\\) pueden ser consideramos como una suma dada en la Ecuación 5.16\n\\[\nx_{_t}=s_{_t}+tr_{_t}+z_{_t}.\n\\tag{5.16}\\]\nDatos estacionales multiplicativos\nLos datos, \\(x_{_t}\\), en el tiempo \\(t\\) pueden ser expresados como el producto dado en la Ecuación 5.17\n\\[\nx_{_t}=s_{_t}\\times tr_{_t}\\times z_{_t}.\n\\tag{5.17}\\]\n\n\nEjemplo 5.4  \n\n\n\n\n\n\nDatos de pasajeros aéreos\n\n\n\n\n\nPara ilustrar la diferencia entre los tipos de datos que se ajustan mejor a un modelo aditivo y a uno multiplicativo, se utiliza el conjunto de datos de AirPassengers. Como se ha señalado anteriormente, los datos de AirPassengers, representados en la Figura 5.7 (a), tienen un componente estacional y de tendencia, pero también la variabilidad dentro del año aumenta con el tiempo.\n\nCódigo\nlibrary(tswge)\ndata(AirPassengers)\nlogAirPassengers=log(AirPassengers)\nplot(AirPassengers)\nplot(logAirPassengers)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Datos de pasajeros aéreos: 1949-1960\n\n\n\n\n\n\n\n\n\n\n\n(b) Datos de pasajeros aéreos en escala logarítmica\n\n\n\n\n\n\n\nFigura 5.7: Datos de pasajeros aereos y logaritmo de los datos de pasajeros aereos\n\n\n\nLos conjuntos de datos con este tipo de comportamiento suelen modelarse utilizando modelos multiplicativos. Para eliminar el aumento en la variabilidad, los analistas suelen tomar el logaritmo de los datos y utilizan los “datos logarítmicos” para el análisis.\nLos datos logarítmicos de logAirPassengers en la Figura 5.7 (b) no muestran un aumento en la variabilidad dentro del año y son un ejemplo clásico de datos que se modelan utilizando el modelo aditivo en la Ecuación 5.16.\n\n\n\n\nSe comenzó discutiendo el modelo aditivo, considerado el más intuitivo de los dos.\n\nA continuación, se discutirán las diferencias en las estrategias de modelado para estos dos conjuntos de datos.\nLas descomposiciones aditivas y multiplicativas siguen pasos de implementación similares:\n\nEstimar el componente de tendencia.\nEliminar el componente de tendencia, lo que resulta en un conjunto de datos compuesto principalmente por las fluctuaciones estacionales en los datos.\nCalcular un componente estacional “promedio” dentro del año.\nEncontrar el ruido restante.\n\nSe comenzará discutiendo el modelo aditivo, que es el más intuitivo de los dos.\n\n\n5.2.1.1 Descomposición aditiva\n\nCuando se analizan datos utilizando el modelo aditivo en la Ecuación 5.16, se parte del supuesto de que los datos son la suma de componentes estacionales, de tendencia y de ruido aleatorio. Se discuten los pasos de análisis involucrados en la descomposición de los datos logarítmicos de logAirPassengers. En la práctica, los componentes en Ecuación 5.16 se estiman y un modelo estimado puede describirse como\n\\[\nx_{_t}=\\hat{s_{_t}}+\\hat{tr_{_t}}+\\hat{z_{_t}}\n\\tag{5.18}\\]\n\nEjemplo 5.5  \n\n\n\n\n\n\nDescomposición aditiva de LogAirPassengers\n\n\n\n\n\nLa descomposición de los datos logAirPassengers se logra mediante los siguientes pasos.\n\nEstimar el Componente de Tendencia: La Figura 5.8 es una representación gráfica del conjunto de datos logAirPassengers superpuesto con el resultado de aplicar un suavizador de media móvil centrada de orden 12 a los datos.\n\n\nCódigo\nlibrary(tswge)\ndata(AirPassengers)\nlogAirPassengers=log(AirPassengers)\nlogair.12=ma.smooth.wge(logAirPassengers,order=12)\nlogair.12$smooth\n\n\n  [1]       NA       NA       NA       NA       NA       NA 4.837280 4.841114\n  [9] 4.846596 4.851238 4.854488 4.859954 4.869840 4.881389 4.893411 4.904293\n [17] 4.912752 4.923701 4.940483 4.957406 4.974380 4.991942 5.013095 5.033804\n [25] 5.047776 5.060902 5.073812 5.088378 5.106906 5.124312 5.138282 5.152751\n [33] 5.163718 5.171454 5.178401 5.189431 5.203909 5.218093 5.231553 5.243722\n [41] 5.257413 5.270736 5.282916 5.292150 5.304079 5.323338 5.343560 5.357427\n [49] 5.367695 5.378309 5.388417 5.397805 5.403849 5.407220 5.410364 5.410294\n [57] 5.408381 5.406761 5.406218 5.410571 5.419628 5.428330 5.435128 5.442237\n [65] 5.450659 5.461103 5.473655 5.489713 5.503974 5.516367 5.529403 5.542725\n [73] 5.557864 5.572693 5.587498 5.602730 5.616658 5.631189 5.645937 5.659812\n [81] 5.674172 5.687636 5.700766 5.714738 5.727153 5.738856 5.750676 5.760658\n [89] 5.770846 5.780430 5.788745 5.796524 5.804821 5.814072 5.823075 5.832692\n [97] 5.842665 5.853541 5.864863 5.875490 5.885654 5.894475 5.901555 5.907026\n[105] 5.910012 5.910708 5.911637 5.913829 5.917360 5.922887 5.926146 5.927563\n[113] 5.929657 5.930458 5.932964 5.938377 5.946188 5.956352 5.967813 5.977291\n[121] 5.985269 5.994078 6.003991 6.014899 6.026589 6.040709 6.054492 6.066195\n[129] 6.073088 6.080733 6.091930 6.102013 6.112511 6.121153 6.128381 6.137437\n[137] 6.145733 6.151526       NA       NA       NA       NA       NA       NA\n\n\nCódigo\nlogair.sm12=ts(logair.12$smooth,start=c(1949,1),frequency=12)\n\n\n\n\n\n\n\n\nFigura 5.8: LogAirPassengers con un suavizador de promedio móvil centrado de orden 12.\n\n\n\n\n\nEn relación con el modelo estimado en Ecuación 5.18, \\(\\hat{tr_{_t}} =\\) logair.sm12 representa la curva casi lineal en la Figura 5.8.\nEliminar el Componente de Tendencia de los Datos: El paso subsiguiente implica la sustracción del componente de tendencia estimado de los datos (logAirPassengers).\n\n\nCódigo\nseas.logair=logAirPassengers-logair.sm12\nround(seas.logair,4) \n\n\n         Jan     Feb     Mar     Apr     May     Jun     Jul     Aug     Sep\n1949      NA      NA      NA      NA      NA      NA  0.1599  0.1561  0.0661\n1950 -0.1249 -0.0451  0.0553  0.0010 -0.0844  0.0802  0.1953  0.1784  0.0882\n1951 -0.0710 -0.0503  0.1080  0.0054  0.0406  0.0575  0.1550  0.1406  0.0512\n1952 -0.0622 -0.0251  0.0311 -0.0452 -0.0479  0.1138  0.1552  0.1968  0.0383\n1953 -0.0896 -0.1002  0.0754  0.0618  0.0299  0.0858  0.1656  0.1955  0.0597\n1954 -0.1015 -0.1919  0.0245 -0.0173  0.0047  0.1148  0.2368  0.1905  0.0529\n1955 -0.0689 -0.1217 -0.0002 -0.0080 -0.0182  0.1214  0.2512  0.1895  0.0688\n1956 -0.0782 -0.1148  0.0082 -0.0145 -0.0088  0.1438  0.2347  0.2074  0.0673\n1957 -0.0901 -0.1464  0.0101 -0.0233 -0.0135  0.1505  0.2405  0.2393  0.0914\n1958 -0.0884 -0.1608 -0.0345 -0.0754 -0.0353  0.1449  0.2635  0.2862  0.0552\n1959 -0.0992 -0.1593  0.0024 -0.0335  0.0137  0.1163  0.2518  0.2600  0.0646\n1960 -0.0794 -0.1524 -0.0905 -0.0040  0.0112  0.1307      NA      NA      NA\n         Oct     Nov     Dec\n1949 -0.0721 -0.2101 -0.0893\n1950 -0.1016 -0.2769 -0.0922\n1951 -0.0839 -0.1948 -0.0774\n1952 -0.0711 -0.1961 -0.0896\n1953 -0.0549 -0.2133 -0.1073\n1954 -0.0826 -0.2162 -0.1090\n1955 -0.0745 -0.2327 -0.0871\n1956 -0.0905 -0.2210 -0.1091\n1957 -0.0614 -0.1913 -0.0967\n1958 -0.0730 -0.2312 -0.1572\n1959 -0.0719 -0.2003 -0.0981\n1960      NA      NA      NA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) LogAirPassengers sin tendencia\n\n\n\n\n\n\n\n\n\n\n\n(b) Componente estacional estimado\n\n\n\n\n\n\n\nFigura 5.9: Datos de LogAirPassengers sin el componente de tendencia y componente estacional estimado\n\n\n\nSe aprecia con mayor claridad el comportamiento estacional año tras año en la Figura 5.9 (a) sin la “interferencia” de la tendencia. Específicamente, se observa un patrón similar en cada año (mayor cantidad de viajes en verano, disminución en noviembre, aún bajos pero con una ligera alza en diciembre, continuamente bajos en enero y febrero, alza en marzo, y así sucesivamente). No obstante, se presentan variaciones de un año a otro: los viajes aéreos en noviembre fueron notablemente bajos en 1950 y luego inusualmente altos en julio y agosto de 1958.\n\nCalcular un “Promedio” del Componente Estacional Dentro del Año: Es importante notar que el componente estacional en el modelo (2.4) es un patrón general que se mantiene igual de un año a otro. Es decir,\\(\\{s_{_t}, t=1,\\ldots,12\\} = \\{s_{_{t+12}},t=1,\\ldots,12\\} =\\{s_{_{t+2(12)}}, t=1,\\ldots,12\\}=\\cdots.\\) El componente de ruido, \\(z_{_t}\\), ajusta las variaciones de un año a otro del patrón estacional general. El patrón estacional, \\(s_{_t}, t=1,\\ldots,12\\), se estima calculando el promedio a lo largo de los años, y el componente estacional estimado, \\(\\hat{s}_{_t}\\) (el cual es el mismo para cada año), se muestra en la Figura 5.9 (b).\n\n\nCódigo\nseas.logair.numeric=as.numeric(seas.logair)\nseas.logair.matrix=matrix(seas.logair.numeric,ncol=12)\nseas.logair.matrix.t=t(seas.logair.matrix)\nmonths=colMeans(seas.logair.matrix.t, na.rm=TRUE)\nround(months,4)\n\n\n [1] -0.0867 -0.1153  0.0172 -0.0139 -0.0098  0.1145  0.2100  0.2036  0.0640\n[10] -0.0761 -0.2167 -0.1012\n\n\nCódigo\nseas.means=rep(months,12)\nseas.means=ts(seas.means,start=c(1949,1),frequency=12)\n\n\nEncontrar el componente de ruido restante: El ruido estimado en Ecuación 5.18, \\(\\hat{z_{_t}}\\), es calculado de la siguiente manera\n\n\nCódigo\nlogair.noise = logAirPassengers - logair.sm12 - seas.means\nplot(decompose(logAirPassengers))\n\n\n\n\n\n\n\n\nFigura 5.10: Descomposición aditiva de LogAirPassengers\n\n\n\n\n\n\nLa Figura 5.10 muestra un gráfico de los datos de LogAirPassengers junto con las partes del procedimiento de descomposición.\n\n\n\n\n\n\n\n5.2.1.2 Descomposición multiplicativa\n\nSe llevará a cabo en el Ejemplo 5.6 una descomposición multiplicativa de los datos de AirPassengers. Se destaca que esta serie temporal exhibe un patrón estacional y una variabilidad intra-anual crecientes con el tiempo. A pesar de la posibilidad de modelar estos datos mediante el uso del logaritmo seguido de un modelo aditivo, en esta sección se opta por un enfoque multiplicativo para analizar los datos originales de AirPassengers. Al emplear la descomposición multiplicativa en el análisis de datos, se hace la suposición de que la serie temporal es el resultado de componentes estacionales, de tendencia y de ruido. El modelo estimado se expresa como;\n\\[\nx_{_t}=\\hat{s_{_t}}\\times \\hat{tr_{_t}}\\times \\hat{z_{_t}}.\n\\tag{5.19}\\]\n\nEjemplo 5.6  \n\n\n\n\n\n\n\nDescomposición multiplicativa de AirPassengers\n\n\n\n\n\n\nEstimar el Componente de Tendencia: Al igual que con el modelo aditivo, el primer paso consiste en utilizar un suavizador de media móvil centrada, nuevamente en este caso de orden 12. Anteriormente se calculó y representó gráficamente el suavizador de media móvil en la Figura 5.11.\n\n\nCódigo\nlibrary(tswge)\ndata(AirPassengers)\nAirPass.sm12=ma.smooth.wge(AirPassengers,order=12)\nAirPass.sm12=ts(AirPass.sm12$smooth,start=c(1949,1),frequency=12)\n\n\n\n\n\n\n\n\nFigura 5.11: Datos de pasajeros aéreos con suavizado de orden 12.\n\n\n\n\n\nEs importante recordar que, en relación con el modelo estimado en Ecuación 5.19, \\(\\hat{tr_{_t}} =\\) AirPass.sm12. Esta curva casi lineal se muestra como parte de la descomposición completa en la Figura 5.13.\nEliminar el Componente de Tendencia de los Datos: El siguiente paso consiste en eliminar el componente de tendencia estimado del conjunto de datos de AirPassengers. Esto se puede lograr mediante la división (en lugar de la resta).\n\n\nCódigo\nseas.AirPass=AirPassengers/AirPass.sm12\n\n\nLa conducta estacional de un año a otro resulta mucho más clara en la Figura 5.12 (a) después de eliminar la “interferencia” de la tendencia y el aumento de la variabilidad dentro del año. También se observa que la variabilidad dentro del año no está aumentando tanto como en la Figura 5.3. El incremento en la variabilidad en el modelo final Ecuación 5.19 se debe a la tendencia creciente que se multiplica por los datos estacionales en la Figura 5.12 (a). Los patrones estacionales en la Figura 5.12 (a) son similares a los de los datos aditivos mostrados en la Figura 5.9 (a).\n\n\n\n\n\n\n\n\n\n\n\n\n(a) AirPassengers Datos/tendencia\n\n\n\n\n\n\n\n\n\n\n\n(b) Componente estacional estimado\n\n\n\n\n\n\n\nFigura 5.12: Datos de AirPassengers sin el componente de tendencia y componente estacional estimado\n\n\n\n\nCalcular un “Promedio” del Componente Estacional Dentro del Año: Al igual que en el modelo aditivo, en el modelo Ecuación 5.17 , el componente estacional es un patrón general que se supone igual de un año a otro, y el componente de ruido, \\(z_{_t}\\), se ajusta a las variaciones de un año a otro con respecto al patrón estacional general. El componente estacional estimado, \\(\\hat{s_{_t}}\\) (que es idéntico para cada año), se representa en la Figura 5.12 (b). Se observa la similitud entre la Figura 5.12 (b) y la Figura 5.9 (b), que fue el componente estacional para la descomposición aditiva de los datos logAirPassengers.\n\n\nCódigo\nseas.AirPass.numeric=as.numeric(seas.AirPass) \nseas.AirPass.matrix=matrix(seas.AirPass.numeric,ncol=12) \nseas.AirPass.matrix.t=t(seas.AirPass.matrix) \nmonths=colMeans(seas.AirPass.matrix.t,na.rm=TRUE) \nseas.means=rep(months,12) \nseas.means=ts(seas.means,start=c(1949,1),frequency=12)\n\n\nEncontrar el componente de ruido restante: El ruido estimado en Ecuación 5.19, \\(\\hat{z_{_t}}\\), es calculado de la siguiente manera\n\n\nCódigo\nAir.Pass.noise = AirPassengers / (AirPass.sm12 * seas.mean)\nplot(decompose(AirPassengers))\n\n\n\n\n\n\n\n\nFigura 5.13: Descomposición multiplicativa de AirPassengers\n\n\n\n\n\n\nLa Figura 5.13 muestra un gráfico de los datos de AirPassengers junto con las partes del procedimiento de descomposición.\n\n\n\n\n\n\n\n\n\n5.2.2 Ajuste estacional\n\n5.2.2.1 Ajuste estacional aditivo\n\nLos ajustes estacionales están relacionados con las descomposiciones discutidas previamente. Si una descomposición aditiva es apropiada, entonces se utiliza un ajuste estacional aditivo. Un emparejamiento similar se aplica en el caso multiplicativo. El método de ajuste estacional aditivo más directo, consiste en obtener los datos ajustados estacionalmente, \\(\\hat{sa_{_t}}\\), utilizando la fórmula\n\\[\n\\hat{sa_{_t}}=x_{_t}-\\hat{s_{_t}},\n\\tag{5.20}\\]\nque resta el componente estacional (mostrado en la Figura 5.9 (b)) de los datos.\n\n\n\n5.2.2.2 Ajuste estacional multiplicativo\n\nDado que la descomposición multiplicativa fue apropiada para los datos de Pasajeros Aéreos, se empleará un ajuste estacional multiplicativo para este conjunto de datos. Similar al método utilizado para el ajuste estacional aditivo, los datos ajustados estacionalmente utilizan la fórmula\n\\[\n\\hat{sa_{_t}}=x_{_t}/\\hat{s_{_t}},\n\\tag{5.21}\\]\npara dividir los datos por el componente estacional (mostrado en la Figura 5.12 (b)).\n\nEjemplo 5.7  \n\n\n\n\n\n\nAirPassengers\n\n\n\n\n\nLa Figura Figura 5.14 (a) muestra los datos de Pasajeros Aéreos superpuestos con la estimación de tendencia obtenida utilizando un suavizador de media móvil centrada de orden 12. La Figura 5.14 (b) es una representación gráfica de los datos ajustados estacionalmente calculados utilizando Ecuación 5.21. Es decir, es una representación de AirPassengers.adj. Una vez más, los datos ajustados estacionalmente son similares a la tendencia estimada pero con más detalle respecto a los cambios mensuales.\nEl análisis de la Figura 5.14 (c) muestra que el ajuste estacional utilizando seas es más suave y se ve menos afectado por el aumento de la variabilidad dentro del año en años posteriores. En general, los resultados son similares a los vistos en la Figura 5.14 (b) con los efectos estacionales eliminados.\n\nCódigo\nAirPassengers.adj = AirPassengers/seas.means\nlibrary(seasonal) \nlibrary(tswge)\ndata(AirPassengers)\nAirPass.sm12=ma.smooth.wge(AirPassengers,order=12)\nAirPass.sm12=ts(AirPass.sm12$smooth,start=c(1949,1),frequency=12)\ncensus=seas(AirPassengers)\nplot(AirPassengers.adj)\nplot(census$data[,3])\n\n\n\n\n\n\n\n\n\n\n\n\n(a) AirPassengers con suavizamiento\n\n\n\n\n\n\n\n\n\n\n\n(b) Ajuste estacional usando la fórmula\n\n\n\n\n\n\n\n\n\n\n\n(c) Ajuste estacional: Census\n\n\n\n\n\n\n\nFigura 5.14: Datos de AirPassengers y ajuste estacional multiplicativo",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Series de Tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#pronóstico-y-métodos-predictivos.",
    "href": "series.html#pronóstico-y-métodos-predictivos.",
    "title": "5  Series de Tiempo",
    "section": "5.3 Pronóstico y métodos predictivos.",
    "text": "5.3 Pronóstico y métodos predictivos.\n\nUna aplicación principal del análisis de series temporales es la de realizar pronósticos. Anteriormente se mencionó que uno de los propósitos del suavizado es prever valores futuros. De hecho, si existe evidencia de que los patrones previos en un conjunto de datos continuarán en el futuro, se pueden utilizar diversas técnicas para realizar pronósticos.\nPor ejemplo, un propietario de negocio puede desear prever la demanda futura de cierto producto para asegurarse de tener la cantidad apropiada de inventario en stock. Una ciudad que toma decisiones sobre infraestructura podría necesitar prever su población en diez años. Un problema difícil pero de interés para muchos en el sector financiero (y para la mayoría de las personas, en realidad) es predecir las fluctuaciones del mercado de valores y de las acciones individuales para que se puedan tomar decisiones de inversión sólidas. Cada uno de estos ejemplos ilustra la aplicabilidad y necesidad de técnicas de pronóstico. Sin una opción mejor, dichos pronósticos a menudo se hacen de manera algo subjetiva, basados en la memoria pasada de eventos similares, rumores o tal vez mediante cálculos intuitivos pero presumidos que proporcionan conjeturas educadas y estimaciones.\nAfortunadamente, las técnicas de análisis de series temporales proporcionan una alternativa matemática basada en si las suposiciones matemáticas subyacentes son apropiadas. Esto resulta en algoritmos que calculan pronósticos junto con límites de predicción correspondientes a un determinado nivel de confianza, análogos al cálculo de la media muestral más o menos un margen de error en el entorno de muestra aleatoria no temporal. El escenario típico es que se desarrolle un algoritmo de pronóstico que luego se utilice para predecir un resultado de interés. El pronóstico comprende estimaciones de parámetros que pueden encontrarse utilizando software en un esfuerzo por lograr una capacidad predictiva óptima.\n\nObservación. Se utilizarán los términos predicción y pronóstico de manera sinónima.\n\n\n\n5.3.1 Suavizador de media móvil predictivo\n\nEn la Sección 5.1.3.1 se explicó cómo se utiliza el suavizador de media móvil centrada para visualizar una versión suavizada de los datos con el propósito de recuperar señales subyacentes o eliminar ruido o efectos estacionales. También se pueden emplear medias móviles para la predicción. En lugar de la media móvil centrada discutida en la sección mencionada, se utilizará el promedio móvil predictivo para prever valores futuros. Si los datos no exhiben estacionalidad o tendencia, entonces para predecir el valor de la serie temporal en el instante \\(t+1\\), tiene sentido ‘predecir’ \\(x_{_{t+1}}\\) como el promedio de los \\(k\\) valores de datos anteriores para algún \\(k\\). Es decir, dejando que \\(\\tilde{x}_{_{t+1}}\\) denote la predicción de un paso hacia adelante de \\(x_{_{t+1}}\\) dada la información hasta el tiempo \\(t\\), entonces un predictor razonable y muy simple sería\n\\[\n\\tilde{x}_{_{t+1}}=\\left(\\sum\\limits_{i=0}^{k+1}x_{_{t-i}}\\right)/k\n\\]\nEsto es, el predictor de \\(x_{_{t+1}}\\) es el promedio de los últimos \\(k\\) valores de datos.\n\n\n\n\n\n\n\nEjemplos\n\n\n\n\n\n\nSi se quiere usar un predictor de promedio móvil de 3 puntos para un conjunto de datos de longitud \\(t=20\\). Se observa que la predicción un paso hacia adelante de \\(x_4\\) usando este predictor sería\n\\[\n\\tilde{x}_{_4}=(x_{_3}+x_{_2}+x_{_1})/3\n\\]\nDado que el conjunto de datos tiene 20 valores, hay un valor conocido para \\(x_{_4}\\), por lo que podemos comparar el predictor \\(\\tilde{x}_{_4}\\) con el valor real, \\(x_{_4}\\), para evaluar la precisión del predictor.\nPara predecir los valores \\(x_{_4}\\) hasta \\(x_{_n}\\), la predicción es\n\\[\n\\tilde{x}_{_n}=(x_{_{n-1}}+x_{_{n-2}}+x_{_{n-3}})/3\n\\]\nNuevamente, todos estos predictores de un paso hacia adelante pueden compararse con los valores reales para determinar la calidad de cada predicción.\nLa predicción de \\(x_{_{n+1}}\\) está dado por\n\\[\n\\tilde{x}_{_{n+1}}= (x_{_n}+x_{_{n-1}}+x_{_{n-2}})/3\n\\]\nEn este caso, \\(\\tilde{x}_{_{n+1}}\\) es un predictor de un valor futuro que presumiblemente no se conoce. Se puede hacer una evaluación sobre la calidad de esta predicción basándose en las predicciones de \\(x_{_4},x_{_5},\\ldots,\\) todas las cuales pueden ser verificadas. El procedimiento se ilustra en el Ejemplo 5.8.\n\n\n\n\n\n\n5.3.2 Suavizado exponencial\n\nSi bien la predicción mediante el promedio móvil es fácil de conceptualizar y calcular, resulta poco realista asumir que todos los valores de datos precedentes tendrán una influencia igual en los valores futuros. Resulta más intuitivo pensar que, en muchos casos, los datos más recientes deberían tener mayor influencia en los valores futuros que los datos en un pasado más distante, ya que son más representativos del estado actual de la realidad. Un método de suavizado que tiene en cuenta esto se conoce como suavizado exponencial. El suavizado exponencial fue introducido por primera vez por R.G. Brown. Nuevamente se considera que cada valor de datos \\(x_{_t}\\) en una serie temporal está compuesto por un valor medio en cada punto de tiempo \\(t\\) y un término de error independiente con media cero y varianza constante. Es decir, \\(x_{t}=\\mu_{_t}+e_{_t}\\). Para \\(0 \\leq \\alpha \\leq 1\\), la recursión de suavizado exponencial para \\(t =1, 2, \\ldots, n\\) es\n\\[\nu_{_{t+1}}=\\alpha x_{_t}+ (1-\\alpha)u_{_t}\n\\tag{5.22}\\]\nLa Ecuación 5.22 es una combinación lineal del valor actual \\(x_{_t}\\) junto con \\(u_{_t}\\), que es la estimación de \\(\\mu_{_t}\\) basada en datos hasta, pero no incluyendo, el tiempo \\(t\\). En el momento \\(t\\), el promedio ponderado dado en la expresión anterior es el predictor de \\(\\mu_{_{t+1}}\\). Nótese que la estimación \\(\\mu_{_t}\\) depende en gran medida del parámetro de suavizado \\(\\alpha\\), que varía de \\(0\\) a \\(1\\). Cuanto más cercano esté \\(\\alpha\\) a \\(1\\), más peso se le otorga a los datos más recientes, mientras que cuanto más cercano esté \\(\\alpha\\) a \\(0\\), menos peso se le otorga a los datos más recientes. Naturalmente, el valor óptimo de \\(\\alpha\\) dependerá de la aplicación particular del conjunto de datos y se puede ajustar en consecuencia. Debido a que la fórmula anterior es recursiva, cada nueva estimación \\(\\mu_{_t}\\) depende de la estimación anterior \\(\\mu_{_{t-1}}\\), que a su vez depende de la estimación \\(\\mu_{_{t-2}}\\), y así sucesivamente. Esta fórmula no parece ser “exponencial” de inmediato, ¿entonces cómo recibe el método su nombre? Dejando \\(t = 1, 2, 3, 4,\\) vemos que la fórmula recursiva produce lo siguiente:\n\\[\n\\begin{split}\nu_{_1} &= x_{_1}\\\\\nu_{_2} &= \\alpha x_{_1}+(1-\\alpha)u_{_1}\\\\ &=\\alpha x_{_1}+(1-\\alpha)x_{_1}\\\\ &=x_{_1}\\\\\nu_{_3} &= \\alpha x_{_2}+(1-\\alpha)u_{_2}\\\\ &=\\alpha x_{_2}+(1-\\alpha)x_{_1}\\\\\nu_{_4} &= \\alpha x_{_3}+(1-\\alpha)u_{_3}\\\\ &=\\alpha x_{_3}+(1-\\alpha)[\\alpha x_{_2}+(1-\\alpha)x_{_1}]\\\\ &=\\alpha x_{_3} + \\alpha(1-\\alpha)x_{_2}+(1-\\alpha)^2x_{_1}\\\\\nu_{_5} &= \\alpha x_{_4}+(1-\\alpha)u_{_4}\\\\ &=\\alpha x_{_4}+(1-\\alpha)[\\alpha x_{_3}+\\alpha(1-\\alpha)x_{_2}+(1-\\alpha)^2x_{_1}]\\\\ &=\\alpha x_{_4} + \\alpha(1-\\alpha)x_{_3}+\\alpha(1-\\alpha)^2 x_{_2}+(1-\\alpha)^3x_{_1}\n\\end{split}\n\\]\nY en general,\n\\[\nu_{_k}=\\sum_{j=1}^{k-2}\\alpha(1-\\alpha)^{j-1}x_{_{k-j}}+(1-\\alpha)^{k-2}x_{_1}.\n\\tag{5.23}\\]\nEs claro a partir de la Ecuación 5.23 que dado que \\(\\alpha\\) está entre cero y uno, la fórmula recursiva otorga menos peso a las observaciones anteriores y más peso a las observaciones más recientes, y que la magnitud del ponderado es exponencial.\n\n\n\nEjemplo 5.8  \n\n\n\n\n\n\nPredicción por promedio móvil y suavizado exponencial de AirPassengers\n\n\n\n\n\nLa Figura 5.15 (a) muestra la gráfica de los datos de AirPassengers. La función ma.pred.wge implementada en el software R, que hace parte de la librería tswge, calcula predicciones a un paso utilizando un suavizador de media móvil de quinto orden. Utilizando los datos, la función extiende las predicciones hasta \\(x_{_{n+20}}\\). La Figura 5.15 (b) representa tanto los datos como las predicciones.\nLa Figura 5.15 (c) muestra los valores \\(u_{_t}\\), exhibe pronósticos a un paso utilizando suavizado exponencial con \\(\\alpha = 0.4\\). Los predictores resultantes son similares a los de la Figura 5.15 (b).\n\nCódigo\nlibrary(tswge) \nplot(AirPassengers) \n# Predicción por promedio móvil \nma.pred.wge(AirPassengers,order=5,n.ahead=20) \n# Predicción por suavizamiento exponencial \nexpsmooth.wge(AirPassengers,alpha=0.4,n.ahead=20)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Datos de AirPassengers\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicción de AirPassengers por promedio móvil\n\n\n\n\n\n\n\n\n\n\n\n(c) Predicción de AirPassengers por suavizamiento exponencial\n\n\n\n\n\n\n\nFigura 5.15: Datos de AirPassengers, predicción por promedio móvil y suavizado exponencial\n\n\n\n\n\n\n\n\n\n\n5.3.3 Pronóstico Holt-Winters\n\nEl enfoque Holt-Winters es una técnica desarrollada por los economistas Holt (Holt 1957) y Winters (Winters 1960).\nEste método de predicción es una extensión del suavizado exponencial y se aplica a series temporales univariadas. El método no necesita un gran almacenamiento de datos y es simple. Es adecuado para la predicción a corto plazo y utiliza la función de máxima verosimilitud para estimar los parámetros. Existen dos modelos de Holt-Winter que utilizan modelos aditivos o multiplicativos basados en el componente estacional. Los modelos aditivos se aplican para un modelo con una tendencia lineal y con una tendencia exponencial.\n\n\n5.3.3.1 Ecuaciones aditivas de Holt-Winters\n\nEl modelo aditivo de Holt-Winters para datos con tendencia y estacionalidad que no aumentan con el tiempo es adecuado (consulte la Ecuación 5.16). Las fórmulas para la predicción de Holt-Winters son generalizaciones de las ecuaciones de suavizado exponencial, y las ecuaciones de Holt-Winters son las siguientes:\n\\[\n\\begin{split}\nu_{_t}&= \\alpha(x_{_t}-s_{_{t-m}})+(1-\\alpha)(u_{_{t-1}}+v_{_{t-1}})\\\\\nv_{_t}&= \\beta(u_{_t}-u_{_{t-1}})+(1-\\beta)v_{_{t-1}}\\\\\ns_{_t}&= \\gamma(x_{_t}-u_{_{t-1}})+(1-\\gamma)s_{_{t-m}}\n\\end{split}\n\\tag{5.24}\\]\nDonde \\(0 \\le \\alpha, \\beta, \\gamma \\le 1\\), y donde \\(m\\) es la longitud del período. Para datos mensuales, \\(m = 12\\), y para datos trimestrales, \\(m = 4\\). Los \\(u_{_t}\\) están relacionados con el suavizado exponencial simple y proporcionan una línea de base. Los \\(v_{_t}\\) y \\(s_{_t}\\) se relacionan con los efectos de tendencia y estacionales, respectivamente. Para los tiempos \\(t= m+1,\\ldots, n\\), las predicciones de un paso adelante, \\(\\hat{x}_{_t}\\), para la media en el tiempo \\(t\\), se expresan como:\n\\[ \\hat{x}_{_t}= u_{_{t-1}}+v_{_{t-1}}+s_{_{t-m}} \\]\nLas predicciones para \\(x_{_{n+l}}, l=1,\\ldots,K\\) (es decir, hasta \\(K\\) pasos más allá del final de los datos observados), se proporcionan de manera recursiva mediante:\n\\[\n\\hat{x}_{_{n+l|n}}=u_{_n}+mv_{_n}+s_{_{n+l-ml'.}}\n\\]\nDonde \\(l' =\\left[ \\frac{l-1}{m} \\right] + 1\\), con \\(\\left[ \\frac{l-1}{m} \\right]\\) denotando el entero mayor o igual a \\(\\frac{l-1}{m}\\). Aquí, \\(\\alpha, \\beta\\) y \\(\\gamma\\) son parámetros de suavizado, y se pueden obtener utilizando la función HoltWinters la cual parte de las funciones base que conforman al software R.\n\n\n\n5.3.3.2 Ecuaciones multiplicativas de Holt-Winters\n\nComo sugiere el término, las ecuaciones multiplicativas de Holt-Winters son aplicables a datos para los cuales el modelo multiplicativo la Ecuación 5.17 es apropiado. En este caso, las ecuaciones de Holt-Winters son:\n\\[\n\\begin{split}\nu_{_t}&= \\alpha(x_{_t}/s_{_{t-m}})+(1-\\alpha)(u_{_{t-1}}+v_{_{t-1}})\\\\\nv_{_t}&= \\beta(u_{_t}-u_{_{t-1}})+(1-\\beta)v_{_{t-1}}\\\\\ns_{_t}&= \\gamma(x_{_t}/u_{_{t-1}})+(1-\\gamma)s_{_{t-m}}\n\\end{split}\n\\]\nDonde \\(0 \\le \\alpha, \\beta, \\gamma \\le 1\\), y donde nuevamente, \\(m\\) es la frecuencia. Las predicciones para los valores de \\(x_{_t}\\) se expresan mediante:\n\\[ \\hat{x}_{_t}= (u_{_{t-1}}+v_{_{t-1}})s_{_{t-m}} \\]\nLas predicciones para \\(x_{_{n+l}}, l=1,\\ldots,K\\) (es decir, hasta \\(K\\) pasos más allá del final de los datos observados), se proporcionan de manera recursiva mediante:\n\\[\n\\hat{x}_{_{n+l|n}}=(u_{_n}+lv_{_n})s_{_{n+l-ml'.}}\n\\]\nDonde \\(l' =\\left[ \\frac{l-1}{m} \\right] + 1\\).\n\n\nEjemplo 5.9  \n\n\n\n\n\n\nAirPassengers\n\n\n\n\n\nReconsidere los datos de AirPassengers. Dado que los puntos temporales posteriores revelan magnitudes crecientes de los picos y valles cíclicos, la serie temporal es multiplicativa en lugar de aditiva. La Figura 5.16 (a) muestra las predicciones de un paso adelante de Holt-Winters para los años 1950-1960 (superpuestas a los datos reales) dadas por la fórmula utilizando los parámetros de suavizado y coeficientes estimados anteriormente. Las predicciones de un paso adelante (línea sólida) son bastante precisas y apenas se distinguen de los datos (puntos en la línea). La Figura 5.16 (b) muestra los datos de AirPassengers junto con las predicciones de Holt-Winters para los próximos tres años (línea punteada). Estas predicciones parecen extender con precisión el patrón precedente.\n\nCódigo\n# Figure 2.20(a)\nap.hw=HoltWinters(AirPassengers,seasonal=\"mult\")\nplot(ap.hw)\n# Figure 2.20(b)\nap.pred=predict(ap.hw,n.ahead=36)\nplot(ap.hw,ap.pred,lty=1:2)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Predicción de AirPassengers un paso adelante\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicción por Holt-Winters de AirPassengers\n\n\n\n\n\n\n\nFigura 5.16: Predicción mediante Holt-Winters de los datos de AirPassengers\n\n\n\n\n\n\n\n\n\n\n5.3.4 Modelo Autoregresivo (AR)\n\nDefinición 5.11 Se afirma que el proceso \\(X_{_t}\\) satisface un modelo \\(\\mathrm{AR}(p)\\) (Autoregresivo de orden \\(p\\)) si\n\\[\nX_{_t}=a_{_t}+\\beta+\\sum_{k=1}^p \\phi_{_k}X_{_{t-k}}\n\\tag{5.25}\\]\ndonde \\(\\phi_{_k}, k=1,\\ldots,p\\) son constantes reales, \\(\\beta = \\left(1-\\phi_{_1}-\\phi_{_2}-\\cdots-\\phi_{_p}\\right)\\mu\\), \\(\\phi_{_p}\\neq 0\\), y \\(a_{_t}\\) es un proceso de ruido blanco con media cero y varianza finita \\(\\sigma_{_a}^2\\).\n\n\nLa fórmula en la Ecuación 5.25 indica que el valor del proceso en el tiempo \\(t\\) es una combinación lineal de los \\(p\\) valores anteriores más un componente de ruido aleatorio en \\(a_{_t}\\). Iniciamos nuestra discusión sobre los modelos \\(\\mathrm{AR}\\) al abordar sus propiedades, incluidas las condiciones de estacionariedad y el comportamiento de las autocorrelaciones y densidades espectrales para modelos específicos.\nEl modelo \\(\\mathrm{AR}(p)\\) general definido en la Definición 5.11, se asemeja a una ecuación de regresión múltiple, donde, en este caso, las “variables independientes” son los \\(p\\) valores previos de la “variable dependiente” \\(X_{_t}\\). Otra forma de escribir la Ecuación 5.25, después de reorganizar los términos, es:\n\\[\nX_{_t}-\\mu-\\phi_{_1}(X_{_{t-1}}-\\mu)-\\phi_{_2}(X_{_{t-2}}-\\mu)-\\cdots-\\phi_{_p}(X_{_{t-p}}-\\mu)=a_{_t}\n\\tag{5.26}\\]\nAl igual que en el caso de los modelos \\(\\mathrm{AR}(1)\\) y \\(\\mathrm{AR}(2)\\), se expresará con frecuencia el \\(\\mathrm{AR}(p)\\) en la forma de media cero:\n\\[\nX_{_t} -\\phi_{_1}X_{_{t-1}}-\\phi_{_2}X_{_{t-2}}-\\cdots-\\phi_{_p}X_{_{t-p}}=a_{_t}\n\\tag{5.27}\\]\nLas ecuaciones Ecuación 5.25 a Ecuación 5.27 dan la impresión de que un modelo \\(\\mathrm{AR}(p)\\) será mucho más complicado de manejar que un modelo \\(\\mathrm{AR}(1)\\) o \\(\\mathrm{AR}(2)\\). La comprensión de las características de los modelos \\(\\mathrm{AR}(1)\\) y \\(\\mathrm{AR}(2)\\) conduce directamente a comprender el comportamiento de un modelo \\(\\mathrm{AR}(p)\\).\n\n\n5.3.4.0.1 Hechos sobre el modelo \\(\\mathrm{AR}(p)\\)\n\n\n\\(\\mathrm{E}[X_{_t}]=\\mu\\), para la forma “no nula de la media” del modelo \\(\\mathrm{AR}(p)\\) en la Ecuación 5.26 y Ecuación 5.27.\nEl proceso de varianza es \\[\\sigma_{_X}^2=\\gamma_{_0}=\\frac{\\sigma_{_a}^2}{1-\\phi_{_1}\\rho_{_1}-\\phi_{_2}\\rho_{_2}-\\cdots-\\phi_{_p}\\rho_{_p}}\\]\nla cuál es contante y finita cuando \\(X_{_t}\\) es estacionaria.\nLa autocorrelación de un proceso \\(\\mathrm{AR}(p)\\) satisface \\[\n\\rho_{_k}=\\phi_{_p}+\\sum_{n=1}^{p-1}\\phi_{_n}\\rho_{_{k-n}}\n\\]\nLa ecuación (5.28) es una generalización de (5.17) para el caso AR(2), y conduce a las ecuaciones de Yule-Walker de orden p p: \\[\n    \\begin{split}\n\\rho_{_{1}} &= \\phi_{_1}+\\phi_{_{2}} \\rho_{_1} +\\ldots + \\phi_{_p} \\rho_{_{p-1}} \\\\\n\\rho_{_{2}} &= \\phi_{_1}\\rho_{_1}+\\phi_{_{2}}  +\\ldots + \\phi_{_p} \\rho_{_{p-2}}\\\\\n&\\vdots \\\\\n\\rho_{_{p}} &= \\phi_{_1}\\rho_{_{p-1}}+\\phi_{_{2}} \\rho_{_{p-2}} +\\ldots + \\phi_{_p}.\n\\end{split}\n  \\]\nAnálogo al caso \\(\\mathrm{AR}(2)\\), conocer los valores de \\(\\phi_{_1}, \\phi_{_2}, \\ldots, \\phi_{_p}\\) nos permite resolver este sistema de ecuaciones de dimensión \\(p\\times p\\) para \\(\\rho_{_k}\\), donde \\(k = 1, 2, \\ldots, p\\). Las autocorrelaciones basadas en el modelo, \\(\\rho_{_k}\\), para \\(k &gt; p\\), se pueden calcular utilizando la recursión \\(\\phi_{_1} \\rho_{_{k-1}} - \\phi_{_2} \\rho_{_{k-2}} + \\ldots + \\phi_{_p} \\rho_{_{k-p}}\\). No sorprendentemente, se utilizan funciones computacionales para realizar estos cálculos.\nLa densidad espectral de un modelo \\(\\mathrm{AR}(p)\\) es dada por\n\\[\nS_{_X}(f)=\\frac{\\sigma_{_a}^2}{\\gamma_{_0}|1-\\phi_{_1}e^{-2\\pi i f}-\\phi_{_2}e^{-4\\pi i f}-\\cdots-\\phi_{_p}e^{-2p\\pi i f}|^2}\n\\]\n\n\n\nDefinición 5.12 (Autocorrelaciones parciales) Sea \\(X_{_t}\\) un proceso estacionario con autocorrelaciones \\(\\rho_{_j}=j=0,1,\\ldots\\).\n\nLa autocorrelación parcial en rezago \\(k\\), denotada como \\(\\phi_{_{kk}}\\) , es la correlación entre \\(X_{_t}\\) y \\(X_{_{t+ k}}\\) condicional al “conocimiento” de las variables intervinientes \\(X_{_{t+1}}, X_{_{t+2}}\\), y \\(X_{_{t+k-1}}\\).\nConsidere las siguientes ecuaciones de Yule-Walker donde \\(\\phi_{_{kj}}\\) denota el coeficiente \\(j-\\)ésimo asociado con las ecuaciones de Yule-Walker de orden \\(k\\).\n\\[\\begin{split} k&=1\\\\ \\rho_{_1}&=\\phi_{_{11}}\\\\ \\\\ k&=2\\\\ \\rho_{_1}&=\\phi_{_{21}}+\\phi_{_{22}}\\rho_{_1}\\\\ \\rho_{_2}&=\\phi_{_{21}}\\rho_{_1}+\\phi_{_{22}}\\end{split}\\]\nEn general…\n\\[\\begin{split}\\rho_{_1}&=\\phi_{_{k1}}+\\phi_{_{k2}}\\rho_{_1}+\\cdots+\\phi_{_{kk}}\\rho_{_{k-1}}\\\\\\rho_{_2}&=\\phi_{_{k1}}\\rho_{_1}+\\phi_{_{k2}}+\\cdots+\\phi_{_{kk}}\\rho_{_{k-2}}\\\\ \\vdots\\\\ \\rho_{_k}&=\\phi_{_{k1}}\\rho_{_{k-1}}+\\phi_{_{k2}}\\rho_{_{k-2}}+\\cdots+\\phi_{_{kk}}\\end{split}\\]\nLa función de autocorrelación parcial se define como \\(\\phi_{_{kk}}, k = 1, 2,...\\).\n\n\n\n\n5.3.4.0.2 Notación de operador y ecuación característica para un \\(\\mathrm{AR}(p)\\)\n\nEl modelo \\(\\mathrm{AR}(p)\\) en la Ecuación 5.26 puede ser escrito en notación de operador como\n\\[\n(1-\\phi_{_1}B-\\phi_{_2}B^2-\\cdots-\\phi_{_p}B^p)(X_{_t}-\\mu)=a_{_t}\n\\]\nO utilizando una notación abreviada, \\(\\phi(B)(X_{t}-\\mu)=a_{_t}\\) , donde \\(\\phi(B)\\) es el operador de orden \\(p\\)\n\\[\n\\phi(B)=1-\\phi_{_1}B-\\phi_{_2}B^2-\\cdots-\\phi_{_p}B^p.\n\\]\nConvirtiendo el operador \\(\\phi(B)\\) en la cantidad algebraica \\(\\phi(z)\\) resulta en el polinomio característico general \\(\\mathrm{AR}(p)\\)\n\\[\n\\phi(z)=1-\\phi_{_1}z-\\phi_{_2}z^2-\\cdots-\\phi_{_p}z^p\n\\]\nLa correspondiente ecuación característica \\(\\mathrm{AR}(p)\\) es\n\\[\\phi(z) = 1 -\\phi_{_1}z -\\phi_{_2}z^2 - \\cdots - -\\phi_{_p}z^p = 0\\]\nLa ecuación característica tiene \\(p\\) raíces \\(r_{_1}, r_{_2} ,\\ldots, r_{_p}\\) que son reales y/o complejas, donde las raíces complejas aparecen como pares conjugados y algunas raíces pueden ser repetidas.\n\n\nTeorema 5.3 Un proceso \\(\\mathrm{AR}(p)\\) es estacionario si y solo si todas las raíces de la ecuación característica son mayores que uno en valor absoluto.\n\nPrueba. Vea Harvey (1981).\n\n\n\nEjemplo 5.10  \n\n\n\n\n\n\nUn modelo \\(\\mathrm{AR}(4)\\)\n\n\n\n\n\nConsidere el modelo \\(\\mathrm{AR}(4)\\)\n\\[\nX_{_t}-0.13X_{_{t-1}}-1.4414X_{_{t-2}}+.0326X_{_{t-3}}+.8865X_{_{t-4}}=a_{_{t}}\n\\tag{5.28}\\]\ndonde \\(\\sigma_{_a}^2 = 1\\). La notación del operador para este modelo es\n\\[ (1 - 0.13B + 1.4414B^2 - .0326B^3 + 0.8865 B^4)X_{_t}= a_{_t},\\]\ny la correspondiente ecuación característica es\n\\[1 - 0.13z + 1.4414z^2 - .0326z^3 + 0.8865 z^4 = 0.\\]\nLa Figura 5.17 representa una realización de longitud \\(n = 200\\) del proceso descrito en la Ecuación 5.28, junto con las autocorrelaciones muestrales asociadas y la estimación de la densidad espectral Parzen, respectivamente.\n\n\nCódigo\nlibrary(tswge)\nx=gen.arma.wge(n=200,phi=c(0.1300,1.4414,-.0326,-.8865),sn=9310,plot=FALSE)\nplotts.sample.wge(x)\n\n\n\n\n\n\n\n\nFigura 5.17: Realización del modelo AR(4)\n\n\n\n\n\n\n\n\n\n\n\n5.3.4.0.3 El Test Aumentado de Dickey-Fuller\n\nEste test ha estado en uso durante muchos años para probar las hipótesis:\n\n\\(H_{_0}:\\) el modelo contiene una raíz unitaria\n\\(H_{_a}\\): el modelo no contiene una raíz unitaria (y por lo tanto es estacionario)\n\nEstadístico de prueba: \\(\\uptau\\)\nRegión de rechazo: Rechazar \\(H_{_0}\\) si \\(\\uptau &lt; d_{_\\alpha}\\) donde \\(d_{_\\alpha}\\) es el valor crítico de nivel \\(\\alpha\\).\nDavid Alan Dickey (1976) obtiene la distribución límite (complicada) del estadístico de prueba. Si \\(\\uptau \\geq d_{_{.05}}\\), entonces no se rechaza \\(H_{_0}\\) y la prueba de Dickey-Fuller detecta una raíz unitaria. Nótese que el rechazo de la hipótesis nula lleva a la conclusión de que el proceso es estacionario. Por lo tanto, la conclusión de una raíz unitaria se basa en no rechazar la hipótesis nula. Es importante recalcar que no rechazar la hipótesis nula no implica creer que la hipótesis nula sea verdadera, sino simplemente que no hubo suficiente evidencia para rechazarla.\nPara llevar a cabo pruebas de raíz unitaria, se empleará una implementación del test del software estadístico R. Existen diversas opciones, y se utilizará el siguiente comando que incorpora una constante pero no una tendencia en el modelo, y utiliza el criterio de información de Akaike (AIC) para seleccionar el número de rezagos. Se recomienda consultar las obras de David A. Dickey y Fuller (1979) o Fuller (1995) para obtener más detalles al respecto.\n\n\n\n5.3.4.0.4 Factorización del polinomio característico de un \\(\\mathrm{AR}(p)\\)\n\nLas raíces de una ecuación cuadrática se pueden encontrar mediante el uso de la fórmula cuadrática. Sin embargo, las cosas se vuelven más complicadas para órdenes polinómicos mayores a dos. La ecuación cúbica\n\\[\n1-2.1z+1.6z^2-.3z^3=0\n\\]\npuede factorizarse en la forma \\((1-.5z)(1-1.6z+.8z^2)\\). Basándose en esta factorización, las raíces que se obtienen son \\(r_{_1} = 1/.5=2\\), \\(r_{_2} = 1+.5i\\) y \\(r_{_3} = 1-.5i\\). Es decir, este \\(\\mathrm{AR}(3)\\) tendrá un comportamiento de primer orden asociado con \\(1-.5B\\) (es decir, una frecuencia de cero), un comportamiento cíclico de segundo orden con una frecuencia de sistema \\(f_{_0} = 0.07\\), y el proceso es estacionario porque todas las raíces están fuera del círculo unitario.\n\n\nTeorema 5.4 El polinomio de orden \\(p\\), \\(1-\\phi_{_1}z-\\phi_{_2}z^2-\\cdots-\\phi_{_p}z^p\\), siempre puede descomponerse como un producto de\n\nfactores de primer orden (lineales) asociados con raíces reales\nfactores de segundo orden (cuadráticos) cuyas raíces son pares conjugados complejos.\n\n\n\n\n5.3.4.0.5 Tablas de factores para modelos \\(\\mathrm{AR}(p)\\)\n\nEl Teorema 5.4 establece que cualquier polinomio de orden \\(p\\) puede expresarse como un producto de factores de primer orden y/o factores irreducibles de segundo orden. Comprender los factores de primer y segundo orden es la clave para comprender el modelo \\(\\mathrm{AR}(p)\\).\n\n\n\n\n\n\nEjemplo 5.10 (Continuación…)\n\n\n\n\n\nSe considera de nuevo el modelo \\(\\mathrm{AR}(4)\\) en Ecuación 5.28. La ecuación característica asociada es\n\\[\n1-.13z-1.4414z^2+.0326z^3+.8865z^4=0\n\\]\nLa forma factorizada (obtenida numéricamente) es\n\\[\n(1-1.89B+.985B^2)(1+1.76B+.9B^2)=0\n\\]\nLa tabla de factores es una herramienta muy útil para resumir rápidamente la escencia de un modelo \\(\\mathrm{AR}(p)\\) con respecto a los factores de primer y segundo orden.\n\n\nCódigo\nlibrary(tswge)\nfactor.wge(phi=c(.13,1.4414,-.0326,-.8865))\n\n\n  \n  \nCoefficients of AR polynomial:  \n0.1300 1.4414 -0.0326 -0.8865 \n\n                           AR Factor Table \nFactor                 Roots                Abs Recip    System Freq \n1-1.8900B+0.9850B^2    0.9594+-0.3079i      0.9925       0.0494\n1+1.7600B+0.9000B^2   -0.9778+-0.3938i      0.9487       0.4391\n  \n  \n\n\nEn este caso, hay dos factores de segundo orden, \\(1-1.89B+.985B^2\\) y \\(1+1.76B+.9B^2\\).",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Series de Tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#evaluación-de-la-precisión-de-los-pronósticos",
    "href": "series.html#evaluación-de-la-precisión-de-los-pronósticos",
    "title": "5  Series de Tiempo",
    "section": "5.4 Evaluación de la precisión de los pronósticos",
    "text": "5.4 Evaluación de la precisión de los pronósticos\n\nPara obtener una cuantificación “general” de la calidad de las predicciones, se evalúa qué tan bien coinciden las predicciones (\\(f_{_t}\\)) con los valores reales (\\(y_{_t}\\)) en el tiempo \\(t\\). Afortunadamente, se han ideado métricas de error para evaluar la calidad del modelo y permitir la comparación con otras regresiones que poseen diferentes parámetros. Estas métricas son resúmenes breves pero informativos de la calidad de los datos. A continuación se presentan algunas métricas de rendimiento más comunes (Segall y Niu (2022)).\n\n\n5.4.1 MAE\nEl error absoluto medio (MAE) se calcula tomando el residuo para cada punto de datos, considerando únicamente el valor absoluto para minimizar el impacto de los valores atípicos en comparación con Ecuación 5.31. Luego, se obtiene el promedio de todos estos residuos. La ecuación formal se presenta a continuación: \\[MAE= \\frac{1}{n}\\sum_{t=1}^n |y_{_t}-f_{_t}| \\tag{5.29}\\] Dado que se emplea el valor absoluto del residuo, no se indica el rendimiento inferior o superior del modelo. Cada residuo contribuye de manera equitativa al error total, y los errores más grandes tienen una mayor contribución al error general. Un MAE pequeño indica un buen rendimiento de predicción, mientras que un MAE grande sugiere que el modelo puede tener dificultades en ciertas áreas. Obtener MAE perfecta de 0 es rara, indica que el modelo es un predictor impecable.\nSin embargo, el uso del valor absoluto del residuo puede no ser el mejor enfoque para interpretar los datos, ya que los valores atípicos (es decir, los puntos de datos que se alejan significativamente de la tendencia general de los datos) pueden afectar significativamente el rendimiento del modelo. Dependiendo del tratamiento de los valores atípicos y extremos en los datos, es posible que se desee resaltar o minimizar su impacto. Como resultado, la elección de la métrica de error adecuada puede verse influida por el problema de los valores atípicos.\n\n\n5.4.2 MSE\nEl error cuadrático medio (MSE) es similar al MAE, pero eleva al cuadrado la diferencia antes de sumarlos todos en lugar de utilizar el valor absoluto. Esta diferencia se puede observar en la siguiente ecuación: \\[MSE=\\frac{1}{n} \\sum_{t=1}^n (y_{_t}-f_{_t})^2 \\tag{5.30}\\] El error medio absoluto (MAE) y el error cuadrático medio (MSE) son métricas de error comúnmente utilizadas en la evaluación de modelos. Sin embargo, el MSE suele ser mayor que el MAE debido al cuadrado de la diferencia. Comparar los dos directamente no siempre es posible, y en su lugar, debemos comparar las métricas de error de nuestro modelo con las de un modelo ya conocido o que se ajuste a la serie de datos. El efecto de los valores atípicos en nuestros datos es más evidente con la presencia del término cuadrado en la ecuación MSE. Mientras que cada residuo en MAE contribuye proporcionalmente al error total, el error crece cuadráticamente en MSE. En última instancia, esto significa que los valores atípicos en nuestros datos contribuirán a un error total mucho mayor en el MSE que en el MAE. Del mismo modo, nuestro modelo se verá más penalizado por hacer predicciones que difieran mucho del valor real correspondiente.\n\n\n5.4.3 RMSE\nRMSE, o error cuadrático medio, es una medida frecuentemente utilizada para evaluar la diferencia entre los valores predichos \\(f_{_t}\\) y los valores observados \\(y_{_t}\\). Su función se expresa a continuación, donde \\(n\\) representa el número de observaciones. En comparación con el error cuadrático medio (MSE), RMSE toma la raíz cuadrada de MSE y restituye la unidad al mismo nivel que la variable dependiente. Por lo tanto, tiene la ventaja de ser interpretado directamente. En general, un valor de RMSE más bajo es preferible, y RMSE\\(=0\\) indica un ajuste perfecto de los datos. La desventaja de RMSE es su sensibilidad a valores atípicos, ya que unos pocos errores grandes en la suma pueden generar un aumento significativo, y la prueba no distingue entre subestimación y sobreestimación. Como se discutió anteriormente en la descripción de los datos, el conjunto de datos que se utiliza tiene varios valores extremos de gastos elevados, por lo que utilizar solo RMSE como medida podría no ser muy adecuado.\nLa fórmula para el cálculo de RMSE es la siguiente: \\[RMSE= \\sqrt{\\frac{\\sum_{t=1}^n (y_t-f_t)^2}{n}} \\tag{5.31}\\]\n\n\n5.4.4 MAPE\nEl error porcentual absoluto medio (MAPE) mide la precisión de la predicción como un porcentaje y se define generalmente de la siguiente manera. La ventaja es que es muy intuitivo interpretar el error relativo, y un MAPE más bajo significa un error menor. MAPE es similar a MAE, pero normaliza MAE mediante observaciones reales, resolviendo así el problema de que MAE proporciona poca información sobre el error al comparar datos de diferentes escalas. Sin embargo, también presenta la desventaja de que puede producir valores infinitos o indefinidos para valores reales cercanos o iguales a cero. Otra limitación de MAPE es que penaliza más los errores negativos que los errores positivos. Por ejemplo, para un valor real de \\(100\\) y un valor estimado de \\(90\\), el MAPE es \\(0.10\\). Para el mismo valor estimado y un valor real de \\(80\\), el MAPE es \\(0.125\\). Como resultado, si se utiliza MAPE como función objetivo, el estimador preferirá valores más pequeños y puede sesgarse hacia errores negativos. \\[MAPE=\\frac{100}{n}\\sum_{t=1}^n \\left| \\frac{y_t-f_t}{y_t}\\right| \\tag{5.32}\\]\n\n\n\n\n\nDickey, David A, y Wayne A Fuller. 1979. «Distribution of the estimators for autoregressive time series with a unit root». Journal of the American statistical association 74 (366a): 427-31.\n\n\nDickey, David Alan. 1976. Estimation and Hypothesis Testing in Nonstationary Time Series. Iowa State University.\n\n\nFuller, W. A. 1995. Introduction to Statistical Time Series. Wiley Series en Probability y Statistics. Wiley. https://books.google.com.mx/books?id=wyRhjmAPQIYC.\n\n\nHarvey, AC. 1981. «The econometric analysis of time series. Philip Allan». Oxford.\n\n\nHolt, Charles C. 1957. «Forecasting trends and seasonals by exponentially weighted moving averages». ONR Memorandum 52 (52): 5-10.\n\n\nSegall, R. S., y G. Niu. 2022. Biomedical and Business Applications Using Artificial Neural Networks and Machine Learning. Advances en Computational Intelligence y Robotics. IGI Global. https://books.google.com.mx/books?id=9G9bEAAAQBAJ.\n\n\nWaldmeier, Max. 1961. «The sunspot-activity in the years 1610-1960». Zurich: Schulthess.\n\n\nWinters, Peter R. 1960. «Forecasting sales by exponentially weighted moving averages». Management science 6 (3): 324-42.\n\n\nWoodward, W. A., B. P. Sadler, y S. Robertson. 2022. Time Series for Data Science: Analysis and Forecasting. A Chapman & Hall Book. CRC Press, Taylor & Francis Group. https://books.google.com.mx/books?id=gM3gzgEACAAJ.\n\n\nYaglom, A. M. 1962. An Introduction to the Theory of Stationary Random Functions. Selected Russian publications en the mathematical sciences. Prentice-Hall. https://books.google.com.mx/books?id=l_JvAAAAIAAJ.\n\n\nYule, George Udny. 1971. «On a method of investigating periodicities in disturbed series with special reference to Wolfer’s sunspot numbers». Statistical Papers of George Udny Yule, 389-420.",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Series de Tiempo</span>"
    ]
  },
  {
    "objectID": "redes.html",
    "href": "redes.html",
    "title": "6  Redes Neuronales",
    "section": "",
    "text": "6.1 Elementos fundamentales de las Redes Neuronales Artificiales",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "redes.html#elementos-fundamentales-de-las-redes-neuronales-artificiales",
    "href": "redes.html#elementos-fundamentales-de-las-redes-neuronales-artificiales",
    "title": "6  Redes Neuronales",
    "section": "",
    "text": "Para obtener una comprensión clara de los principales elementos utilizados para construir modelos de redes neuronales artificiales (RNA), en la Figura 6.2 se presenta un modelo general de red neuronal artificial que incorpora los componentes fundamentales para este tipo de modelos.\n\n\n\n\n\n\nFigura 6.2: Modelo general de redes neuronales artificiales.\n\n\n\nLa información de entrada, \\(x_1, ..., x_p\\), es recibida por la neurona del sistema sensorial externo u otras neuronas con las que tiene conexión. El vector de pesos sinápticos \\(\\mathbf{w} = (w_1, ..., w_p)\\) modifica la información recibida emulando la sinapsis entre las neuronas biológicas. Estos pueden interpretarse como ganancias que pueden atenuar o amplificar los valores que desean propagar hacia la neurona. El parámetro \\(b_j\\) se conoce como el sesgo (intercepto o umbral) de una neurona. En redes neuronales artificiales, el aprendizaje se refiere al método de modificar los pesos de las conexiones entre los nodos (neuronas) de una red especificada.\nLos valores recibidos por la neurona son ajustados por los pesos sinápticos y que sumados para generar la entrada neta, expresada matemáticamente como:\n\\[v_j=\\sum_{j=1}^p \\omega_{ij}x_j\\]\nLa entrada neta \\((v_j)\\) determina si la neurona se activa o no. La activación de la neurona depende de la función de activación, evaluándose la entrada neta en dicha función para obtener la salida de la red, como se ilustra a continuación:\n\\[\ny_j=g(v_j)\n\\]\ndonde \\(g\\) representa la función de activación. Por ejemplo, si se define esta función como un escalón unitario (también llamado umbral), la salida será \\(1\\) si la entrada neta es mayor que cero; de lo contrario, la salida será \\(0\\).\nAunque no existe un comportamiento biológico análogo a las neuronas cerebrales, el uso de la función de activación es un artificio que permite aplicar RNA a una variedad de problemas reales. La salida \\(y_j\\) de la neurona se genera al evaluar la entrada neta \\((v_j)\\) en la función de activación, pudiendo propagarse a otras neuronas o ser la salida final de la red, con una interpretación específica según la aplicación.\nEn términos generales, el funcionamiento de un modelo de red neuronal artificial se lleva a cabo mediante elementos simples denominados neuronas. Las señales se transmiten entre neuronas a través de enlaces de conexión, cada uno con un peso asociado que multiplica la señal transmitida. Cada neurona aplica una función de activación (generalmente no lineal) a las entradas de la red (suma ponderada de las señales de entrada) para determinar su signo correspondiente.\nUn modelo de RNA de una sola capa, como el presentado en la Figura 6.2, posee una capacidad de procesamiento limitada por sí mismo y una aplicabilidad reducida; su verdadero poder radica en la interconexión de múltiples redes neuronales artificiales, similiar al funcionamiento del cerebro humano. Este enfoque ha motivado a diversos investigadores a proponer diversas arquitecturas para la interconexión de neuronas en el contexto de RNA. A continuación, se presentan las definiciones de RNA y aprendizaje profundo (Montesinos López, Montesinos López, y Crossa (2022)).\n\n\nDefinición 6.1 (Red Neuronal Artificial) Una red neuronal artificial es un sistema compuesto por numerosos elementos de procesamiento simples que operan en paralelo, y cuya función está determinada por la estructura de la red y el peso de las conexiones. En cada uno de los nodos o elementos de cómputo, que posee una capacidad de procesamiento baja, se lleva a cabo el procesamiento.\n\n\nDefinición 6.2 (Aprendizaje profundo) Se define el aprendizaje profundo como una generalización de RNA donde se utilizan más de una capa oculta, lo que implica que se utilizan más neuronas para implementar el modelo. Por esta razón, a una red neuronal artificial con múltiples capas ocultas se le llama Red Neuronal Profunda (RNP) y la práctica de entrenar este tipo de redes se llama aprendizaje profundo (AP).\n\n\nPara una comprensión más completa de los elementos que componen una red neuronal artificial, resulta crucial diferenciar entre las diversas categorías de capas y tipos de neuronas. Por consiguiente, se procede a detallar los tipos de capas seguido por una exposición más detallada de los tipos de neuronas.\n\nCapa de entrada: Es el conjunto de neuronas que recibe directamente la información proveniente de las fuentes externas de la red. En el contexto de la Figura 6.3, esta información es \\(x_1, ... ,x_8\\). Por lo tanto, el número de neuronas en una capa de entrada es la mayoría de las veces igual al número de variables explicativas de entrada proporcionadas a la red. Por lo general, las capas de entrada están seguidas por al menos una capa oculta. Solo en las redes neuronales feedforward, las capas de entrada están completamente conectadas a la siguiente capa oculta.\nCapas ocultas: Consisten en un conjunto de neuronas internas de la red que no tienen contacto directo con el exterior. El número de capas ocultas puede ser \\(0, 1\\) o más. En general, las neuronas de cada capa oculta comparten el mismo tipo de información; por esta razón, se llaman capas ocultas. Las neuronas de las capas ocultas pueden estar interconectadas de diferentes maneras; esto determina, junto con su número, las diferentes arquitecturas de RNA y RNP. La información aprendida extraída de los datos de entrenamiento se almacena y captura mediante los valores de peso de las conexiones entre las capas de la red neuronal artificial. Además, es importante señalar que las capas ocultas son componentes clave para capturar de manera más eficiente comportamientos no lineales complejos de los datos.\nCapa de salida: Es un conjunto de neuronas que transfiere la información procesada por la red hacia el exterior. En la Figura 6.3, las neuronas de salida corresponden a las variables de salida \\(y_1, y_2, y_3\\) e \\(y_4\\). Esto implica que la capa de salida proporciona la respuesta o predicción del modelo de red neuronal artificial basada en la entrada proveniente de la capa de entrada. La salida final puede ser continua, binaria, ordinal o de conteo, dependiendo de la configuración de la RNA, la cual está controlada por la función de activación especificada en las neuronas de la capa de salida.\n\n\n\n\n\n\n\n\nFigura 6.3: Red neuronal artificial profunda feedforward con ocho variables de entrada, cuatro variables de salida y dos capas ocultas con tres neuronas cada una\n\n\n\n\nA continuación, se definen los tipos de neuronas:\n\nNeurona de entrada: Una neurona que recibe entradas externas desde fuera de la red.\nNeurona de salida: Una neurona que produce algunas de las salidas de la red.\nNeurona oculta: Una neurona que no tiene interacción directa con el “mundo exterior” sino solo con otras neuronas dentro de la red. Una terminología similar se utiliza a nivel de capa para redes neuronales multicapa.\n\nComo se aprecia en la Figura 6.3, la disposición de las neuronas en una red neuronal artificial se lleva a cabo mediante la formación de niveles que contienen un número específico de neuronas. Cuando un conjunto de neuronas artificiales recibe simultáneamente el mismo tipo de información, se le denomina capa. Además, se hace referencia a una red compuesta por tres tipos de niveles como capas. La Figura 6.4 exhibe otras seis redes con diversos números de capas, y la mitad de ellas (Figura 6.4 (a), Figura 6.4 (c), Figura 6.4 (e)) son univariadas, ya que la variable de respuesta a predecir es única, mientras que la otra mitad (Figura 6.4 (b), Figura 6.4 (d), Figura 6.4 (f)) son multivariadas, dado que la red tiene el propósito de predecir dos salidas. Es relevante destacar que los paneles a y b en la Figura 6.4 representan redes con solo una capa y sin capas ocultas; por consiguiente, este tipo de redes corresponde a modelos convencionales de regresión o clasificación por regresión.\n\n\n\n\n\n\n\n\n\n\n\n(a) Salida unicapa y univariante.\n\n\n\n\n\n\n\n\n\n\n\n(b) Salida unicapa y multivariante.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Salida univariante y de tres capas.\n\n\n\n\n\n\n\n\n\n\n\n(d) Salida multivariante y de tres capas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Salida univariante de cuatro capas.\n\n\n\n\n\n\n\n\n\n\n\n(f) Salida multivariante de cuatro capas.\n\n\n\n\n\n\n\nFigura 6.4: Diferentes estructuras de redes neuronales univariadas y multivariadas.\n\n\n\nEn consecuencia, la arquitectura de una red neuronal artificial se refiere a la manera en que las neuronas están organizadas en la red, y está estrechamente vinculada al algoritmo de aprendizaje empleado para entrenar la red. Según el número de capas, clasificamos las redes como monocapa o multicapa; y si consideramos la dirección del flujo de información como criterio clasificatorio, las redes se denominan de avance o recurrentes. Cada tipo de arquitectura se aborda la siguiente sección.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "redes.html#arquitectura",
    "href": "redes.html#arquitectura",
    "title": "6  Redes Neuronales",
    "section": "6.2 Arquitectura",
    "text": "6.2 Arquitectura\n\n6.2.1 Perceptrón simple\n\nEl perceptrón simple consta de cuatro componentes fundamentales en su estructura. Estos son: las entradas (input) con conexiones y pesos (nodos ponderados), el nodo de procesamiento o suma, la función de activación y las salidas (output). El nodo de procesamiento realiza una regresión lineal, involucrando la suma ponderada de los pesos en cada nodo de las entradas y un término de sesgo o término independiente. En esencia, el perceptrón simple funciona como un discriminador lineal que, a partir de un umbral establecido, produce una salida binaria.\nDesde una perspectiva matemática, el perceptrón simple se representa mediante la siguiente ecuación:\n\\[\n\\hat{\\mathbf{y}}(\\mathbf x)=f(\\mathbf w^T\\mathbf x+b).\n\\tag{6.1}\\]\nLa arquitectura que modela esta ecuación se describe a través de la Figura 6.5.\n\n\n\n\n\n\nFigura 6.5: Arquitectura de un perceptrón simple\n\n\n\ndonde \\(\\mathbf x\\) denota el vector de entradas, \\(\\mathbf w\\) denota el vector de pesos asociados a cada nodo, \\(b\\) denota el sesgo o intercepto de la regresión, \\(\\sum\\) denota el nodo de procesamiento o combinador lineal, y \\(f\\) denota la función de activación o función limitadora, siendo esta última una transformación no lineal de la regresión obtenida en el nodo de procesamiento.\nAunque el perceptrón simple demuestra eficacia en el aprendizaje y la resolución de problemas linealmente separables, como las compuertas lógicas AND (Figura 6.6 (b)) y OR (Figura 6.6 (a)) , presenta limitaciones en la resolución de problemas que no son de este tipo. Un ejemplo paradigmático de ello es su incapacidad para clasificar las salidas de una compuerta lógica del tipo XOR (Figura 6.6 (c)), ya que el nodo de procesamiento solo permite la separación de la información mediante una única recta de regresión.\n\n\n\n\n\n\n\n\n\n\n\n\nOR\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\nAND\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\nXOR\n\n\n\n\n(c)\n\n\n\n\n\n\n\nFigura 6.6: Compuertas lógicas\n\n\n\n\n\n6.2.2 Perceptrón Multicapa (MLP)\n\nLa solución al problema de la puerta lógica XOR consiste en la adición de una neurona adicional, permitiendo así la definición de una nueva recta de regresión, como se ilustra en la Figura 6.6 (c). Esto conduce a la creación de lo que se conoce como Perceptrón Multicapa o MLP (por sus siglas en inglés), también reconocido como Red Neuronal Profunda. Esta estructura representa una generalización del perceptrón simple, incorporando más de un nivel de neuronas y/o una o varias capas de neuronas “entre” la capa de entradas y la capa de salidas, las cuales son denominadas capas ocultas. En estas capas ocultas, las funciones de activación entre las neuronas no son necesariamente lineales. Las MLP son consideradas las redes neuronales artificiales por defecto y se representan mediante un diagrama simple, que transmite las entradas de capa en capa hasta alcanzar la capa final.\nLa red neuronal de la Figura 7.11 ejemplifica un MLP de dos capas ocultas. En esta representación, los superíndices indican la posición en las capas, mientras que los subíndices indican la posición relativa de cada nodo en su respectiva capa. La red consta de un vector de entradas \\(\\mathbf{x} \\in \\mathbb{R}^{d_0}\\), donde \\(\\mathbf{x} = (x_1, \\ldots, x_{d_0})^T\\), capas ocultas denotadas por \\(a^l\\), y un vector de salidas \\(\\hat{y} \\in \\mathbb{R}^{d_L}\\) con \\(\\hat{y} = (\\hat{y}_1, \\ldots,\\hat y_{d_L})^T\\). Las capas ocultas contienen nodos de procesamiento o neuronas representadas por \\(a = f(z)\\), donde \\(f\\) es la función de activación de cada capa y \\(z\\) es un combinador lineal (matricial). Las conexiones entre las capas están ponderadas por \\(\\mathbf{w}\\), que representa las matrices de pesos asociadas en cada capa. Por ejemplo, \\(w_{ij}^1\\) representa el peso asociado a la conexión entre la entrada j-ésima y el i-ésimo nodo de procesamiento en la primera capa oculta. Las matrices \\(\\mathbf{w}^l\\) tienen dimensiones \\((d_l \\times d_{l-1})\\), donde la capa de entrada se considera como capa cero \\((l = 0)\\).\nEs importante destacar que el término \\(b\\), que indica el sesgo en el perceptrón simple, también se incluye en la red MLP en cada nodo de procesamiento, específicamente en el combinador lineal \\(z\\). A partir de este momento, el nodo de procesamiento incorporará el término de sesgo \\(b\\), y \\(b^1 \\in a^1\\) denotará el vector de sesgo en la primera capa oculta.\n\n\n\n\n\n\nFigura 6.7: Red neuronal MLP con dos capas ocultas (Sosa Jerez, Zamora Alvarado, et al. (s. f.)).\n\n\n\nLa ecuación matemática que describe la red de la Figura 7.11 es la siguiente:\n\\[\n\\begin{split}\\hat{\\mathbf{y}} &= f^3(z^3) \\\\&= f^3(\\mathbf{w}^3 a^2 + b^3) \\\\&= f^3(\\mathbf{w}^3 (f^2(z^2)) + b^3) \\\\&= f^3(\\mathbf{w}^3 (f^2(\\mathbf{w}^2 a^1 + b^2)) + b^3) \\\\&= f^3(\\mathbf{w}^3 (f^2(\\mathbf{w}^2 (f^1(z^1)) + b^2)) + b^3) \\\\&= f^3(\\mathbf{w}^3 (f^2(\\mathbf{w}^2 (f^1(\\mathbf{w}^1 \\mathbf{x} + b^1)) + b^2)) + b^3)\\end{split}\n\\]\nSe observa que \\(f^3\\) representa la función de activación en la capa de salida, la cual comúnmente se elige como la identidad. Sin embargo, en algunos modelos de clasificación, la predicción puede ser más precisa si esta función es no lineal y limitadora.\nPor otro lado, la última columna en la Figura 7.11 constituye una capa adicional en la cual, a través de una función de pérdida, se evalúa el rendimiento de la red. Esta evaluación relaciona la información obtenida en la capa de salida con los datos esperados en un modelo de aprendizaje supervisado.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "redes.html#perceptrón",
    "href": "redes.html#perceptrón",
    "title": "6  Redes Neuronales",
    "section": "6.3 Perceptrón",
    "text": "6.3 Perceptrón\n\nEn un principio, se establece un conjunto de datos a estudiar denominado \\(\\mathbf X \\subseteq \\mathbb R^{m+1}\\). Este conjunto se particiona en dos clases linealmente separables, \\(\\mathscr C_1\\) y \\(\\mathscr C_2\\). A los vectores \\(\\mathbf x = (x_1, x_2,...,x_m,1)^T\\) que pertenecen a \\(\\mathbf X\\), se les denomina entradas.\nA continuación, se introduce un conjunto \\(\\mathbf W \\subseteq \\mathbb R^{m+1}\\), que contiene etiquetas para los nodos del perceptrón. Los elementos de este conjunto, denotados como \\(\\mathbf w = (w_1,w_2,...,w_m,b)^T\\), se llaman pesos sinápticos. Aquí, \\(b\\) es un número real fijo conocido como sesgo. Con el propósito de describir el algoritmo del Perceptrón, se presentan cuatro definiciones fundamentales:\n\nDefinición 6.3 (Clases linealmente separables) Sean \\(\\mathscr C_1\\) y \\(\\mathscr C_2\\) dos clases en un espacio \\(n-\\)dimensional. \\(\\mathscr C_1\\) y \\(\\mathscr C_2\\) se consideran clases linealmente separables si existe un vector \\(\\mathbf w \\in \\mathbb R^{m+1}\\) de pesos sinápticos que cumple con las siguientes condiciones: \\[\n\\begin{split}\n\\mathbf w^T \\mathbf x_1 &&gt; 0\\text{ para cada vector de entrada } \\mathbf x_1 \\in \\mathscr C_1.\\\\\n\\mathbf w^T \\mathbf x_2 &\\leq 0\\text{ para cada vector de entrada } \\mathbf x_2 \\in \\mathscr C_2.\n\\end{split}\n\\]\n\n\nDefinición 6.4 (Combinador lineal) Dados \\(\\mathbf x = (x_1, x_2,..., x_m,1)^T\\) y \\(\\mathbf w = (w_1,w_2,...,w_m,b)^T\\), se define la función \\(\\mathcal V: \\mathbb R^{m+1}\\times\\mathbb R^{m+1} \\rightarrow \\mathbb R\\) como \\(\\mathcal V(\\mathbf x, \\mathbf w) = \\mathbf w^T\\mathbf x\\), donde \\(\\mathcal V(\\mathbf x, \\mathbf w) = 0\\) representa el hiperplano de separación entre dos regiones de decisión.\n\n\nDefinición 6.5 (Función limitadora) Sea \\(\\mathscr A\\) el conjunto de todas las combinaciones lineales \\(\\mathcal V(\\mathbf x, \\mathbf w)\\). Considerando \\(t \\in \\mathscr A\\), se define la función limitadora \\(g\\) como sigue: \\[\n\\begin{split}\ng: \\mathscr A&\\rightarrow \\{1,-1\\}\\\\\nt &\\rightarrow g(t)= \\left\\{\\begin{array}{lcc} 1 & si & t&gt; 0\\\\ \\\\-1 & si & t\\leq 0\\end{array}\\right.\n\\end{split}\n\\]\n\n\nDefinición 6.6 (Función perceptrón) Dadas \\(\\mathcal V(\\mathbf x, \\mathbf w)\\) y \\(g(t)\\), se define la aplicación clasificadora \\(\\mathscr P: \\mathbb R^{m+1}\\times \\mathbb R^{m+1} \\rightarrow \\{1,-1\\}\\) como \\(\\mathscr P(\\mathbf x, \\mathbf w)=g(\\mathcal V(\\mathbf x, \\mathbf w))=\\hat{y}\\), donde \\(\\hat{y}\\in \\{-1,1\\}\\) es la salida de la función perceptrón. Además, la aplicación perceptrón posee una representación gráfica mediante un dígrafo simple, como se muestra en la Figura 6.5.\n\nA través de la función establecida en la Definición 6.6, se desarrolla un modelo de aprendizaje supervisado de clasificación binaria denominado Perceptrón. Este modelo involucra las funciones previamente definidas con el objetivo de clasificar correctamente un conjunto de entradas \\(\\mathbf X\\), linealmente separables en dos clases. Se aplica una regla de aprendizaje adaptativa sobre cada uno de los pesos sinápticos \\((\\mathbf w)\\) en una cantidad finita de pasos \\((n)\\), proceso conocido como algoritmo de aprendizaje del Perceptrón.\n\nDefinición 6.7 (Combinador lineal del perceptrón) Considerando las entradas y los pesos sinápticos en el perceptrón, \\(\\mathbf x(n) = (x_1(n), x_2(n),...,x_m(n),1)^T\\) y \\(\\mathbf w(n) = (w_1(n),w_2(n),...,w_m(n),b)^T\\), se define el combinador lineal del perceptrón como\n\\[\n\\mathcal V=\\mathbf w^T(n)\\mathbf x(n),\n\\]\ndonde \\(n\\) denota el número de iteraciones en la aplicación del algoritmo.\n\nSe considera \\(\\mathscr H \\subset \\mathbf X\\) como el subsepacio vectorial de entrenamiento. \\(\\mathscr H_1\\) es el subespacio de vectores de entrenamiento \\(\\mathbf x_1(1),\\mathbf x_1(2),...\\) que pertenecen a la clase \\(\\mathscr C_1\\), y \\(\\mathscr H_2\\) es el espacio de vectores de entrenamiento \\(\\mathbf x_2(1),\\mathbf x_2(2),...\\) que pertenecen a la clase \\(\\mathscr C_2\\). Se define \\(\\mathscr H= \\mathscr H_1\\cup \\mathscr H_2\\). Con el fin de evitar un sobreentrenamiento en alguna de las dos clases, se garantiza que \\(\\mathscr H_1\\) y \\(\\mathscr H_2\\) tengan la misma cardinalidad.\nDado que el perceptrón es un modelo de aprendizaje supervisado, se establece \\(y(k) \\in \\{-1,1\\}\\) como la clase a la que realmente pertenece cada entrada \\(x(k)\\) de \\(\\mathscr H\\). Se observa que el valor \\(y(k) - \\hat{y}(k)\\) representa el error cometido por el Perceptrón en su clasificación, y de este error se deriva la siguiente definición:\n\nDefinición 6.8 (Función actualización por corrección del error) Se define la regla de actualización de los pesos sinápticos como sigue:\n\\[\n\\mathbf w(n+1)=\\mathbf w(n)+\\eta(n)[y(n)-\\hat y(n)]x(n).\n\\]\nDe esta manera,\n\\[\n\\mathbf{w}(n+1) = \\left\\{\\begin{array}{lcc} \\mathbf w(n)+2\\eta(n) x(n)& si & y(n)=1 \\text{ y }\\hat{y}=-1,\\\\ \\\\\\mathbf w(n) & si & y(n)=\\hat{y}(n),\\\\ \\\\ \\mathbf w(n)-2\\eta(n)x(n) & si & y(n)=-1 \\text{ y }\\hat{y}=1, \\end{array}\\right.\n\\]\ndonde \\(\\eta(n)=\\eta&gt;0\\) es una regla de adaptación de incremento fijo llamada tasa de aprendizaje.\n\n\n\n6.3.1 Teorema de convergencia del perceptrón\n\n\nTeorema 6.1 Sean \\(\\mathscr H_1\\) y \\(\\mathscr H_2\\), subconjuntos de vectores de entrenamiento linealmente separables. Considere las \\(m\\) entradas presentadas al perceptrón, como elementos de estos dos subconjuntos. El perceptrón converge después de \\(n_0\\) iteraciones, en el sentido que:\n\\[\n\\mathit w(n_0)=\\mathit w(n_0+1)=\\mathit w(n_0+2)=\\cdots,\n\\] es un vector solución para \\(n_0\\leq n_{\\max}\\).\n\nPrueba. Vea Sosa Jerez, Zamora Alvarado, et al. (s. f.).",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "redes.html#funciones-de-activación",
    "href": "redes.html#funciones-de-activación",
    "title": "6  Redes Neuronales",
    "section": "6.4 Funciones de activación",
    "text": "6.4 Funciones de activación\n\nLa asignación entre las entradas y una capa oculta en una Red Neuronal Artificial (RNA) y una Red Neuronal Profunda (RNP) es determinada por funciones de activación. Dichas funciones propagan la información generada mediante la combinación lineal de los pesos y las entradas hacia la siguiente capa, incluyendo la capa de salida. Como se ha mencionado anteriormente, existe una analogía entre las neuronas biológicas y las redes neuronales artificiales; en este contexto, las funciones de activación son análogas a la tasa del potencial de acción disparado en el cerebro.\nLas funciones de activación son transformaciones de funciones escalares a escalares que proporcionan una salida específica para cada neurona. Estas funciones introducen no linealidades en las capacidades de modelado de la red. La función de activación de una neurona (nodo) define la forma funcional de su activación. Por ejemplo, si se define una función de activación lineal como \\(g(z) = z\\), en este caso, el valor de la neurona sería la entrada cruda \\(x\\) multiplicada por el peso aprendido, representando así un modelo lineal. A continuación, se describen las funciones de activación más populares.\n\n\n6.4.1 Lineal\n\nLa Figura 6.8 (a) exhibe una función de activación lineal que es esencialmente la función identidad. Esta se define como\n\\[\nF(x)=Wx + b,\n\\]\ndonde la variable dependiente mantiene una relación directa y proporcional con la variable independiente. En términos prácticos, esto implica que la función transmite la señal sin cambios. Sin embargo, el inconveniente al utilizar funciones de activación lineales radica en que esto no permite aprender formas funcionales no lineales.\n\n\n\n6.4.2 Sigmoide\n\nLa función de activación sigmoide desempeña el papel de un mecanismo que transforma variables independientes, abarcando un rango prácticamente infinito, en probabilidades situadas dentro del intervalo de \\(0\\) a \\(1\\). La mayor concentración de su producción tiende a agruparse estrechamente alrededor de los valores \\(0\\) o \\(1\\). Funcionando como una transformación logística, los sigmoides exhiben la capacidad de mitigar valores extremos o atípicos en los datos sin eliminarlos. Las ecuaciones que describen la función sigmoidal y su derivada son las siguientes:\n\\[\\sigma(x) = \\frac{1}{1+e^{-x}}, \\quad \\sigma'(x) = \\frac{e^{-x}}{(1+e^{-x})^2}.\\]\nAmpliamente utilizada en la construcción de Redes Neuronales Artificiales (RNA) y Redes Neuronales Profundas (DNN), especialmente en escenarios donde el resultado deseado es una probabilidad o un resultado binario, la función de activación sigmoide representa uno de los tipos más frecuentemente empleados.\nLa función de activación \\(\\sigma(x):\\mathbb R\\to [0,1]\\) se caracteriza por ser una función suave y diferenciable en todo punto. Compacta cualquier valor entre \\(0\\) y \\(1\\) y destaca por su naturaleza estrictamente creciente, logrando un delicado equilibrio entre comportamiento lineal y no lineal. Sin embargo, es susceptible de experimentar “atascos”, un fenómeno en el cual los valores de salida convergen muy cerca de \\(1\\) o \\(0\\), especialmente cuando los valores de entrada son muy positivos o negativos (consulte la Figura 6.8 (b)). Al referirnos a que la función de activación se “atasca”, implicamos que el proceso de aprendizaje deja de mejorar debido al dominio de valores de salida grandes o pequeños dentro de esta función de activación.\n\n\n\n6.4.3 Unidad lineal rectificadora (ReLu)\n\nLa función de activación de la unidad lineal rectificadora (ReLU) destaca como una de las más adoptadas. Exhibe una respuesta plana por debajo de un umbral especificado, normalmente establecido en cero, y luego se vuelve lineal. La activación en una ReLU se produce solo cuando la entrada supera un determinado umbral. Cuando la entrada está por debajo de cero, la salida sigue siendo cero, pero al exceder el umbral, como se ilustra en la Figura 6.8 (c)., establece una relación lineal con la variable dependiente, de la siguiente manera\n\\[\nF(x)=\\max(0,x)\n\\]\nA pesar de su aparente simplicidad, la función de activación de ReLU facilita las transformaciones no lineales, lo que permite la aproximación de funciones no lineales arbitrarias mediante el uso de rectificadores lineales suficientes. Esto contrasta con los escenarios en los que se emplean exclusivamente funciones de activación lineal.\nEn la actualidad, las ReLU representan el estado de la técnica, demostrando su eficacia en diversas situaciones. Sin embargo, debido a que el gradiente de la ReLU es cero o una constante, plantea desafíos en el control de problemas como la desaparición y la explosión de gradientes, comúnmente conocido como el problema de la “ReLU moribunda”. En particular, las funciones de activación de ReLU han mostrado un rendimiento de entrenamiento superior en la práctica en comparación con las funciones de activación sigmoide. Esta función de activación se emplea más comúnmente en capas ocultas y capas de salida cuando la variable de respuesta es continua y supera cero.\n\n\n\n6.4.4 ReLu con fugas\n\nLas ReLU con fugas sirven como medida correctiva para abordar el fenómeno de la “ReLU moribunda”. A diferencia de la ReLU convencional, que asigna un valor cero a la función cuando \\(x &lt; 0\\), la ReLU con fugas introduce una pequeña pendiente negativa, denotada como \\(\\alpha\\), donde \\(\\alpha\\) es un valor escalar dentro del rango de \\(0\\) a \\(1\\) (consulte la Figura 6.8 (d)). Si bien esta variación de ReLU ha demostrado cierto éxito en aplicaciones prácticas, los resultados no son uniformemente consistentes. La expresión matemática de esta función de activación se proporciona a continuación:\n\\[\nF(x)=\\begin{cases}x & \\text{si}\\quad x&gt;0\\\\ \\alpha x& \\text{otro caso}\\end{cases}.\n\\]\n\n\n\n6.4.5 Tangente hiperbólica\n\nLa función de activación tangente hiperbólica \\((\\tanh)\\) es una modificación de la función sigmoide y se define como\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^{x}+e^{-x}}\n\\]\nCuyas gráficas se observan en la Figura 6.8 (e). La función de activación tangete hiperbólica \\(\\tanh(x):\\mathbb R\\to [-1,1]\\) es una función suave y diferenciable en todo punto. Similar a la función de activación sigmoide, produce una salida sigmoidal (en forma de “S”). Sin embargo, la función \\(\\tanh\\) tiene la ventaja de ser menos propensa al problema de “atascarse” en comparación con la función de activación sigmoide. Esto se atribuye a que los valores de salida de la función \\(\\tanh\\) se encuentran dentro del rango de \\(-1\\) a \\(1\\). En consecuencia, a menudo se prefiere la función de activación \\(\\tanh\\) para capas ocultas. Una ventaja adicional de \\(\\tanh\\) es su capacidad para manejar los números negativos de manera más efectiva. Sin embargo, el gradiente de la función evaluado en valores muy alejados al origen será un valor muy pequeño, por lo que sigue generando un estancamiento en el proceso de retropropagación.\n\n\n\n6.4.6 Softmax\n\nLa función Softmax se emplea predominantemente en redes neuronales dedicadas a abordar problemas de clasificación. Su resultado proporciona un porcentaje que indica la probabilidad de que los datos ingresados pertenezcan a cada una de las clases. Es habitual utilizar esta función de activación en las capas finales de la red neuronal. La expresión que la define es:\n\\[\nS=\\frac{e^{a_i^l}}{\\sum_{k=1}^K (e^{a_k^l})}, \\text{ para }i=1,\\ldots, K\n\\]\ndonde \\(a\\) es la salida de las capas ocultas y \\(K\\) es el número de clases en el modelo. La Figura 6.8 (f) ejemplifica esta función de activación.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Lineal\n\n\n\n\n\n\n\n\n\n\n\n(b) Sigmoide\n\n\n\n\n\n\n\n\n\n\n\n(c) ReLu\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) ReLu con fugas\n\n\n\n\n\n\n\n\n\n\n\n(e) Tangente hiperbólica\n\n\n\n\n\n\n\n\n\n\n\n(f) Softmax\n\n\n\n\n\n\n\nFigura 6.8: Funciones de activación",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "redes.html#funciones-de-coste",
    "href": "redes.html#funciones-de-coste",
    "title": "6  Redes Neuronales",
    "section": "6.5 Funciones de coste",
    "text": "6.5 Funciones de coste\n\nLas funciones de costo, pérdida u objetivo desempeñan un papel fundamental al medir la disparidad entre los resultados obtenidos y los valores deseados. En el contexto del descenso del gradiente, estas funciones son cruciales, ya que buscan minimizar la salida de la función de costo, lo que lleva a que los valores generados por la red neuronal sean cercanos a los valores deseados.\nPara ser empleada en el proceso de retropropagación, la función de costo debe cumplir con dos propiedades fundamentales:\n\nLa función de costo \\(C\\) debe expresarse como un promedio:\n\n\\[C = \\frac{1}{n} \\sum_{x} \\mathcal L_x, \\]\ndonde \\(\\mathcal L_x\\) representa las funciones de pérdida para ejemplos individuales \\(x\\) en el conjunto de entrenamiento.\n\nLa función de costo \\(C\\) no debe depender de ningún valor de activación, excepto los valores de salida \\({a}^L\\). Si la función de costo depende de otras capas de activación además de la capa de salida, la retropropagación no será válida, ya que la idea de propagación hacia atrás dejará de funcionar.\n\n\nObservación. Es importante destacar que la función de costo y la función de pérdida son conceptos distintos. La función de costo representa el promedio de las pérdidas de todas las muestras o datos de entrenamiento, mientras que la función de pérdida se refiere a las pérdidas individuales para cada ejemplo. A pesar de esta diferencia, es común observar el uso de ambos términos de manera intercambiable o con propósitos similares en la literatura.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "redes.html#gradiente-descendente",
    "href": "redes.html#gradiente-descendente",
    "title": "6  Redes Neuronales",
    "section": "6.6 Gradiente descendente",
    "text": "6.6 Gradiente descendente\n\nEl gradiente o vector gradiente se presenta como una generalización de la derivada en varias variables, su definición formal se muestra a continuación.\n\nDefinición 6.9 (Vector gradiente) Sea \\(f : U \\subseteq \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) una función diferenciable definida en el conjunto abierto \\(U\\in \\mathbb R^n\\). Se define el vector gradiente de la función \\(f\\) en el punto \\(x_0\\) de \\(U\\), denotado por \\(\\nabla f(x_0)\\), como el vector en \\(\\mathbb{R}^n\\) dado por\n\\[\\nabla f(x_0) = \\left( \\frac{\\partial f}{\\partial x_1}(x_0), \\frac{\\partial f}{\\partial x_2}(x_0), \\ldots, \\frac{\\partial f}{\\partial x_n}(x_0) \\right).\\]\n\nAdicionalmente, el vector gradiente señala la dirección en la cual la función \\(f\\) experimenta el crecimiento más rápido. Este resultado se formaliza mediante el siguiente teorema\n\nTeorema 6.2 Sea \\(f : X \\subseteq \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) diferenciable en \\(x_0 \\in X\\), el gradiente apunta hacia la dirección de mayor crecimiento de \\(f\\).\n\nPrueba. Vea Stewart (2017).\n\n\nEl método de descenso del gradiente desempeña un papel fundamental en el entrenamiento de las redes neuronales. A través de este método, se logra considerar los valores más óptimos y eficaces, específicamente los pesos \\(w\\) de la red neuronal. Este enfoque permite estimar cada nuevo parámetro basándose en el anterior, teniendo en cuenta la derivada de la función de coste. Además, el proceso presenta ventajas como la simplicidad y la rapidez de convergencia.\n\n\n6.6.1 Algoritmo gradiente descendente\n\nConsidere una función de costo \\(\\mathcal C\\) definida como \\(\\mathcal C : \\Omega \\subseteq \\mathbb{R}^n \\rightarrow \\mathbb{R}\\). El algoritmo de gradiente descendente es utilizado para encontrar un valor \\(w\\) en \\(\\Omega\\) tal que \\(\\mathcal C(w)\\) alcance un mínimo (extremo local).\nLas actualizaciones de \\(w\\) se realizan de la siguiente manera:\n\\[w_{k+1} = w_k - \\alpha \\nabla\\mathcal C(w_k),\\]\ndonde \\(\\alpha\\) es la tasa de aprendizaje y \\(k\\) es el número de iteraciones. Se elige inicialmente un valor inicial \\(w_0\\) (puede ser seleccionado de forma aleatoria o elegido manualmente). El algoritmo comienza en este punto con el propósito de ajustar el valor del peso inicial hasta situarlo en el mínimo de la función.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "redes.html#perceptrón-multicapa",
    "href": "redes.html#perceptrón-multicapa",
    "title": "6  Redes Neuronales",
    "section": "6.7 Perceptrón Multicapa",
    "text": "6.7 Perceptrón Multicapa\n\nComo se expuso previamente en la Sección 6.2.2, se pueden representar mediante un diagrama simple, que incluye nodos ponderados y un conjunto de atributos que las caracterizan. En esta sección, la estructura de la red será formalizada junto con sus definiciones correspondientes (Sosa Jerez, Zamora Alvarado, et al. (s. f.)).\n\n\nDefinición 6.10 (Perceptrón Multicapa (MLP)) Una red neuronal artificial MLP se define formalmente como una tripla \\(&lt;\\mathscr D, \\{f\\}, \\mathscr A&gt;\\), donde;\n\n\\(\\mathscr D\\) es un dígrafo contable, localmente finito, con nodos etiquetados. Sus vértices corresponden a los nodos de procesamiento (neuronas), mientras que las etiquetas de los nodos, denominadas pesos, representan las intensidades de las conexiones sinápticas. Dichas intensidades se denotan por \\(w_{ij}\\), indicando el peso de la conexión entre la neurona \\(j\\)-ésima y la \\(i\\)-ésima.\n\\(\\mathscr A\\) es el conjunto que contiene los elementos de “entrada” de las unidades o nodos de procesamiento, generalmente representado por \\(A =\\mathbb R\\).\n\\(\\{f: \\mathscr A\\to\\mathscr A\\},\\) es una colección de funciones de activación.\n\n\n\nEn el dígrafo \\(\\mathscr D\\), se definen las capas como las columnas de vértices en \\(\\mathscr D\\). Cada una de estas columnas puede ser representada matemáticamente a través de un vector, de la siguiente manera:\n\nCapa de entrada: corresponde a la primera columna de vértices de \\(\\mathscr D\\), cuya representación matemática se expresa como: \\[\\mathbf x = (x_1, \\ldots, x_{d_0})^T \\text{ donde } \\mathbf x \\in \\mathbb{R}^{(d_0 \\times 1)}\\]\nCapa de salida: corresponde a la última columna de vértices de \\(\\mathscr D\\), cuya representación matemática se describe como: \\[\\hat{\\mathbf y} = (\\hat{y}_1, \\ldots, \\hat{y}_{d_L})^T \\text{ donde } \\hat{y}\\in\\mathbb{R}^{(d_L\\times 1)}\\]\nCapas ocultas: corresponden a las columnas intermedias entre la capa de entrada y la de salida. Su representación matemática está dada por: \\[\\begin{split}\n\\mathbf a^l &= (a_{1}^l, \\ldots, a_{d_l}^l)^T \\text{ donde } a^l\\in\\mathbb{R}^{(d_l\\times 1)}\\\\ &= f^l(z^l)\\text{ con } l = 1, \\ldots, L - 1\n\\end{split}.\\]\n\nCabe destacar que cada \\(\\mathbf a^l\\) corresponde a una columna de vértices en \\(\\mathscr D\\), donde \\(L\\) denotará la totalidad de capas en la red. \\(f^l\\) será una función de activación vectorial y \\(z^l\\) será el combinador lineal matricial, ambos en la capa \\(l\\). De esta manera, la capa de salida también puede representarse como el vector \\(\\mathbf a^L\\), y la capa de entrada como el vector \\(\\mathbf a^0\\).\n\n\nDefinición 6.11 (Neuronas o nodos de procesamiento) Las neuronas de la red MLP son los vértices de las capas ocultas en \\(\\mathscr D\\), es decir, las componentes de \\(\\mathbf a^l\\) se denotarán como \\(a_i^l\\), donde:\n\\[\na_i^l=f^l(z_i^l).\n\\]\n\n\nDefinición 6.12 (Función de activación) Se define \\(f^l\\) como una función de activación vectorial, de modo que:\n\\[\nf^l: \\mathbb R^{(d_1\\times 1)}\\rightarrow \\mathbb R^{(d_1\\times 1)}.\n\\]\n\n\nDefinición 6.13 (Matriz de pesos) Para cada capa \\(l\\) en \\(\\mathscr D\\), se define \\(\\mathbf w^l\\) como una matriz de dimensiones \\(d_l \\times d_{l-1}\\), donde \\(d_l\\) representa la cantidad de neuronas en la capa \\(l\\), de la siguiente manera:\n\\[\n\\mathbf w^l=\\begin{bmatrix}w_{11}^l & \\cdots & w_{1j}^l&\\cdots&w_{1d_{l-1}}^l\\\\ \\vdots &\\cdots&\\vdots&\\cdots&\\vdots\\\\ w_{i1}^l & \\cdots & w_{ij}^l&\\cdots&w_{id_{l-1}}^l\\\\ \\vdots &\\cdots&\\vdots&\\cdots&\\vdots\\\\ w_{d_l1}^l & \\cdots & w_{d_lj}^l&\\cdots&w_{d_ld_{l-1}}^l \\end{bmatrix}\n\\]\n\n\nDefinición 6.14 (Sesgo) Se define el sesgo como el vector\n\\[\n\\mathbf b^l=(b_1^l,\\ldots,b_{d_l}^l)^T\\quad\\text{con }\\mathbf b^l\\in\\mathbb R^{(d_1\\times 1)}\n\\]\ncorrespondiente a la capa \\(l\\), cuyas entradas son el parámetro de sesgo de cada neurona.\n\n\nDefinición 6.15 (Combinador lineal matricial) Dados \\(\\mathbf a^{l-1}, \\mathbf w^l\\) y \\(\\mathbf b^l\\) se define el combinador lineal como\n\\[\n\\begin{split}\n\\mathbf z^l&=(z_1^l,\\ldots,z_{d_l}^l)^T\\\\\n&=\\mathbf w\\mathbf a^{l-1}+\\mathbf b^l,\n\\end{split}\n\\]\ndonde\n\\[\nz_i^l=\\sum_{j=1}^{d_{l-1}}w_{ij}^la_j^{l-1}+b_i.\n\\tag{6.2}\\]\n\n\nSe observa que la ecuación Ecuación 6.2 guarda una fuerte relación con la Definición 6.4. No obstante, en el caso de \\(\\mathbf{z}^l\\), se ha incorporado el vector de parámetros de sesgo \\(\\mathbf{b}^l\\).\n\n\nDefinición 6.16 (Función de pérdida) Se define \\(\\mathcal L: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) de manera que\n\\[\\begin{split}\\mathcal L(\\mathbf y,\\mathbf{\\hat{y}}) &= \\frac{1}{2}\\|\\mathbf y - \\mathbf{\\hat{y}}\\|^2\\\\ &= \\frac{1}{2} \\|\\mathbf y - \\mathbf a^L\\|^2\\\\ &= \\frac{1}{2} \\sum_{r=1}^{d_L} (y_r - a_r^L)^2,\\end{split}\\] como la función de pérdida de la red MLP.\n\n\nDefinición 6.17 (Conjunto de datos de entrenamiento) Sea \\(\\mathbf X = (\\mathbf x(1), \\ldots, \\mathbf x(n))\\), donde \\(\\mathbf x(k)\\), con \\(k = 1, \\ldots, n\\), representa el \\(k\\)-ésimo dato en el conjunto \\(\\mathbf X\\), siendo este el vector de entradas de la red neuronal en la \\(k\\)-ésima etapa.\n\n\nDefinición 6.18 (Conjunto de salidas de la red) Se define \\(\\hat{\\mathbf Y} = (\\hat{\\mathbf y}(1), \\ldots, \\hat{\\mathbf y}(n))\\), donde \\(\\hat{\\mathbf y}(k)\\), con \\(k = 1, \\ldots, n\\), representa el \\(k\\)-ésimo dato en el conjunto \\(\\hat{\\mathbf Y}\\), siendo este el vector de salidas de la red neuronal en la \\(k\\)-ésima etapa.\n\n\nDefinición 6.19 (Resultados esperados) Se define \\(\\mathbf Y = (\\mathbf y(1), \\ldots, \\mathbf y(n))\\), donde \\(\\mathbf y(k)\\), con \\(k = 1, \\ldots, n\\), representa el \\(k\\)-ésimo dato en el conjunto \\(\\mathbf Y\\), siendo este el vector de resultados esperados correspondiente al dato \\(\\mathbf x(k)\\).\n\n\n6.7.1 Entrenamiento y aprendizaje del Perceptrón Multicapa\n\nEl proceso de aprendizaje de una red neuronal se configura como un modelo de aprendizaje supervisado. En este proceso, se establece un algoritmo que, a partir de un conjunto de datos de entrenamiento que incluye entradas y resultados esperados, permite el entrenamiento gradual de la red. El objetivo principal es que la red pueda calcular de manera autónoma los valores óptimos de pesos y sesgos para clasificar las entradas en salidas, minimizando la discrepancia con respecto a los resultados esperados.\nAl concluir este proceso de entrenamiento, se espera que la red neuronal desarrolle la capacidad de clasificar cualquier dato, incluso aquellos no presentes en el conjunto de entrenamiento inicial (datos de prueba), generando salidas con un error de clasificación mínimo. Este proceso de entrenamiento se compone de dos etapas esenciales: la propagación hacia adelante o feedforward, y la retropropagación, también conocida como back-propagation.\n\n\n6.7.1.1 Propagación hacia adelante\n\nEl proceso de prealimentación constituye la base del entrenamiento y aprendizaje de la red, considerando los siguientes pasos:\n\nSe elige un vector de datos \\(\\mathbf x \\in \\mathbf X\\) como entrada de la red neuronal MLP.\nSe establecen matrices \\(\\mathbf w^l\\) de pesos y vectores \\(\\mathbf b^l\\) de sesgo, cuyas componentes tienen entradas aleatorias que pertenecen a un umbral prefijado.\nSe “alimenta” la red neuronal en una única dirección. Para ello, se inicia estableciendo lo que se tendrá en la primera capa de procesamiento y luego se generaliza el proceso:\n\nAlimentación primera capa: Se establecen los productos matriciales en cada nodo de procesamiento, dados por:\n\\[\n\\begin{split}\\mathbf z^1&=(\\mathbf w^1\\mathbf x)+\\mathbf b^1\\\\ \\mathbf a^1&=f^1(\\mathbf z^1).\\end{split}\n\\]\nGeneralización: Considerando cómo se “alimenta” la red en la primera capa, se repite el mismo proceso para cada capa siguiente:\n\\[\n\\begin{split}\\mathbf z^l&=(\\mathbf w^l\\mathbf a^{l-1})+\\mathbf b^l\\\\\\mathbf a^l&= f^l(\\mathbf z^l).\\end{split}\n\\]\n\nSe observa que en este paso, lo que en la primera capa era \\(\\mathbf x\\), en cualquier capa diferente será \\(a^{l-1}\\). Esto se debe a que la red es un dígrafo \\(\\mathscr D\\), donde la salida de la capa anterior \\((l - 1)\\) se convierte en el vector de entrada para la capa siguiente \\((l)\\).\n\n\n\n\n6.7.1.2 Retropropagación\n\nLa retropropagación se emplea en las redes neuronales como algoritmo de aprendizaje, y su objetivo es ajustar de manera eficiente los pesos de la red. Este proceso consiste en establecer inicialmente de manera aleatoria los pesos requeridos en la red para obtener una salida, la cual se compara mediante la función de pérdida \\(\\mathcal L\\) con el resultado esperado. De esta manera, se calcula el error de aproximación de la red con el objetivo de minimizar dicho error a través de la optimización de la función \\(\\mathcal L\\). La optimización se realiza mediante una generalización del algoritmo de descenso del gradiente, utilizando la regla de la cadena y recorriendo la red de atrás hacia adelante.\nDe forma iterativa, la red aprende a establecer los pesos y sesgos adecuados para cada neurona, con el fin de obtener una salida que se aproxime al resultado esperado. Para comprender el funcionamiento del algoritmo de retropropagación, es necesario comenzar calculando las derivadas respecto a los parámetros de pesos y sesgos de la función de coste en la red prealimentada.\nSe inicia calculando la derivada de \\(\\mathcal L\\) respecto a uno de los pesos que afectan a la última capa:\n\\[\\begin{split}\\frac{\\partial \\mathcal L}{\\partial w_{ij}^L} &= \\frac{1}{2} \\sum_{r=1}^{d_L} \\frac{\\partial}{\\partial w_{ij}^L} (y_r - a_{r}^L)^2\\\\\n&= \\sum_{r=1}^{d_L} (a_{r}^L - y_r) \\left(\\frac{\\partial a_r^L}{\\delta w_{ij}^L}\\right)\\\\\n&=\\sum_{r=1}^{d_L} (a_{r}^L - y_r) \\frac{\\partial}{\\partial w_{ij}^L}f^L(z_{r}^L)\\\\\n&= \\sum_{r=1}^{d_L} (a_{r}^L - y_r) \\frac{\\partial}{\\partial w_{ij}^L}f^L\\left(\\sum_{t=1}^{d_L}w_{rt}^La_t^{L-1}+b_r^L\\right),\\end{split} \\tag{6.3}\\]\nEsta expresión se anula en todos los valores en los que \\(r\\neq i\\) o \\(t\\neq j\\). Si \\(r = i\\) y \\(t = j\\), se tiene:\n\\[\\frac{\\partial \\mathcal L}{\\partial w_{ij}^L} = (a_{i}^L - y_i) f^{(1)L}(z_{i}^L) a_j^{L-1} \\tag{6.4}\\]\nEsta ecuación proporciona la derivada particular de la función de pérdida respecto a un único peso. Para generalizar esta situación y calcular \\(\\frac{\\partial \\mathcal L}{\\partial \\mathbf w^{L}}\\), se deben tener en cuenta las dimensiones y definir una nueva operación matricial.\n\n\nDefinición 6.20 (Producto Hadamard) Dadas \\(A, B\\) dos matrices de dimensión \\((m\\times n)\\), el producto de Hadamard \\((A\\odot B)\\) es una matriz de dimensión \\((m\\times n)\\) tal que:\n\\[\n(A\\odot B)_{ij}=[a_{ij}b_{ij}].\n\\]\n\n\nGeneralizando la Ecuación 6.4 y haciendo uso de la definición previa, se puede expresar la derivada parcial de la función de pérdida respecto a los pesos en la última capa como:\n\\[\\begin{split}\\frac{\\partial \\mathcal L}{\\partial \\mathbf w^L} &= \\frac{\\partial \\mathcal L}{\\partial \\mathbf a^L}\\frac{\\partial \\mathbf a^L}{\\partial \\mathbf z^L}\\frac{\\partial \\mathbf z^L}{\\partial \\mathbf w^L}\\\\&= \\left[(\\mathbf a^L - y)\\odot f^{(1)L}(\\mathbf z^L)\\right] (\\mathbf a^{L-1})^T,\\end{split} \\tag{6.5}\\]\nDonde el error en la última capa se denota como \\((\\mathbf a^L - y)\\) y se representa como \\(\\mathbf e^L\\). También se introduce la notación \\(\\delta^L\\) para referirse al producto de Hadamard \\([(\\mathbf a^L - y)\\odot f^{(1)L}(\\mathbf z^L)]\\). La expresión se simplifica como:\n\\[\\frac{\\partial \\mathcal L}{\\partial \\mathbf w^L} = \\delta^L (a^{L-1})^T. \\tag{6.6}\\]\nAl extender este proceso desde la Ecuación 6.3 hasta la Ecuación 6.6 para calcular \\(\\frac{\\partial \\mathcal L}{\\partial \\mathbf b^L}\\), se obtiene:\n\\[\\frac{\\partial \\mathcal L}{\\partial \\mathbf b^L} = \\delta. \\tag{6.7}\\]\nSe reconoce que la función de pérdida \\(\\mathcal L\\) en el conjunto de datos \\(\\mathscr D\\) depende de las matrices de pesos y los vectores de sesgo de cada capa. Por lo tanto, se busca minimizar la función de pérdida en cada capa \\(l\\). Al considerar las derivadas en la capa \\(L-1\\), se obtiene:\n\\[\n\\begin{split}\\frac{\\partial \\mathcal L}{\\partial \\mathbf w^{L-1}}&= \\frac{\\partial \\mathcal L}{\\partial \\mathbf a^{L}}\\frac{\\partial \\mathbf a^L}{\\partial \\mathbf z^{L}}\\frac{\\partial \\mathbf z^L}{\\partial \\mathbf a^{L-1}}\\frac{\\partial \\mathbf a^{L-1}}{\\partial \\mathbf z^{L-1}}\\frac{\\partial \\mathbf z^{L-1}}{\\partial \\mathbf w^{L-1}}\\\\\n&= [((\\mathbf w^L)^T \\delta^L)\\odot f^{L-1(1)}(\\mathbf z^{L-1})](\\mathbf a^{L-2})^T\\\\\n&= \\delta^{L-1}(\\mathbf a^{L-2})^T,\\end{split}\n\\tag{6.8}\\]\nDonde \\(((\\mathbf w^L)^T \\delta^L) = \\mathbf e^{L-1}\\) y \\([((\\mathbf w^L)^T \\delta^L)\\odot f^{L-1}(\\mathbf z^{L-1})] = \\delta^{L-1}\\).\nDe manera análoga, la derivada parcial de la función de pérdida con respecto al sesgo en la capa \\(l-1\\) se expresa como:\n\\[\\frac{\\partial \\mathcal L}{\\partial \\mathbf b^{L-1}} = \\delta^{L-1}. \\tag{6.9}\\]\nAl generalizar este proceso, se obtiene la relación recurrente para \\(\\delta^l\\):\n\\[\\delta^l = \\left[((\\mathbf w^{l+1})^T \\delta^{l+1})\\odot f^l(\\mathbf z^l) \\right], \\quad \\text{para } l = L-1, \\ldots, 1.\\]\nDe esta forma, las derivadas parciales de la función de pérdida respecto a los pesos y sesgos en cada capa se expresan como:\n\\[\\frac{\\partial \\mathcal L}{\\partial \\mathbf w^l} = \\delta^l (a^{l-1})^T,\\quad \\frac{\\partial \\mathcal L}{\\partial \\mathbf b^l} = \\delta^l. \\tag{6.10}\\]\nCon estas expresiones, se define el proceso iterativo de retropropagación en los siguientes pasos:\n\nCalcular el error \\(\\mathbf e^L\\) y \\(\\delta^L\\) en la última capa, como se muestra en la Ecuación 6.5 y Ecuación 6.6.\nCalcular \\(\\mathbf e^l\\) y \\(\\delta^l\\) en cada capa \\(l\\) mediante las relaciones:\n\\[\n\\begin{cases}\\mathbf e^l&= (\\mathbf w^{l+1})^T\\delta^{l+1}\\\\ \\delta^l &= (f^{l(1)}(\\mathbf z^l))\\odot \\mathbf e^l.\\end{cases}\n\\]\nProceder a la actualización de pesos y sesgos. Para ello, se introduce la función de coste \\(\\mathcal C\\) aplicada a la pérdida \\(\\mathcal L\\) y se calculan las derivadas con respecto a los pesos y sesgos:\n\\[\n\\mathcal C=\\frac{1}{n}\\sum_{k=1}^n \\mathcal L(\\mathbf y, \\mathbf{\\hat{y}})(k)\n\\]\nEstas derivadas son equivalentes a las obtenidas en la Ecuación 6.6, Ecuación 6.7 y Ecuación 6.10. Luego, se aplica el algoritmo de descenso del gradiente para actualizar las matrices de pesos y sesgos:\n\\[\n\\begin{split}\\frac{\\partial \\mathcal C}{\\partial \\mathbf w^l}&=\\frac{1}{n}\\sum_{k=1}^n \\frac{\\partial}{\\partial \\mathbf w^l}\\mathcal L(\\mathbf y, \\hat{\\mathbf y})(k)\\\\ &=\\nabla_{\\mathbf w^l}\\mathcal C\\\\\n\\frac{\\partial\\mathcal C}{\\partial\\mathbf b^l}&= \\frac{1}{n}\\sum_{k=1}^n \\frac{\\partial}{\\partial \\mathbf b^l}\\mathcal L(\\mathbf y, \\hat{\\mathbf y})(k)=\\nabla_{\\mathbf b^l}\\mathcal C,\\end{split}\n\\tag{6.11}\\]\nNote que en la Ecuación 6.11, las derivadas con respecto a \\(\\mathbf w^L\\) y \\(\\mathbf b^L\\), son las mismas que se dedujeron en la Ecuación 6.10, con estos últimos parámetros obtenidos, se puede aplicar el algoritmo del descenso del gradiente, para actualizar las matrices de pesos y sesgos, así:\n\\[\n\\begin{cases}\\mathbf w^l(t)&:= \\mathbf w^{l-1}(t-1)-\\eta\\nabla_{\\mathbf w^l}\\mathcal C,\\\\ \\mathbf b^l(t)&:= \\mathbf b^{l-1}(t-1)-\\eta\\nabla_{\\mathbf b^l}\\mathcal C,\\end{cases}\n\\]\ndonde \\(t\\) representa el iterador de épocas asignadas a la red.\n\nAl aplicar estos algoritmos (Feed-Forward y Backpropagation), se puede construir una red neuronal que, a partir de un conjunto de datos (ya sea de prueba o entrenamiento), se entrena para lograr una clasificación precisa de los datos. Es importante destacar que antes de aplicar el conjunto de prueba a la red, se debe realizar un proceso de preprocesamiento de datos, que incluye la eliminación de datos atípicos y la normalización del conjunto de entrenamiento, con el fin de evitar confusiones en la clasificación.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "redes.html#evaluación-de-modelos-de-aprendizaje-automático",
    "href": "redes.html#evaluación-de-modelos-de-aprendizaje-automático",
    "title": "6  Redes Neuronales",
    "section": "6.8 Evaluación de modelos de aprendizaje automático",
    "text": "6.8 Evaluación de modelos de aprendizaje automático\n\nUna vez entrenado un modelo de Machine Learning con datos etiquetados, se espera que funcione correctamente con nuevos datos. Sin embargo, es crucial asegurar la precisión de las predicciones del modelo en condiciones de producción.\nPara lograr este objetivo, es imprescindible validar el modelo. Este procedimiento implica determinar si los resultados digitales que cuantifican las relaciones hipotéticas entre las variables son adecuados como descripciones de los datos.\nCon el propósito de evaluar el rendimiento de un modelo de Machine Learning, es necesario ponerlo a prueba con datos nuevos. A partir del desempeño del modelo con datos desconocidos, se puede determinar si requiere ajustes adicionales, si ha sido sobreajustado o si está generalizado de manera adecuada.\nUna de las técnicas más utilizadas para evaluar la eficacia de un modelo de Machine Learning es la validación cruzada. Este método, que también se considera un procedimiento de re-muestreo, permite evaluar un modelo incluso cuando se cuenta con datos limitados.\nPara llevar a cabo la validación cruzada, es necesario reservar previamente una parte de los datos de entrenamiento. Estos datos no se emplearán durante el proceso de entrenamiento del modelo, sino que se utilizarán posteriormente para probarlo y validar sus resultados.\nFrecuentemente en el ámbito del Machine Learning, la validación cruzada se emplea para comparar diferentes modelos y seleccionar aquel que sea más apropiado para un problema específico. Esta técnica, además de ser fácil de comprender e implementar, presenta menos sesgos que otros métodos. A continuación se exploran las principales técnicas de validación cruzada.\n\n\n6.8.1 División de datos en entrenamiento y prueba\n\nEl enfoque denominado división datos en entrenamiento y prueba se basa en la aleatoria división de una serie de datos en dos conjuntos. Uno de estos conjuntos se destina al entrenamiento del modelo de Machine Learning, mientras que el otro se reserva para la validación del mismo.\nGeneralmente, se asigna entre un \\(70\\%\\) y un \\(80\\%\\) de los datos totales para el entrenamiento, dejando el \\(20-30\\%\\) restante para llevar a cabo la validación cruzada.\nAunque esta técnica suele ser efectiva, su utilidad puede verse comprometida en casos de disponibilidad limitada de datos. En tales situaciones, existe la posibilidad de que se pierda información relevante durante el entrenamiento, lo que podría resultar en sesgos significativos en los resultados obtenidos.\nNo obstante, en escenarios donde la cantidad de datos es suficientemente amplia y la distribución entre los conjuntos es equilibrada, este enfoque se muestra completamente apropiado.\n\n\n\n6.8.2 Validación cruzada de \\(K\\) pliegues\n\nLa técnica validación cruzada de \\(K\\) pliegues se caracteriza por su accesibilidad y su reconocimiento generalizado en el ámbito de la validación cruzada. En comparación con otros métodos de validación cruzada, tiende a proporcionar modelos con un menor sesgo (Zhang (1993)).\nEsta técnica asegura que todas las observaciones originales de la serie de datos tengan la oportunidad de formar parte tanto del conjunto de entrenamiento como del conjunto de prueba. Es especialmente valiosa en situaciones donde los datos de entrada son limitados.\nEl proceso comienza al dividir de manera aleatoria la serie de datos en \\(K\\) pliegues. El parámetro \\(K\\) determina el número de grupos en los que se dividirá la muestra.\nEs fundamental elegir un valor adecuado para \\(K\\), evitando que sea demasiado bajo o demasiado alto. Usualmente, se selecciona un valor entre \\(5\\) y \\(10\\) dependiendo del tamaño de la serie de datos. Por ejemplo, si \\(K=10\\), la serie de datos se divide en \\(10\\) partes iguales.\nUn valor de \\(K\\) más alto reduce el sesgo del modelo, pero una varianza excesiva puede conducir al sobreajuste. Un valor más bajo equivale prácticamente al enfoque de división de datos en entrenamiento y prueba.\n\n\n\n\n\nMcCulloch, Warren S, y Walter Pitts. 1943. «A logical calculus of the ideas immanent in nervous activity». The bulletin of mathematical biophysics 5: 115-33.\n\n\nMontesinos López, Osval Antonio, Abelardo Montesinos López, y Jose Crossa. 2022. «Fundamentals of Artificial Neural Networks and Deep Learning». En Multivariate Statistical Machine Learning Methods for Genomic Prediction, 379-425. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-89010-0_10.\n\n\nRosenblatt, Frank. 1960. «Perceptron simulation experiments». Proceedings of the IRE 48 (3): 301-9.\n\n\nSosa Jerez, Lexly Vanessa, Laura Camila Zamora Alvarado, et al. s. f. «Estructura de redes neuronales (MLP) y su aplicación como aproximador universal». {B.S.} thesis.\n\n\nStewart, J. 2017. Cálculo de varias variables: trascendentes tempranas. Cengage Learning. https://books.google.com.mx/books?id=bKSvtAEACAAJ.\n\n\nZhang, Ping. 1993. «Model Selection Via Multifold Cross Validation». The Annals of Statistics 21 (1): 299-313. http://www.jstor.org/stable/3035592.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "estudio.html",
    "href": "estudio.html",
    "title": "Estudio de caso",
    "section": "",
    "text": "Modelación y pronóstico del número de casos confirmados y fallecidos por COVID-19 en IRÁN",
    "crumbs": [
      "Estudio de caso"
    ]
  },
  {
    "objectID": "estudio.html#modelación-y-pronóstico-del-número-de-casos-confirmados-y-fallecidos-por-covid-19-en-irán",
    "href": "estudio.html#modelación-y-pronóstico-del-número-de-casos-confirmados-y-fallecidos-por-covid-19-en-irán",
    "title": "Estudio de caso",
    "section": "",
    "text": "A finales de diciembre de 2019, se identificó la aparición de un nuevo virus en Wuhan, China, el cual manifestó un impacto agudo en el sistema respiratorio y presentó una rápida propagación. La Organización Mundial de la Salud (OMS) catalogó este virus como el SARS-CoV-2, perteneciente a la familia de los coronavirus. Aunque algunas investigaciones y evidencias sugieren que los murciélagos podrían ser el origen principal del COVID-19, esta afirmación aún no está definitivamente confirmada y requiere una mayor investigación. Esta enfermedad infecciosa aguda se caracteriza por su alta tasa de contagio, lo que llevó a declararla una pandemia global debido a su rápida expansión y diseminación a nivel mundial.\nLos síntomas comunes de esta enfermedad incluyen complicaciones respiratorias, tos seca, fiebre, escalofríos, dificultad para respirar, dolor torácico, neumonía, entre otros. No obstante, a medida que progresa la enfermedad, los síntomas en los pacientes evolucionan y varían.\nUna de las principales problemáticas asociadas a este virus es su periodo de incubación de hasta 14 días, durante el cual puede transmitirse la infección sin presentar síntomas. Además, algunas personas infectadas con el COVID-19 manifiestan síntomas leves, similares a un resfriado común o a la gripe. Esta pandemia ha ejercido una presión significativa sobre los gobiernos y los sistemas de salud pública. La escasez de equipamiento médico en hospitales, incluyendo camas, unidades de cuidados intensivos, personal médico, ventiladores, entre otros, constituye uno de los principales desafíos. Asimismo, han surgido repercusiones económicas y sociales a raíz de la propagación de la enfermedad y la implementación de cuarentenas estrictas, lo que ha afectado la salud mental de las comunidades, entre otros aspectos.\n\n\n\n\n\nEl surgimiento de las problemáticas mencionadas, sumado a la ausencia de tratamientos definitivos para esta enfermedad, la naturaleza dinámica del virus y su propagación global, subraya la necesidad de investigar exhaustivamente este virus y su comportamiento. Se han explorado diversos campos y metodologías de pronóstico y modelización. Uno de estos enfoques de pronóstico radica en la creación de modelos para anticipar el número de casos futuros, basados en registros de casos confirmados. Aunque las proyecciones sobre el número de pacientes futuros no son totalmente precisas, sirven de apoyo a los gobiernos y a los responsables de políticas de salud para adoptar decisiones cruciales y aplicar restricciones que reduzcan la prevalencia. Asimismo, resulta crucial anticipar futuros brotes, posibles mutaciones del virus y su propagación, especialmente identificar el pico para mitigar sus efectos graves. Estas proyecciones asisten a los tomadores de decisiones para prevenir e incluso controlar la propagación de la enfermedad mediante políticas efectivas y rigurosas. Cabe destacar que la falta de información suficiente con anticipación constituye uno de los desafíos principales en el pronóstico, aunque sigue siendo una herramienta de orientación efectiva para los gobiernos en la contención de la enfermedad.\nPor consiguiente, dado el papel potencialmente efectivo de los modelos estadísticos y matemáticos en la predicción de la tendencia futura de la enfermedad, en este estudio se emplearon dos modelos, Holt-Winter y MLP (Multilayer Perceptron), con el propósito de determinar el mejor modelo para pronosticar, de manera independiente, el número de casos confirmados y muertes en Irán para los próximos 30 días.\nEn el presente estudio, se utilizó el conjunto de datos disponible en el sitio web https://www.who.int/, el cual contempla el número absoluto de casos confirmados y muertes por día, excluyendo otros factores debido a su falta de disponibilidad.\nEl análisis a realizar tiene como propósito verificar los resultados obtenidos en el estudio de Talkhi et al. (2021) .\n\n\n\n\n\nTalkhi, Nasrin, Narges Akhavan Fatemi, Zahra Ataei, y Mehdi Jabbari Nooghabi. 2021. «Modeling and forecasting number of confirmed and death caused COVID-19 in IRAN: A comparison of time series forecasting methods». Biomedical signal processing and control 66: 102494.",
    "crumbs": [
      "Estudio de caso"
    ]
  },
  {
    "objectID": "confirmados.html",
    "href": "confirmados.html",
    "title": "7  Pronóstico de infectados diarios",
    "section": "",
    "text": "7.1 Obtención de datos\nCódigo\n# Se crea un objeto 'Date' diario\ninds &lt;- seq(as.Date(\"2020-02-20\"), as.Date(\"2020-08-15\"), by = \"day\")\n# Se crea un objeto 'serie de tiempo' de frecuencia diaria\nConfirmed_ts &lt;- ts(Confirmed_df[2], \n                   start = c(2020, as.numeric(format(inds[1], \"%j\"))),\n                   frequency = 365)\nLa gráfica de la Figura 7.1 exhibe la serie temporal derivada de la base de datos, en la cual se evidencia la ausencia de información para los días 27 y 29 de Febrero, así como para el 02 de Marzo y el 05 de Abril de 2020. Para subsanar esta carencia de datos, se llevó a cabo una interpolación promedio a fin de sustituir los valores faltantes. La Tabla 7.1 muestra la base de datos con las modificaciones efectuadas, así como la serie de tiempo (Figura 7.2) resultante de estas correcciones.\nTabla 7.1: Casos confirmados ajustados del 20-02-2020 al 15-08-2020",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pronóstico de infectados diarios</span>"
    ]
  },
  {
    "objectID": "confirmados.html#obtención-de-datos",
    "href": "confirmados.html#obtención-de-datos",
    "title": "7  Pronóstico de infectados diarios",
    "section": "",
    "text": "Conforme se ha referido previamente, se emplea el conjunto de datos global informado diariamente, disponible para su descarga en https://covid19.who.int/WHO-COVID-19-global-data.csv. Resulta relevante destacar que la base de datos consultada corresponde al 16 de Enero del 2023, restringiéndose a los datos concernientes exclusivamente a los casos confirmados en Irán entre el 20 de febrero y el 15 de agosto de 2020.\nEl análisis posterior se ha llevado a cabo empleando el software R versión 4.3.2. Con el propósito de realizar el análisis de los datos y la generación de gráficos, se procedió a convertir los datos al formato ts, lo que permitió su representación como una serie temporal.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.1: Serie de tiempo de los casos de COVID-19 confirmados en Irán del 20-02-2020 al 15-08-2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.2: Serie de tiempo de los casos de COVID-19 confirmados en Irán del 20-02-2020 al 15-08-2020",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pronóstico de infectados diarios</span>"
    ]
  },
  {
    "objectID": "confirmados.html#análisis-de-la-serie-de-tiempo-de-casos-confirmados-de-covid-19-en-irán",
    "href": "confirmados.html#análisis-de-la-serie-de-tiempo-de-casos-confirmados-de-covid-19-en-irán",
    "title": "7  Pronóstico de infectados diarios",
    "section": "7.2 Análisis de la serie de tiempo de casos confirmados de COVID-19 en Irán",
    "text": "7.2 Análisis de la serie de tiempo de casos confirmados de COVID-19 en Irán\n\n7.2.1 Estadística descriptiva\n\nCon el propósito de llevar a cabo una auditoría de los datos y al mismo tiempo una descripción preliminar, se ejecuta un estudio de estadística descriptiva que arroja los resultados correspondientes, incluyendo un gráfico Boxplot (Figura 7.3) para representar la información o\n\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      3    1304    2181    1923    2529    3574 \n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.3: Boxplot de casos confirmados de COVID-19 en Irán del 20-02-2020 al 15-08-2020\n\n\n\n\n\n7.2.2 Componentes de la serie de tiempo\n\nLos componentes identificados en la serie de tiempo de casos confirmados de COVID-19 en Irán, revelan distintos patrones y características.\nEn primer lugar, se observa una tendencia discernible en el gráfico de la serie temporal (Figura 7.2). Por ejemplo, entre el 30 de marzo y el 03 de mayo de 2020, se evidencia una tendencia negativa o decreciente, seguida por una tendencia creciente a partir del 03 de mayo en adelante. Estos cambios en la tendencia podrían indicar fluctuaciones significativas en la evolución de los casos confirmados durante esos periodos específicos.\nEn cuanto a la estacionalidad, aunque no se identifica claramente a simple vista en el periodo observado, la extensión del análisis a un periodo más amplio podría revelar patrones recurrentes o ciclos temporales característicos. Es posible que ciertos patrones estacionales se manifiesten en intervalos más extensos de la serie temporal, lo que implicaría variaciones sistemáticas y repetitivas en los datos en períodos específicos.\nPor último, se destacan pequeñas subidas y bajadas en el gráfico que sugieren la presencia de ruido en la serie temporal. Estas fluctuaciones irregulares podrían atribuirse a diversas causas, como posibles errores en la recolección de datos o fluctuaciones aleatorias inherentes al comportamiento de la enfermedad. Es importante considerar estas variaciones no sistemáticas al analizar la serie temporal, ya que podrían influir en la interpretación de los patrones y tendencias observadas.\n\n\n\n7.2.3 Estacionariedad\n\nA continuación, se emplea el test de Dickey-Fuller para examinar la presencia de estacionariedad en la serie temporal. Este test fue utilizado con la finalidad de identificar la existencia de raíces unitarias en la serie, lo cual permite inferir la presencia o ausencia de estacionariedad en los datos analizados.\n\n\n\nCódigo\nadf.test(Confirmed_ts, alternative = \"stationary\")\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Confirmed_ts\nDickey-Fuller = -2.9529, Lag order = 5, p-value = 0.1781\nalternative hypothesis: stationary\n\n\n\nLa hipótesis nula \\((H_0)\\) asume la presencia de raíces unitarias, lo que indica no estacionariedad en la serie. Al obtener un \\(p-\\)valor superior al nivel de significancia establecido el cuál es del \\(95\\%\\), no se rechaza la hipótesis nula, sugiriendo la ausencia de estacionariedad en la serie de tiempo de casos confirmados.\nAdemás, se complementa la evaluación de la estacionalidad mediante la inspección de los gráficos de la función de autocorrelación (ACF) y la función de autocorrelación parcial (PACF). Estos gráficos se utilizan para identificar patrones de autocorrelación en la serie temporal, lo que permite visualizar la presencia de estacionalidad, tendencias o ciclos.\n\n\nLa serie de tiempo representada en la Figura 7.2 exhibe un comportamiento característico de deambulación aleatoria. Dado que el valor de la variable \\(X_{t+1}\\) generalmente se encuentra en proximidad al valor \\(X_t\\), se evidencia una autocorrelación positiva notablemente marcada entre las variables \\(X_t\\) y \\(X_{t+1}\\).\n\nCódigo\nautoplot(acf(Confirmed_ts, plot = FALSE), \n         main=\"Autocorrelograma de casos confirmados\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.4: Autocorrelograma de los casos confirmados de COVID-19 en Irán\n\n\n\nEn la Figura 7.4 se observa que la autocorrelación (vea Ecuación 5.2) entre \\(X_t\\) y \\(X_{t+k}\\) decrece con el incremento del retraso \\(k\\). Este declive conduce a la constatación de que, a un desfase de \\(20\\), existe una correlación bastante débil entre \\(X_t\\) y \\(X_{t+20}\\). Al analizar el gráfico de la función de autocorrelación (ACF), se aprecia que \\(\\rho_{20}\\approx 0.19\\).\nLa gráfica de la Función de Autocorrelación Parcial (PACF) proporciona información valiosa sobre la estructura de autocorrelación de una serie temporal una vez han sido eliminadas las correlaciones debidas a los intervalos de tiempo intermedios.\n\nCódigo\nggPacf((Confirmed_ts), main = 'Autocorrelograma parcial de casos confirmados')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.5: Autocorrelograma Parcial de los casos confirmados de COVID-19 en Irán\n\n\n\nConsiderando que los datos se ajustan a un modelo de series de tiempo, la Figura 7.5 indica que el valor de correlación \\(\\phi_{15}\\) es ligeramente superior a \\(0.25\\), aproximadamente \\(\\phi_{52}\\approx 0.16\\), y \\(\\phi_{76}\\approx 0.15\\), mientras que para los restantes valores, la correlación parcial no es nula.\n\nObservación. De acuerdo con la gráfica de la Función de Autocorrelación Parcial Figura 7.5, se observa un corte abrupto después del rezago 4, lo cual sugiere que las autocorrelaciones parciales más allá de ese punto no poseen significancia estadística. Por consiguiente, se infiere la posibilidad de ajustar un modelo autoregresivo AR(4) a la base de datos.\n\n\nCódigo\nlibrary(tswge)\ncoeff &lt;- est.ar.wge(Confirmed_ts, p=4)\n\n\n  \n  \nCoefficients of AR polynomial:  \n0.8656 0.1724 0.0592 -0.1318 \n\n                           AR Factor Table \nFactor                 Roots                Abs Recip    System Freq \n1-0.9605B              1.0411               0.9605       0.0000\n1-0.5355B              1.8675               0.5355       0.0000\n1+0.6303B+0.2563B^2   -1.2298+-1.5459i      0.5062       0.3570\n  \n  \n\n\nCódigo\ncoeff$phi #coeficientes\n\n\n[1]  0.86563811  0.17237111  0.05917558 -0.13180534\n\n\nCódigo\ncoeff$xbar #media\n\n\n[1] 1922.868\n\n\nCódigo\ncoeff$avar #varianza finita\n\n\n[1] 47818.04\n\n\nEl modelo autoregresivo AR(4) se expresa mediante la siguiente ecuación:\n\\[\n(1-0.865B-0.172B^2-0.059B^3+0.131B^4)(X_t-1922.868)+a_t\n\\tag{7.1}\\]\ndonde \\(\\hat{\\sigma}_a^2 = 47818.04\\).\n\n\n\nEl análisis del ACF y PACF proporcionó información sobre la relación de los puntos de datos con sus rezagos, permitiendo observar posibles patrones estacionales. La presencia de picos significativos en estos gráficos podría indicar la existencia de estacionalidad en la serie de tiempo.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pronóstico de infectados diarios</span>"
    ]
  },
  {
    "objectID": "confirmados.html#entrenamiento-modelado-pronóstico-y-métricas-de-rendimiento",
    "href": "confirmados.html#entrenamiento-modelado-pronóstico-y-métricas-de-rendimiento",
    "title": "7  Pronóstico de infectados diarios",
    "section": "7.3 Entrenamiento, modelado, pronóstico y métricas de rendimiento",
    "text": "7.3 Entrenamiento, modelado, pronóstico y métricas de rendimiento\n\nSe procede a la evaluación del rendimiento de métodos destinados al ajuste y consecuente pronóstico. Específicamente, se contempla el método de suavizamiento exponencial de Holt-Winters y el ajuste mediante un modelo de red neuronal del tipo perceptrón multicapa. Ambos procedimientos requieren la subdivisión de los datos en conjuntos destinados a entrenamiento y prueba. El set inicial, compuesto por el \\(70\\%\\) de los datos, se emplea para el entrenamiento de los modelos, mientras que el \\(30\\%\\) restante se reservará para llevar a cabo las pruebas pertinentes.\n\n\n\nCódigo\nConfirmed_ts &lt;- ts(Confirmed_ts,frequency=1)\ntsize &lt;- round(0.7 * nrow(Confirmed_df))\ntrain_confirmed &lt;- window(Confirmed_ts,end=tsize)\ntest_confirmed &lt;- window(Confirmed_ts,start=tsize+1)\n\n\n\n7.3.1 Holt-Winters\n\nCon el fin de determinar la descomposición más adecuada para los datos en cuestión, se empleó un criterio elaborado basado en el coeficiente de variación, el cual proporciona una recomendación entre las dos versiones disponibles.\n\n\nCódigo\nDescRec &lt;- function(x){\n  n = length(x)\n  di = rep(0, n-1)\n  ci = rep(0, n-1)\n  for (i in 1:n-1) {\n    di[i] = x[i+1] - x[i]\n    ci[i] = x[i+1] / x[i]\n  }\n  d &lt;- cv(di) \n  c &lt;- cv(ci) / mean(di)\n  if(d &lt; c)\n    print(\"Se recomienda la descomposición aditiva\")\n  else\n    print(\"Se recomienda la descomposición multiplicativa\")\n}\nDescRec(train_confirmed)\n\n\n[1] \"Se recomienda la descomposición multiplicativa\"\n\n\nDe acuerdo con la recomendación observada, se sugiere la utilización de la versión multiplicativa (vea Ecuación 5.19). En consecuencia, se procede a mostrar la representación gráfica de la descomposición multiplicativa de la serie temporal.\n\nCódigo\nts_train &lt;- ts(train_confirmed, frequency = 2)\ncomponents_ts &lt;- decompose(ts_train, type = 'mult')\nplot(components_ts)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.6: Descomposición multiplicativa de la serie de tiempo\n\n\n\nSe procede ahora a la aplicación del modelo multiplicativo de Holt-Winters a la serie temporal de los datos de entrenamiento utilizando una frecuencia de dos, con el fin de permitir la aplicabilidad del modelo.\n\n\n\nCódigo\nHWc &lt;- HoltWinters(ts_train, seasonal = 'mult')\nHWc\n\n\nHolt-Winters exponential smoothing with trend and multiplicative seasonal component.\n\nCall:\nHoltWinters(x = ts_train, seasonal = \"mult\")\n\nSmoothing parameters:\n alpha: 0.729859\n beta : 0\n gamma: 0.6494094\n\nCoefficients:\n          [,1]\na  2289.283568\nb     2.250000\ns1    1.119185\ns2    1.113547\n\n\n\nFinalmente, utilizando el modelo de entrenamiento desarrollado en la fase previa, se lleva a cabo la proyección con un horizonte de predicción igual en extensión a los datos de prueba, acompañado de un intervalo de confianza que oscila entre el \\(80\\%\\) y el \\(95\\%\\).\n\n\n\nCódigo\nHWc_for &lt;- forecast(HWc, h=length(test_confirmed))\n\n\n\n\n\n\n\n\nNota\n\n\n\nLas funciones aplicadas en esta sección son parte de la librería stats  (2023) de R.\n\n\n\n\n7.3.2 MLP\n\nPosteriormente, se procede al entrenamiento del modelo MLP (Perceptrón Multicapa). La cantidad de capas ocultas y la configuración de nodos en cada capa se determinaron de manera automatizada mediante el método de validación cruzada de 5 pliegues. Asimismo, se eligió la función de activación como sigmoide, y el proceso de entrenamiento del modelo se ejecutó a lo largo de 20 iteraciones.\n\n\n\nCódigo\nfitc &lt;- mlp(train_confirmed, hd.auto.type=\"cv\", reps=20, comb='median')\nfitc\n\n\nMLP fit with 1 hidden node and 20 repetitions.\nUnivariate lags: (1,2,4)\nForecast combined using the median operator.\nMSE: 57247.6692.\n\n\n\nCódigo\nplot(fitc)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.7: Estructura de la red neuronal resultante\n\n\n\n\nPara llevar a cabo el pronóstico, se emplea el modelo de entrenamiento creado en la etapa anterior, manteniendo un horizonte de predicción que coincide en duración con los datos de prueba, tal como se hizo con la técnica anterior.\n\n\n\nCódigo\nfrcc &lt;- forecast(fitc,h=length(test_confirmed))\n\n\n\n\n\n\n\n\nNota\n\n\n\nLas funciones aplicadas en esta sección son parte de la librería nnfor Kourentzes (2022) de R.\n\n\n\n\n7.3.3 Comparación de pronósticos con el conjunto de datos de prueba\n\nCon el propósito de llevar a cabo un análisis cuantitativo exhaustivo, se presenta a continuación una tabla comparativa de los resultados derivados de las dos técnicas implementadas y la base de datos de prueba. Posteriormente, se exhiben gráficas representativas de estos resultados. En la Figura 7.8 se muestra el pronóstico mediante Holt-Winters acompañado de su respectivo intervalo de confianza. En contraste, en la Figura 7.9, la gráfica punteada en color rojo representa el comportamiento real de los datos, mientras que en azul se representa el pronóstico obtenido a través de la red MLP.\n\n\n\n\n\nTabla 7.2: Comparación de Resultados entre las técnicas y los datos reales para evaluar precisión\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.8: Pronóstico obtenido mediante la técnica de Holt-Winters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.9: Pronóstico obtenido mediante la red neuronal MLP.\n\n\n\n\n7.3.3.1 Métricas de rendimiento\n\nPara evaluar la calidad o bondad de ajuste de los métodos utilizados en este estudio y seleccionar el modelo más apropiado, se aplican tres métricas de rendimiento, Error Cuadrático Medio (Ecuación 5.31), Error Absoluto Medio (Ecuación 5.29) y Error Porcentual Absoluto Medio (Ecuación 5.32) tanto en las fases de entrenamiento como en las de prueba. Los resultados correspondientes a éstas métricas se presentan en la Tabla 7.3 .\n\n\n\nTabla 7.3: Errores de los modelos para casos confirmados.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraining\n\n\nTesting\n\n\n\n\nRMSE\nMAE\nMAPE\nRMSE\nMAE\nMAPE\n\n\nHolt-Winters\n262.9925\n190.0482\n20.8415\n234.0094\n165.8208\n6.2967\n\n\nMLP\n239.3483\n180.9937\n14.6079\n177.0605\n136.4799\n5.4441\n\n\n\n\n\n\n\n\n\n\n7.3.4 Conclusión\n\nBasándose en los resultados extraídos tanto de la tabla de pronósticos (Tabla 7.2) como de la tabla de errores (Tabla 7.3), se llega a la conclusión de que, para esta base de datos en particular, la técnica de redes neuronales MLP demuestra ser más efectiva en la predicción realizada. Esto se fundamenta en la evidencia de un menor error registrado en las tres métricas calculadas, tanto durante la fase de entrenamiento como en la fase de prueba.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pronóstico de infectados diarios</span>"
    ]
  },
  {
    "objectID": "confirmados.html#pronóstico-de-los-próximos-30-días",
    "href": "confirmados.html#pronóstico-de-los-próximos-30-días",
    "title": "7  Pronóstico de infectados diarios",
    "section": "7.4 Pronóstico de los próximos 30 días",
    "text": "7.4 Pronóstico de los próximos 30 días\nTras la identificación del modelo óptimo, se procedió a prever el comportamiento futuro de la serie temporal de casos confirmados para los próximos 30 días utilizando dicho modelo. Se elaboraron representaciones gráficas de la predicción de casos confirmados de COVID-19 a 30 días, realizando una comparación de la efectividad entre las implementaciones de redes neuronales en la paquetería de R y la paquetería nativa de Python, las cuales se encuentran en las figuras Figura 7.10 y Figura 7.11, respectivamente.\n\n7.4.1 Implementación en R\n\nEn la implementación de R, siguiendo el mismo procedimiento que en las fases de entrenamiento y prueba, se empleó un número específico de capas y nodos ocultos determinados automáticamente a través del método de validación cruzada de 5 pliegues. Esta configuración se llevó a cabo con una función de activación sigmoide, ejecutando 20 iteraciones para el entrenamiento de la red neuronal.\n\n\nCódigo\nfit.mlp = mlp(ts(Confirmed_df$Confirmed), reps = 20, hd.auto.type = 'cv', \n              comb=\"median\")\nfore.mlp = forecast(fit.mlp, h = 30)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.10: Predicción futura de la serie tiempo para infectados diariamente mediante el modelo MLP\n\n\n\n\nLos resultados del pronóstico indican que el 14 de septiembre de 2020 se proyectan aproximadamente 2494 nuevos casos confirmados de COVID-19. Estos valores correspondientes al período de 30 días se detallan a continuación en la Tabla 7.4 .\n\n\n\n\n\nTabla 7.4: Pronóstico de casos confirmados de COVID-19 en Irán en los próximos 30 días\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.4.2 Implementación en Python\n\nEn esta sección, se realizaron ajustes en el método para su implementación. Cada día proyectado se forma utilizando el dato del día anterior. En cada paso, se actualiza la secuencia de entrada eliminando el valor más antiguo e incorporando la predicción más reciente como el dato más reciente. Esta dinámica se representa esquemáticamente a continuación, donde \\(n\\) representa la extensión de la secuencia de entrada y \\(T\\) es la longitud de la serie temporal.\n\\[\n\\begin{split}\ny:\\text{Observado}\\quad &\\quad \\hat{y}:\\text{Pronosticado}\\\\\ny_{T-n+1}\\quad y_{T-n+2}\\quad y_{T-n+3}\\quad&\\cdots\\quad y_{T-2}\\quad y_{T-1}\\quad y_T\\quad \\to\\quad \\hat{y}_{T+1}\\\\\ny_{T-n+2}\\quad y_{T-n+3}\\quad y_{T-n+4}\\quad&\\cdots\\quad y_{T-1}\\quad y_{T}\\quad \\hat{y}_{T+1}\\quad \\to\\quad \\hat{y}_{T+2}\\\\\ny_{T-n+3}\\quad y_{T-n+4}\\quad y_{T-n+5}\\quad&\\cdots\\quad y_{T}\\quad \\hat{y}_{T+1}\\quad \\hat{y}_{T+2}\\quad \\to\\quad \\hat{y}_{T+3}\\\\\n&\\ddots\\\\\n\\end{split}\n\\]\nSe exhibe a continuación el código utilizado y el gráfico correspondiente al pronóstico generado por la red neuronal.\n\n\n\n\n\n\n\n▸ Código\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport yfinance as yf\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.preprocessing import MinMaxScaler\n\npd.options.mode.chained_assignment = None\ntf.random.set_seed(0)\ndf = pd.read_excel('Data.xlsx')\n\n# ------------- Entrenamiento y prueba del modelo --------------\ny = df['Confirmed'].fillna(method='ffill')\ny = y.values.reshape(-1, 1)\n# scale the data\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler = scaler.fit(y)\ny = scaler.transform(y)\n\n# generate the input and output sequences\nn_lookback = 53  # length of input sequences (lookback period)\nn_forecast = 30  # length of output sequences (forecast period)\n\nX = []\nY = []\n\nfor i in range(n_lookback, len(y) - n_forecast + 1):\n    X.append(y[i - n_lookback: i])\n    Y.append(y[i: i + n_forecast])\n\nX = np.array(X)\nY = np.array(Y)\n\n# fit the model\nmodel = Sequential()\nmodel.add(Dense(20, activation='sigmoid', input_dim=n_lookback))\nmodel.add(Dense(n_forecast))\n\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X, Y, epochs=20, batch_size=4, verbose=0)\n\n# generate the forecasts\nX_ = y[- n_lookback:]  # last available input sequence\nX_ = X_.reshape(1, n_lookback, 1)\n\nY_ = model.predict(X_).reshape(-1, 1)\nY_ = scaler.inverse_transform(Y_)\n\n# organize the results in a data frame\ndf_past = df\ndf_past.rename(columns={'Date':'Date','Confirmed':'Actual'},inplace=True)\ndf_past['Date'] = pd.to_datetime(df_past['Date'])\ndf_past['Forecast'] = np.nan\ndf_past['Forecast'].iloc[-1] = df_past['Actual'].iloc[-1]\n\ndf_future = pd.DataFrame(columns=['Date', 'Actual', 'Forecast'])\ndf_future['Date'] = pd.date_range(\n  start=df_past['Date'].iloc[-1] + pd.Timedelta(days=1), \n  periods=n_forecast)\ndf_future['Forecast'] = Y_.flatten()\ndf_future['Actual'] = np.nan\n\nresults = df_past._append(df_future).set_index('Date')\n# Calculate minimum, median, and maximum for each forecasted date\nresults['Min'] = results['Forecast'].rolling(window=2).min()\nresults['Max'] = results['Forecast'].rolling(window=2).max()\nresults['Median'] = results['Forecast'].rolling(window=2).median()\n\n# Creamos la gráfica con las predicciones\n#fig = px.line(results, x=results.index, y=['Actual','Forecast', 'Median'],\nfig = px.line(results, x=results.index, y=['Actual', 'Median'],\n              labels={'index': 'Date', 'value': 'Confirmed Cases'},\n              title='Casos Confirmados',\n              line_shape='linear')\n\nfig.update_traces(line=dict(color='cornflowerblue'), \nselector=dict(name='Actual'))\nfig.update_traces(line=dict(color='orange'), \nselector=dict(name='Forecast'))\nfig.update_traces(line=dict(color='mediumvioletred'), \nselector=dict(name='Median'))\n\n# Agregar gráficos de área para el mínimo y el máximo\nfig.add_trace(\n    go.Scatter(x=results.index, \n    y=results['Min'], \n    fill=None, mode='lines', \n    line=dict(color='hotpink'), \n    name='Min'))\nfig.add_trace(\n    go.Scatter(x=results.index, \n    y=results['Max'], \n    fill='tonexty', \n    mode='lines', \n    line=dict(color='deeppink'), \n    name='Max'))\nfig.show('')\n\n\n\n\n\n\n\n                        \n                                            \n\n\nFigura 7.11: Pronóstico de casos confirmados de COVID-19 en Irán en los próximos 30 días (implementación en python)\n\n\n\n\n\nLos resultados del pronóstico en Figura 7.11 indican que el 14 de Septiembre de 2020 se proyectan aproximadamente 2476 nuevos casos confirmados de COVID-19.\n\n\n\n\n\nKourentzes, Nikolaos. 2022. «nnfor: Time Series Forecasting with Neural Networks». https://CRAN.R-project.org/package=nnfor.\n\n\nR Core Team. 2023. «R: A Language and Environment for Statistical Computing». https://www.R-project.org/.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pronóstico de infectados diarios</span>"
    ]
  },
  {
    "objectID": "muertes.html",
    "href": "muertes.html",
    "title": "8  Pronóstico de decesos diarios",
    "section": "",
    "text": "8.1 Pronóstico, comparación y métricas de rendimiento\nCódigo\nDeaths_ts &lt;- ts(Deaths_ts,frequency=1) \ntsize &lt;- round(0.7 * nrow(Deaths_df)) \ntrain_deaths &lt;- window(Deaths_ts,end=tsize) \ntest_deaths &lt;- window(Deaths_ts,start=tsize+1)\nTabla 8.1: Comparación de Resultados entre las técnicas y los datos reales para evaluar precisión",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pronóstico de decesos diarios</span>"
    ]
  },
  {
    "objectID": "muertes.html#pronóstico-comparación-y-métricas-de-rendimiento",
    "href": "muertes.html#pronóstico-comparación-y-métricas-de-rendimiento",
    "title": "8  Pronóstico de decesos diarios",
    "section": "",
    "text": "La evaluación del desempeño de los métodos se realiza a través de la separación del conjunto de datos en entrenamiento y prueba. El set inicial, compuesto por el \\(70\\%\\) de los datos, se emplea para el entrenamiento de los modelos, mientras que el \\(30\\%\\) restante se reservará para llevar a cabo las pruebas pertinentes.\n\n\n\nCon el propósito de llevar a cabo un análisis cuantitativo exhaustivo, se presenta a continuación una tabla comparativa de los resultados derivados de las dos técnicas implementadas (después de realizar el entrenamiento, modelado y pronóstico), y la base de datos de prueba. Posteriormente, se exhiben gráficas representativas de estos resultados. En la Figura 8.2 se muestra el pronóstico mediante Holt-Winters acompañado de su respectivo intervalo de confianza. En contraste, en la Figura 8.3, la gráfica punteada en color rojo representa el comportamiento real de los datos, mientras que en azul se representa el pronóstico obtenido a través de la red MLP.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.2: Pronóstico obtenido mediante la técnica de Holt-Winters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.3: Pronóstico obtenido mediante la red neuronal MLP.\n\n\n\n\nA través de las Figura 8.2 y Figura 8.3, se observa que el pronóstico derivado de la técnica Holt-Winters muestra una mayor proximidad al comportamiento de la gráfica real.\nUtilizando las métricas RMSE, MAE y MAPE, se lleva a cabo la evaluación de la calidad o bondad de ajuste de los métodos empleados en este estudio con el fin de seleccionar el modelo más adecuado.\n\n\n\n\nTabla 8.2: Errores de los modelos para casos confirmados.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraining\n\n\nTesting\n\n\n\n\nRMSE\nMAE\nMAPE\nRMSE\nMAE\nMAPE\n\n\nHolt-Winters\n12.6365\n9.6103\n19.4096\n34.0665\n25.5356\n12.9770\n\n\nMLP\n11.7584\n8.8446\n15.6144\n67.2031\n59.7811\n49.0686\n\n\n\n\n\n\n\nLos resultados derivados de la tabla de errores (Tabla 8.2) llevan a la conclusión de que, en esta base de datos específica, a pesar de que la red MLP exhibe errores más reducidos durante la fase de entrenamiento, la técnica de Holt-Winters presenta un error considerablemente menor en la etapa de prueba en comparación con MLP. Esto evidencia su mayor eficacia en la predicción realizada. Por consiguiente, se recomienda el uso del método Holt-Winters para llevar a cabo el pronóstico de los próximos 30 días.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pronóstico de decesos diarios</span>"
    ]
  },
  {
    "objectID": "muertes.html#pronóstico-de-los-próximos-30-días",
    "href": "muertes.html#pronóstico-de-los-próximos-30-días",
    "title": "8  Pronóstico de decesos diarios",
    "section": "8.2 Pronóstico de los próximos 30 días",
    "text": "8.2 Pronóstico de los próximos 30 días\nTras la identificación del modelo óptimo, se procedió a prever el comportamiento futuro de la serie temporal de casos de muerte para los próximos 30 días utilizando dicho modelo. Se elaboraron representaciones gráficas de la predicción de estos casos, realizando una comparación de la efectividad entre las implementaciones de redes neuronales en la paquetería de R y la paquetería nativa de Python, las cuales se encuentran en las figuras Figura 8.4 y Figura 8.5, respectivamente.\n\n8.2.1 Implementación en R\n\n\nCódigo\nHW_deaths &lt;- HoltWinters(ts(Deaths_df$Deaths,frequency = 2)) \nHW_for_d &lt;- forecast(HW_deaths, h=30, level=c(80,95)) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.4: Predicción futura de la serie tiempo para decesos diarios mediante el modelo Holt-Winters.\n\n\n\n\nLos resultados del pronóstico indican que el 14 de septiembre de 2020 se proyectan 184 nuevos casos de muerte por COVID-19. Estos valores correspondientes al período de 30 días se detallan a continuación en la Tabla 8.3 .\n\n\n\n\n\nTabla 8.3: Pronóstico de decesos por COVID-19 en Irán en los próximos 30 días\n\n\n\n\n\n\n\n\n\n\n\n\n8.2.2 Implementación en Python\n\n\n\n\n\n\n▸Código\n\n\n\n\n\nimport numpy as np \nimport pandas as pd \nimport plotly.express as px \nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\n\n# Importación de los datos de CASOS DE MUERTE del 20-02 al 15-08-2020\ndata = pd.read_excel('muertes.xlsx')\ndf = pd.DataFrame(data)\n\n# Configurar el modelo Holt-Winters\nmodel = ExponentialSmoothing(df['Deaths'], trend='add', \nseasonal='add',seasonal_periods=14)\nmodel_fit = model.fit(optimized=True)\n\n# Generar predicciones\nforecast_days = 30  # Número de días a predecir\nforecast = model_fit.forecast(steps=forecast_days)\n\n# Crear un DataFrame con las fechas de predicción\nforecast_dates = pd.date_range(start=df['Date'].max() + \npd.Timedelta(days=1), periods=forecast_days, freq='D')\n\n# Agregar las fechas y valores predichos al DataFrame original\nforecast_df = pd.DataFrame({'Date': forecast_dates, \n'Forecast': forecast})\ndf_t = pd.concat([df, forecast_df])\n\n# Crear una gráfica interactiva con Plotly\nfig = px.line(df, x='Date', y='Deaths',title='Holt-Winters Forecast', \nlabels={'Deaths': 'Deaths'})\nfig.add_scatter(x=forecast_dates, y=forecast, mode='lines', \nname='Forecast', line=dict(color='red'))\nfig.show()\n\n\n\n\n\n\n\n                        \n                                            \n\n\nFigura 8.5: Pronóstico de casos de muerte por COVID-19 en Irán en los próximos 30 días (implementación en Python)\n\n\n\n\n\nLos resultados del pronóstico en la Figura 8.5 indican que el 14 de septiembre de 2020 se proyectan aproximadamente 132 nuevos casos de muerte por COVID-19.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pronóstico de decesos diarios</span>"
    ]
  },
  {
    "objectID": "conclusiones.html",
    "href": "conclusiones.html",
    "title": "9  Conclusiones",
    "section": "",
    "text": "El presente estudio ha abordado la complejidad inherente a la modelación y pronóstico del número de casos confirmados y fallecidos por COVID-19 en Irán. A través de un análisis exhaustivo de datos recopilados hasta el 16 de enero de 2023, focalizado en el período comprendido entre el 20 de febrero y el 15 de agosto de 2020, se ha explorado la eficacia de distintos métodos de predicción. Los resultados obtenidos han arrojado luces sobre la idoneidad de las técnicas utilizadas y han resaltado la importancia de considerar diversos factores al seleccionar el enfoque predictivo más adecuado.\nDurante el periodo analizado, se ha constatado que la técnica de redes neuronales Perceptrón Multicapa (MLP) muestra una notable eficacia en la predicción de la evolución de los casos confirmados de COVID-19. En contraste, para los fallecimientos asociados a esta enfermedad, la técnica de suavizamiento exponencial de Holt-Winters ha demostrado ser más precisa. Estos hallazgos subrayan la relevancia de adaptar el enfoque predictivo según las características específicas de los datos.\nAdemás, aunque el análisis de estacionariedad no se ha incluido en esta etapa de la investigación, es importante reconocer que tanto la base de datos de casos confirmados como la de fallecimientos por COVID-19 han sido identificadas como no estacionarias. Este aspecto añade un nivel adicional de complejidad al proceso de modelación y predicción de estos eventos epidemiológicos.\nEn cuanto a las métricas de error utilizadas, se ha observado una variabilidad significativa entre las bases de datos de casos confirmados y de muerte. Mientras que en la primera, los errores RMSE y MAE han mostrado valores elevados, la métrica MAPE ha emergido como la más adecuada tanto en la fase de entrenamiento como en la de prueba. Por otro lado, en la base de datos de fallecimientos, las tres métricas de error han mostrado una mayor coherencia, reflejando la naturaleza menos oscilante de estos datos.\nEn relación a la efectividad entre las implementaciones de Holt-Winters y Perceptrón Multicapa en R y Python, se ha observado un rendimiento superior de Python en términos de capacidad para visualizar detalladamente el comportamiento de las predicciones. Si bien las implementaciones en Python han sido enriquecidas con modificaciones que pueden influir en los resultados, especialmente en el caso de la técnica de redes neuronales, este enfoque ha permitido un análisis más profundo de los datos.\nEs crucial recalcar la importancia de limitar el horizonte de predicción para evitar estimaciones poco fiables. Aunque se haya respetado la cantidad de días predichos con el objetivo de corroborar los hallazgos del estudio, se reconoce que esta elección puede influir en la precisión de las predicciones. Por lo tanto, se recomienda ejercer prudencia al establecer el horizonte de predicción en futuros estudios epidemiológicos, considerando cuidadosamente las limitaciones de los datos y los métodos de análisis utilizados.\nFinalmente, una posible extensión de este trabajo para abordar la no estacionariedad de la serie temporal sería considerar la serie como la solución de un modelo epidemiológico SIR con perturbaciones aleatorias. Estos supuestos conducen al planteamiento del SIR como una ecuación diferencial estocástica con parámetros de transmisión y de recuperación desconocidos. El problema a resolver consistiría, en general, en desarrollar un algoritmo para muestrear la serie de tiempo con el fin de estimar dichos parámetros desconocidos de forma recursiva para el pronóstico de una cantidad limitada de días.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Conclusiones</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ash, R. B., and C. A. Doleans-Dade. 2000. Probability and Measure\nTheory. Elsevier Science. https://books.google.com.mx/books?id=GkqQoRpCO2QC.\n\n\nCastañeda, L. B., V. Arunachalam, and S. Dharmaraja. 2014.\nIntroduction to Probability and Stochastic Processes with\nApplications. Wiley. https://books.google.com.mx/books?id=M0hYBAAAQBAJ.\n\n\nDickey, David A, and Wayne A Fuller. 1979. “Distribution of the\nEstimators for Autoregressive Time Series with a Unit Root.”\nJournal of the American Statistical Association 74 (366a):\n427–31.\n\n\nDickey, David Alan. 1976. Estimation and Hypothesis Testing in\nNonstationary Time Series. Iowa State University.\n\n\nFuller, W. A. 1995. Introduction to Statistical Time Series.\nWiley Series in Probability and Statistics. Wiley. https://books.google.com.mx/books?id=wyRhjmAPQIYC.\n\n\nHarvey, AC. 1981. “The Econometric Analysis of Time Series. Philip\nAllan.” Oxford.\n\n\nHolt, Charles C. 1957. “Forecasting Trends and Seasonals by\nExponentially Weighted Moving Averages.” ONR Memorandum\n52 (52): 5–10.\n\n\nKourentzes, Nikolaos. 2022. “Nnfor: Time Series Forecasting with\nNeural Networks.” https://CRAN.R-project.org/package=nnfor.\n\n\nLipschutz, S. 1996. Probabilidad. McGraw-Hill. https://books.google.com.mx/books?id=vndlwgEACAAJ.\n\n\nMann, P. S. 2010. Introductory Statistics. John Wiley &\nSons. https://books.google.com.mx/books?id=N_mEBiCYaqkC.\n\n\nMcCulloch, Warren S, and Walter Pitts. 1943. “A Logical Calculus\nof the Ideas Immanent in Nervous Activity.” The Bulletin of\nMathematical Biophysics 5: 115–33.\n\n\nMontesinos López, Osval Antonio, Abelardo Montesinos López, and Jose\nCrossa. 2022. “Fundamentals of Artificial Neural Networks and Deep\nLearning.” In Multivariate Statistical Machine Learning\nMethods for Genomic Prediction, 379–425. Cham: Springer\nInternational Publishing. https://doi.org/10.1007/978-3-030-89010-0_10.\n\n\nMood, A. M. F., F. A. Graybill, and D. C. Boes. 1986. Introduction\nto the Theory of Statistics. McGraw-Hill Series in Probability and\nStatistics. https://books.google.com.mx/books?id=bKHBjgEACAAJ.\n\n\nR Core Team. 2023. “R: A Language and Environment for Statistical\nComputing.” https://www.R-project.org/.\n\n\nRosenblatt, Frank. 1960. “Perceptron Simulation\nExperiments.” Proceedings of the IRE 48 (3): 301–9.\n\n\nRoss, S. M. 1995. Stochastic Processes. Wiley Series in\nProbability and Mathematical Statistics. Wiley. https://books.google.com.mx/books?id=qiLdCQAAQBAJ.\n\n\nSegall, R. S., and G. Niu. 2022. Biomedical and Business\nApplications Using Artificial Neural Networks and Machine Learning.\nAdvances in Computational Intelligence and Robotics. IGI Global. https://books.google.com.mx/books?id=9G9bEAAAQBAJ.\n\n\nSosa Jerez, Lexly Vanessa, Laura Camila Zamora Alvarado, et al. n.d.\n“Estructura de Redes Neuronales (MLP) y Su Aplicación\nComo Aproximador Universal.” {B.S.} thesis.\n\n\nStewart, J. 2017. Cálculo de Varias Variables:\nTrascendentes Tempranas. Cengage Learning. https://books.google.com.mx/books?id=bKSvtAEACAAJ.\n\n\nTalkhi, Nasrin, Narges Akhavan Fatemi, Zahra Ataei, and Mehdi Jabbari\nNooghabi. 2021. “Modeling and Forecasting Number of Confirmed and\nDeath Caused COVID-19 in IRAN: A Comparison of Time Series Forecasting\nMethods.” Biomedical Signal Processing and Control 66:\n102494.\n\n\nWackerly, D. D., D. D. Wackerly, W. Mendenhall, and R. L. Scheaffer.\n2009. Estadı́stica Matemática Con\nAplicaciones. CENGAGE Learning. https://books.google.com.mx/books?id=8bTfwAEACAAJ.\n\n\nWaldmeier, Max. 1961. “The Sunspot-Activity in the Years\n1610-1960.” Zurich: Schulthess.\n\n\nWinters, Peter R. 1960. “Forecasting Sales by Exponentially\nWeighted Moving Averages.” Management Science 6 (3):\n324–42.\n\n\nWoodward, W. A., B. P. Sadler, and S. Robertson. 2022. Time Series\nfor Data Science: Analysis and Forecasting. A Chapman & Hall\nBook. CRC Press, Taylor & Francis Group. https://books.google.com.mx/books?id=gM3gzgEACAAJ.\n\n\nYaglom, A. M. 1962. An Introduction to the Theory of Stationary\nRandom Functions. Selected Russian Publications in the Mathematical\nSciences. Prentice-Hall. https://books.google.com.mx/books?id=l_JvAAAAIAAJ.\n\n\nYule, George Udny. 1971. “On a Method of Investigating\nPeriodicities in Disturbed Series with Special Reference to Wolfer’s\nSunspot Numbers.” Statistical Papers of George Udny\nYule, 389–420.\n\n\nZhang, Ping. 1993. “Model Selection via Multifold Cross\nValidation.” The Annals of Statistics 21 (1): 299–313.\nhttp://www.jstor.org/stable/3035592.",
    "crumbs": [
      "References"
    ]
  }
]