<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Análisis comparativo del desempeño en métodos para el pronóstico de series temporales - 6&nbsp; Redes Neuronales</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./estudio.html" rel="next">
<link href="./series.html" rel="prev">
<link href="./logofcfm.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Análisis comparativo del desempeño en métodos para el pronóstico de series temporales - 6&nbsp; Redes Neuronales">
<meta property="og:image" content="logofcfm.png">
<meta property="og:site_name" content="Análisis comparativo del desempeño en métodos para el pronóstico de series temporales">
<meta name="twitter:title" content="Análisis comparativo del desempeño en métodos para el pronóstico de series temporales - 6&nbsp; Redes Neuronales">
<meta name="twitter:image" content="logofcfm.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./redes.html">Redes neuronales</a></li><li class="breadcrumb-item"><a href="./redes.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Redes Neuronales</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./logounach.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Análisis comparativo del desempeño en métodos para el pronóstico de series temporales</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/Jennlg/Tesis/tree/main/book/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Tesis_JSLG.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Tesis_JSLG.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Alternar modo oscuro"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Alternar modo lector">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Resumen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introducción</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./objetivos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Objetivos</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Preliminares</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tconjuntos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Teoría de conjuntos</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probabilidad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probabilidad</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estadistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Estadística</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./procesos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Procesos estocásticos</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Series de tiempo</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Series de Tiempo</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Redes neuronales</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./redes.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Redes Neuronales</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./estudio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Estudio de caso</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./confirmados.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pronóstico de infectados diarios</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./muertes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Pronóstico de decesos diarios</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusiones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Conclusiones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#elementos-fundamentales-de-las-redes-neuronales-artificiales" id="toc-elementos-fundamentales-de-las-redes-neuronales-artificiales" class="nav-link active" data-scroll-target="#elementos-fundamentales-de-las-redes-neuronales-artificiales"><span class="header-section-number">6.1</span> Elementos fundamentales de las Redes Neuronales Artificiales</a></li>
  <li><a href="#arquitectura" id="toc-arquitectura" class="nav-link" data-scroll-target="#arquitectura"><span class="header-section-number">6.2</span> Arquitectura</a>
  <ul class="collapse">
  <li><a href="#perceptrón-simple" id="toc-perceptrón-simple" class="nav-link" data-scroll-target="#perceptrón-simple"><span class="header-section-number">6.2.1</span> Perceptrón simple</a></li>
  <li><a href="#sec-arqmlp" id="toc-sec-arqmlp" class="nav-link" data-scroll-target="#sec-arqmlp"><span class="header-section-number">6.2.2</span> Perceptrón Multicapa (MLP)</a></li>
  </ul></li>
  <li><a href="#perceptrón" id="toc-perceptrón" class="nav-link" data-scroll-target="#perceptrón"><span class="header-section-number">6.3</span> Perceptrón</a>
  <ul class="collapse">
  <li><a href="#teorema-de-convergencia-del-perceptrón" id="toc-teorema-de-convergencia-del-perceptrón" class="nav-link" data-scroll-target="#teorema-de-convergencia-del-perceptrón"><span class="header-section-number">6.3.1</span> Teorema de convergencia del perceptrón</a></li>
  </ul></li>
  <li><a href="#funciones-de-activación" id="toc-funciones-de-activación" class="nav-link" data-scroll-target="#funciones-de-activación"><span class="header-section-number">6.4</span> Funciones de activación</a>
  <ul class="collapse">
  <li><a href="#lineal" id="toc-lineal" class="nav-link" data-scroll-target="#lineal"><span class="header-section-number">6.4.1</span> Lineal</a></li>
  <li><a href="#sigmoide" id="toc-sigmoide" class="nav-link" data-scroll-target="#sigmoide"><span class="header-section-number">6.4.2</span> Sigmoide</a></li>
  <li><a href="#unidad-lineal-rectificadora-relu" id="toc-unidad-lineal-rectificadora-relu" class="nav-link" data-scroll-target="#unidad-lineal-rectificadora-relu"><span class="header-section-number">6.4.3</span> Unidad lineal rectificadora (ReLu)</a></li>
  <li><a href="#relu-con-fugas" id="toc-relu-con-fugas" class="nav-link" data-scroll-target="#relu-con-fugas"><span class="header-section-number">6.4.4</span> ReLu con fugas</a></li>
  <li><a href="#tangente-hiperbólica" id="toc-tangente-hiperbólica" class="nav-link" data-scroll-target="#tangente-hiperbólica"><span class="header-section-number">6.4.5</span> Tangente hiperbólica</a></li>
  <li><a href="#softmax" id="toc-softmax" class="nav-link" data-scroll-target="#softmax"><span class="header-section-number">6.4.6</span> Softmax</a></li>
  </ul></li>
  <li><a href="#funciones-de-coste" id="toc-funciones-de-coste" class="nav-link" data-scroll-target="#funciones-de-coste"><span class="header-section-number">6.5</span> Funciones de coste</a></li>
  <li><a href="#gradiente-descendente" id="toc-gradiente-descendente" class="nav-link" data-scroll-target="#gradiente-descendente"><span class="header-section-number">6.6</span> Gradiente descendente</a>
  <ul class="collapse">
  <li><a href="#algoritmo-gradiente-descendente" id="toc-algoritmo-gradiente-descendente" class="nav-link" data-scroll-target="#algoritmo-gradiente-descendente"><span class="header-section-number">6.6.1</span> Algoritmo gradiente descendente</a></li>
  </ul></li>
  <li><a href="#perceptrón-multicapa" id="toc-perceptrón-multicapa" class="nav-link" data-scroll-target="#perceptrón-multicapa"><span class="header-section-number">6.7</span> Perceptrón Multicapa</a>
  <ul class="collapse">
  <li><a href="#entrenamiento-y-aprendizaje-del-perceptrón-multicapa" id="toc-entrenamiento-y-aprendizaje-del-perceptrón-multicapa" class="nav-link" data-scroll-target="#entrenamiento-y-aprendizaje-del-perceptrón-multicapa"><span class="header-section-number">6.7.1</span> Entrenamiento y aprendizaje del Perceptrón Multicapa</a></li>
  </ul></li>
  <li><a href="#evaluación-de-modelos-de-aprendizaje-automático" id="toc-evaluación-de-modelos-de-aprendizaje-automático" class="nav-link" data-scroll-target="#evaluación-de-modelos-de-aprendizaje-automático"><span class="header-section-number">6.8</span> Evaluación de modelos de aprendizaje automático</a>
  <ul class="collapse">
  <li><a href="#división-de-datos-en-entrenamiento-y-prueba" id="toc-división-de-datos-en-entrenamiento-y-prueba" class="nav-link" data-scroll-target="#división-de-datos-en-entrenamiento-y-prueba"><span class="header-section-number">6.8.1</span> División de datos en entrenamiento y prueba</a></li>
  <li><a href="#sec-validación-cruzada-de-k-pliegues" id="toc-sec-validación-cruzada-de-k-pliegues" class="nav-link" data-scroll-target="#sec-validación-cruzada-de-k-pliegues"><span class="header-section-number">6.8.2</span> Validación cruzada de <span class="math inline">\(K\)</span> pliegues</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/Jennlg/Tesis/edit/main/book/redes.qmd" class="toc-action"><i class="bi bi-github"></i>Editar esta página</a></li><li><a href="https://github.com/Jennlg/Tesis/issues/new" class="toc-action"><i class="bi empty"></i>Informar de un problema</a></li><li><a href="https://github.com/Jennlg/Tesis/blob/main/book/redes.qmd" class="toc-action"><i class="bi empty"></i>Ver el código</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./redes.html">Redes neuronales</a></li><li class="breadcrumb-item"><a href="./redes.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Redes Neuronales</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Redes Neuronales</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div style="text-align: justify">
<p>El funcionamiento de los cerebros de humanos y otros animales es intrigante porque son capaces de realizar tareas muy complejas en un tiempo muy corto y con alta eficiencia. Por ejemplo, las señales de los sensores en el cuerpo transmiten información relacionada con la vista, el oído, el gusto, el olfato, el tacto, el equilibrio, la temperatura, el dolor, etc. Luego, las neuronas del cerebro, que son unidades autónomas, transmiten, procesan y almacenan esta información para que se pueda responder con éxito a estímulos externos e internos. Las neuronas de muchos animales transmiten picos de actividad eléctrica a través de una hebra larga y delgada llamada axón. Un axón se divide en miles de terminales o ramas, donde, según el tamaño de la señal, se conectan a dendritas de otras neuronas (<a href="#fig-neubio" class="quarto-xref">Figura&nbsp;<span>6.1</span></a>). Se estima que el cerebro está compuesto por alrededor de <span class="math inline">\(10^{11}\)</span> neuronas que trabajan en paralelo, ya que el procesamiento realizado por las neuronas y la memoria capturada por las sinapsis se distribuyen juntas sobre la red. La cantidad de información procesada y almacenada depende de los niveles umbral de disparo y también del peso dado por cada neurona a cada una de sus entradas. Una de las características de las neuronas biológicas, a las que deben su gran capacidad para procesar y realizar tareas altamente complejas, es que están altamente conectadas con otras neuronas de las cuales reciben estímulos de un evento a medida que ocurre, o cientos de señales eléctricas con la información aprendida.</p>
<p>Las redes neuronales tienen sus raíces en la búsqueda de emular el funcionamiento del cerebro humano en la década de 1940. <span class="citation" data-cites="mcculloch1943logical">McCulloch y Pitts (<a href="references.html#ref-mcculloch1943logical" role="doc-biblioref">1943</a>)</span> propusieron el concepto inicial de una “neurona artificial” que podría realizar operaciones lógicas básicas. Sin embargo, fue en la década de 1950 cuando el psicólogo Frank Rosenblatt desarrolló el “perceptrón”, <span class="citation" data-cites="rosenblatt1960perceptron">Rosenblatt (<a href="references.html#ref-rosenblatt1960perceptron" role="doc-biblioref">1960</a>)</span>, un tipo de red neuronal que podía aprender a reconocer patrones a través de entrenamiento.</p>
<p>A pesar de su potencial, las limitaciones del perceptrón y la falta de avances en la capacidad computacional llevaron a un declive en la investigación en redes neuronales en los años siguientes. Sin embargo, en la década de 1980 y 1990, hubo un resurgimiento del interés debido a nuevos algoritmos de aprendizaje y avances en el hardware, permitiendo el entrenamiento de redes más complejas.</p>
<p>La importancia de las redes neuronales en la predicción de datos radica en su capacidad para aprender patrones y relaciones en conjuntos de datos vastos y complejos. A través del proceso de entrenamiento, una red neuronal ajusta sus pesos y conexiones internas para capturar características relevantes en los datos. Esto les permite realizar tareas como clasificación y regresión, lo que a su vez permite la predicción de resultados futuros.</p>
<p>Con el tiempo, las redes neuronales se han vuelto más sofisticadas, dando lugar a arquitecturas como las redes neuronales convolucionales (CNN) para el procesamiento de imágenes y las redes neuronales recurrentes (RNN) para el procesamiento de secuencias. Además, el surgimiento del aprendizaje profundo (deep learning) ha permitido el entrenamiento de redes neuronales con muchas capas, lo que ha mejorado significativamente su capacidad para abordar problemas complejos de predicción.</p>
</div>
<div id="fig-neubio" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-neubio-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/rna.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="626">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-neubio-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6.1: Representación gráfica de una neurona biológica
</figcaption>
</figure>
</div>
<section id="elementos-fundamentales-de-las-redes-neuronales-artificiales" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="elementos-fundamentales-de-las-redes-neuronales-artificiales"><span class="header-section-number">6.1</span> Elementos fundamentales de las Redes Neuronales Artificiales</h2>
<div style="text-align: justify">
<p>Para obtener una comprensión clara de los principales elementos utilizados para construir modelos de redes neuronales artificiales (RNA), en la <a href="#fig-modelogen" class="quarto-xref">Figura&nbsp;<span>6.2</span></a> se presenta un modelo general de red neuronal artificial que incorpora los componentes fundamentales para este tipo de modelos.</p>
<div id="fig-modelogen" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-modelogen-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/modgen.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-modelogen-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6.2: Modelo general de redes neuronales artificiales.
</figcaption>
</figure>
</div>
<p>La información de entrada, <span class="math inline">\(x_1, ..., x_p\)</span>, es recibida por la neurona del sistema sensorial externo u otras neuronas con las que tiene conexión. El vector de pesos sinápticos <span class="math inline">\(\mathbf{w} = (w_1, ..., w_p)\)</span> modifica la información recibida emulando la sinapsis entre las neuronas biológicas. Estos pueden interpretarse como ganancias que pueden atenuar o amplificar los valores que desean propagar hacia la neurona. El parámetro <span class="math inline">\(b_j\)</span> se conoce como el sesgo (intercepto o umbral) de una neurona. En redes neuronales artificiales, el aprendizaje se refiere al método de modificar los pesos de las conexiones entre los nodos (neuronas) de una red especificada.</p>
<p>Los valores recibidos por la neurona son ajustados por los pesos sinápticos y que sumados para generar la entrada neta, expresada matemáticamente como:</p>
<p><span class="math display">\[v_j=\sum_{j=1}^p \omega_{ij}x_j\]</span></p>
<p>La entrada neta <span class="math inline">\((v_j)\)</span> determina si la neurona se activa o no. La activación de la neurona depende de la función de activación, evaluándose la entrada neta en dicha función para obtener la salida de la red, como se ilustra a continuación:</p>
<p><span class="math display">\[
y_j=g(v_j)
\]</span></p>
<p>donde <span class="math inline">\(g\)</span> representa la función de activación. Por ejemplo, si se define esta función como un escalón unitario (también llamado umbral), la salida será <span class="math inline">\(1\)</span> si la entrada neta es mayor que cero; de lo contrario, la salida será <span class="math inline">\(0\)</span>.</p>
<p>Aunque no existe un comportamiento biológico análogo a las neuronas cerebrales, el uso de la función de activación es un artificio que permite aplicar RNA a una variedad de problemas reales. La salida <span class="math inline">\(y_j\)</span> de la neurona se genera al evaluar la entrada neta <span class="math inline">\((v_j)\)</span> en la función de activación, pudiendo propagarse a otras neuronas o ser la salida final de la red, con una interpretación específica según la aplicación.</p>
<p>En términos generales, el funcionamiento de un modelo de red neuronal artificial se lleva a cabo mediante elementos simples denominados neuronas. Las señales se transmiten entre neuronas a través de enlaces de conexión, cada uno con un peso asociado que multiplica la señal transmitida. Cada neurona aplica una función de activación (generalmente no lineal) a las entradas de la red (suma ponderada de las señales de entrada) para determinar su signo correspondiente.</p>
<p>Un modelo de RNA de una sola capa, como el presentado en la <a href="#fig-modelogen" class="quarto-xref">Figura&nbsp;<span>6.2</span></a>, posee una capacidad de procesamiento limitada por sí mismo y una aplicabilidad reducida; su verdadero poder radica en la interconexión de múltiples redes neuronales artificiales, similiar al funcionamiento del cerebro humano. Este enfoque ha motivado a diversos investigadores a proponer diversas arquitecturas para la interconexión de neuronas en el contexto de RNA. A continuación, se presentan las definiciones de RNA y aprendizaje profundo (<span class="citation" data-cites="MontesinosLópez2022">Montesinos López, Montesinos López, y Crossa (<a href="references.html#ref-MontesinosLópez2022" role="doc-biblioref">2022</a>)</span>).</p>
</div>
<div id="def-ANN" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.1 (Red Neuronal Artificial)</strong></span> Una red neuronal artificial es un sistema compuesto por numerosos elementos de procesamiento simples que operan en paralelo, y cuya función está determinada por la estructura de la red y el peso de las conexiones. En cada uno de los nodos o elementos de cómputo, que posee una capacidad de procesamiento baja, se lleva a cabo el procesamiento.</p>
</div>
<div id="def-AP" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.2 (Aprendizaje profundo)</strong></span> Se define el aprendizaje profundo como una generalización de RNA donde se utilizan más de una capa oculta, lo que implica que se utilizan más neuronas para implementar el modelo. Por esta razón, a una red neuronal artificial con múltiples capas ocultas se le llama Red Neuronal Profunda (RNP) y la práctica de entrenar este tipo de redes se llama aprendizaje profundo (AP).</p>
</div>
<div style="text-align: justify">
<p>Para una comprensión más completa de los elementos que componen una red neuronal artificial, resulta crucial diferenciar entre las diversas categorías de capas y tipos de neuronas. Por consiguiente, se procede a detallar los tipos de capas seguido por una exposición más detallada de los tipos de neuronas.</p>
<ol type="a">
<li><p><strong>Capa de entrada:</strong> Es el conjunto de neuronas que recibe directamente la información proveniente de las fuentes externas de la red. En el contexto de la <a href="#fig-rnp" class="quarto-xref">Figura&nbsp;<span>6.3</span></a>, esta información es <span class="math inline">\(x_1, ... ,x_8\)</span>. Por lo tanto, el número de neuronas en una capa de entrada es la mayoría de las veces igual al número de variables explicativas de entrada proporcionadas a la red. Por lo general, las capas de entrada están seguidas por al menos una capa oculta. Solo en las redes neuronales feedforward, las capas de entrada están completamente conectadas a la siguiente capa oculta.</p></li>
<li><p><strong>Capas ocultas:</strong> Consisten en un conjunto de neuronas internas de la red que no tienen contacto directo con el exterior. El número de capas ocultas puede ser <span class="math inline">\(0, 1\)</span> o más. En general, las neuronas de cada capa oculta comparten el mismo tipo de información; por esta razón, se llaman capas ocultas. Las neuronas de las capas ocultas pueden estar interconectadas de diferentes maneras; esto determina, junto con su número, las diferentes arquitecturas de RNA y RNP. La información aprendida extraída de los datos de entrenamiento se almacena y captura mediante los valores de peso de las conexiones entre las capas de la red neuronal artificial. Además, es importante señalar que las capas ocultas son componentes clave para capturar de manera más eficiente comportamientos no lineales complejos de los datos.</p></li>
<li><p><strong>Capa de salida:</strong> Es un conjunto de neuronas que transfiere la información procesada por la red hacia el exterior. En la <a href="#fig-rnp" class="quarto-xref">Figura&nbsp;<span>6.3</span></a>, las neuronas de salida corresponden a las variables de salida <span class="math inline">\(y_1, y_2, y_3\)</span> e <span class="math inline">\(y_4\)</span>. Esto implica que la capa de salida proporciona la respuesta o predicción del modelo de red neuronal artificial basada en la entrada proveniente de la capa de entrada. La salida final puede ser continua, binaria, ordinal o de conteo, dependiendo de la configuración de la RNA, la cual está controlada por la función de activación especificada en las neuronas de la capa de salida.</p></li>
</ol>
</div>
<div id="fig-rnp" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rnp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/RNP.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rnp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6.3: Red neuronal artificial profunda feedforward con ocho variables de entrada, cuatro variables de salida y dos capas ocultas con tres neuronas cada una
</figcaption>
</figure>
</div>
<div style="text-align: justify">
<p>A continuación, se definen los tipos de neuronas:</p>
<ol type="1">
<li><p><strong>Neurona de entrada</strong>: Una neurona que recibe entradas externas desde fuera de la red.</p></li>
<li><p><strong>Neurona de salida</strong>: Una neurona que produce algunas de las salidas de la red.</p></li>
<li><p><strong>Neurona oculta</strong>: Una neurona que no tiene interacción directa con el “mundo exterior” sino solo con otras neuronas dentro de la red. Una terminología similar se utiliza a nivel de capa para redes neuronales multicapa.</p></li>
</ol>
<p>Como se aprecia en la <a href="#fig-rnp" class="quarto-xref">Figura&nbsp;<span>6.3</span></a>, la disposición de las neuronas en una red neuronal artificial se lleva a cabo mediante la formación de niveles que contienen un número específico de neuronas. Cuando un conjunto de neuronas artificiales recibe simultáneamente el mismo tipo de información, se le denomina capa. Además, se hace referencia a una red compuesta por tres tipos de niveles como capas. La <a href="#fig-estructuras" class="quarto-xref">Figura&nbsp;<span>6.4</span></a> exhibe otras seis redes con diversos números de capas, y la mitad de ellas (<a href="#fig-a" class="quarto-xref">Figura&nbsp;<span>6.4 (a)</span></a>, <a href="#fig-c" class="quarto-xref">Figura&nbsp;<span>6.4 (c)</span></a>, <a href="#fig-e" class="quarto-xref">Figura&nbsp;<span>6.4 (e)</span></a>) son univariadas, ya que la variable de respuesta a predecir es única, mientras que la otra mitad (<a href="#fig-b" class="quarto-xref">Figura&nbsp;<span>6.4 (b)</span></a>, <a href="#fig-d" class="quarto-xref">Figura&nbsp;<span>6.4 (d)</span></a>, <a href="#fig-f" class="quarto-xref">Figura&nbsp;<span>6.4 (f)</span></a>) son multivariadas, dado que la red tiene el propósito de predecir dos salidas. Es relevante destacar que los paneles a y b en la <a href="#fig-estructuras" class="quarto-xref">Figura&nbsp;<span>6.4</span></a> representan redes con solo una capa y sin capas ocultas; por consiguiente, este tipo de redes corresponde a modelos convencionales de regresión o clasificación por regresión.</p>
<div id="fig-estructuras" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-estructuras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-estructuras" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-a" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/a.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-estructuras">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Salida unicapa y univariante.
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-estructuras" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-b" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-b-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/b.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-estructuras">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-b-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Salida unicapa y multivariante.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-estructuras" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-c" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-c-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/c.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-estructuras">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-c-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Salida univariante y de tres capas.
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-estructuras" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-d" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/d.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-estructuras">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d) Salida multivariante y de tres capas.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-estructuras" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-e" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/e.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-estructuras">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(e) Salida univariante de cuatro capas.
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-estructuras" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-f" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-f-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/f.png" class="img-fluid quarto-figure quarto-figure-center figure-img" data-ref-parent="fig-estructuras">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-f-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(f) Salida multivariante de cuatro capas.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-estructuras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6.4: Diferentes estructuras de redes neuronales univariadas y multivariadas.
</figcaption>
</figure>
</div>
<p>En consecuencia, la arquitectura de una red neuronal artificial se refiere a la manera en que las neuronas están organizadas en la red, y está estrechamente vinculada al algoritmo de aprendizaje empleado para entrenar la red. Según el número de capas, clasificamos las redes como monocapa o multicapa; y si consideramos la dirección del flujo de información como criterio clasificatorio, las redes se denominan de avance o recurrentes. Cada tipo de arquitectura se aborda la siguiente sección.</p>
</div>
</section>
<section id="arquitectura" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="arquitectura"><span class="header-section-number">6.2</span> Arquitectura</h2>
<section id="perceptrón-simple" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="perceptrón-simple"><span class="header-section-number">6.2.1</span> Perceptrón simple</h3>
<div style="text-align: justify">
<p>El <em>perceptrón simple</em> consta de cuatro componentes fundamentales en su estructura. Estos son: las entradas (input) con conexiones y pesos (nodos ponderados), el nodo de procesamiento o suma, la función de activación y las salidas (output). El nodo de procesamiento realiza una regresión lineal, involucrando la suma ponderada de los pesos en cada nodo de las entradas y un término de sesgo o término independiente. En esencia, el perceptrón simple funciona como un discriminador lineal que, a partir de un umbral establecido, produce una salida binaria.</p>
<p>Desde una perspectiva matemática, el perceptrón simple se representa mediante la siguiente ecuación:</p>
<p><span id="eq-perceptron"><span class="math display">\[
\hat{\mathbf{y}}(\mathbf x)=f(\mathbf w^T\mathbf x+b).
\tag{6.1}\]</span></span></p>
<p>La arquitectura que modela esta ecuación se describe a través de la <a href="#fig-arqper" class="quarto-xref">Figura&nbsp;<span>6.5</span></a>.</p>
<div id="fig-arqper" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-arqper-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/perceptron.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-arqper-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6.5: Arquitectura de un perceptrón simple
</figcaption>
</figure>
</div>
<p>donde <span class="math inline">\(\mathbf x\)</span> denota el vector de entradas, <span class="math inline">\(\mathbf w\)</span> denota el vector de pesos asociados a cada nodo, <span class="math inline">\(b\)</span> denota el sesgo o intercepto de la regresión, <span class="math inline">\(\sum\)</span> denota el nodo de procesamiento o combinador lineal, y <span class="math inline">\(f\)</span> denota la función de activación o función limitadora, siendo esta última una transformación no lineal de la regresión obtenida en el nodo de procesamiento.</p>
<p>Aunque el perceptrón simple demuestra eficacia en el aprendizaje y la resolución de problemas linealmente separables, como las compuertas lógicas <em>AND</em> (<a href="#fig-and" class="quarto-xref">Figura&nbsp;<span>6.6 (b)</span></a>) y <em>OR</em> (<a href="#fig-or" class="quarto-xref">Figura&nbsp;<span>6.6 (a)</span></a>) , presenta limitaciones en la resolución de problemas que no son de este tipo. Un ejemplo paradigmático de ello es su incapacidad para clasificar las salidas de una compuerta lógica del tipo <em>XOR</em> (<a href="#fig-xor" class="quarto-xref">Figura&nbsp;<span>6.6 (c)</span></a>), ya que el nodo de procesamiento solo permite la separación de la información mediante una única recta de regresión.</p>
</div>
<div id="fig-compuertas" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-compuertas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-compuertas" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-or" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-or-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Imagenes/or.png" class="img-fluid figure-img" data-ref-parent="fig-compuertas"></p>
<figcaption>OR</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-or-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-compuertas" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-and" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-and-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Imagenes/and.png" class="img-fluid figure-img" data-ref-parent="fig-compuertas"></p>
<figcaption>AND</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-and-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-compuertas" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-xor" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-xor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Imagenes/XOR.png" class="img-fluid figure-img" data-ref-parent="fig-compuertas"></p>
<figcaption>XOR</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-xor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-compuertas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6.6: Compuertas lógicas
</figcaption>
</figure>
</div>
</section>
<section id="sec-arqmlp" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="sec-arqmlp"><span class="header-section-number">6.2.2</span> Perceptrón Multicapa (MLP)</h3>
<div style="text-align: justify">
<p>La solución al problema de la puerta lógica <em>XOR</em> consiste en la adición de una neurona adicional, permitiendo así la definición de una nueva recta de regresión, como se ilustra en la <a href="#fig-xor" class="quarto-xref">Figura&nbsp;<span>6.6 (c)</span></a>. Esto conduce a la creación de lo que se conoce como <em>Perceptrón Multicapa</em> o <em>MLP</em> (por sus siglas en inglés), también reconocido como <em>Red Neuronal Profunda</em>. Esta estructura representa una generalización del perceptrón simple, incorporando más de un nivel de neuronas y/o una o varias capas de neuronas “entre” la capa de entradas y la capa de salidas, las cuales son denominadas capas ocultas. En estas capas ocultas, las funciones de activación entre las neuronas no son necesariamente lineales. Las MLP son consideradas las redes neuronales artificiales por defecto y se representan mediante un diagrama simple, que transmite las entradas de capa en capa hasta alcanzar la capa final.</p>
<p>La red neuronal de la <a href="confirmados.html#fig-mlp" class="quarto-xref">Figura&nbsp;<span>7.11</span></a> ejemplifica un MLP de dos capas ocultas. En esta representación, los superíndices indican la posición en las capas, mientras que los subíndices indican la posición relativa de cada nodo en su respectiva capa. La red consta de un vector de entradas <span class="math inline">\(\mathbf{x} \in \mathbb{R}^{d_0}\)</span>, donde <span class="math inline">\(\mathbf{x} = (x_1, \ldots, x_{d_0})^T\)</span>, capas ocultas denotadas por <span class="math inline">\(a^l\)</span>, y un vector de salidas <span class="math inline">\(\hat{y} \in \mathbb{R}^{d_L}\)</span> con <span class="math inline">\(\hat{y} = (\hat{y}_1, \ldots,\hat y_{d_L})^T\)</span>. Las capas ocultas contienen nodos de procesamiento o neuronas representadas por <span class="math inline">\(a = f(z)\)</span>, donde <span class="math inline">\(f\)</span> es la función de activación de cada capa y <span class="math inline">\(z\)</span> es un combinador lineal (matricial). Las conexiones entre las capas están ponderadas por <span class="math inline">\(\mathbf{w}\)</span>, que representa las matrices de pesos asociadas en cada capa. Por ejemplo, <span class="math inline">\(w_{ij}^1\)</span> representa el peso asociado a la conexión entre la entrada j-ésima y el i-ésimo nodo de procesamiento en la primera capa oculta. Las matrices <span class="math inline">\(\mathbf{w}^l\)</span> tienen dimensiones <span class="math inline">\((d_l \times d_{l-1})\)</span>, donde la capa de entrada se considera como capa cero <span class="math inline">\((l = 0)\)</span>.</p>
<p>Es importante destacar que el término <span class="math inline">\(b\)</span>, que indica el sesgo en el perceptrón simple, también se incluye en la red MLP en cada nodo de procesamiento, específicamente en el combinador lineal <span class="math inline">\(z\)</span>. A partir de este momento, el nodo de procesamiento incorporará el término de sesgo <span class="math inline">\(b\)</span>, y <span class="math inline">\(b^1 \in a^1\)</span> denotará el vector de sesgo en la primera capa oculta.</p>
<div id="fig-mlp" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mlp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Imagenes/mlp.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mlp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6.7: Red neuronal MLP con dos capas ocultas (<span class="citation" data-cites="sosaestructura">Sosa Jerez, Zamora Alvarado, et&nbsp;al. (<a href="references.html#ref-sosaestructura" role="doc-biblioref">s.&nbsp;f.</a>)</span>).
</figcaption>
</figure>
</div>
<p>La ecuación matemática que describe la red de la <a href="confirmados.html#fig-mlp" class="quarto-xref">Figura&nbsp;<span>7.11</span></a> es la siguiente:</p>
<p><span class="math display">\[
\begin{split}\hat{\mathbf{y}} &amp;= f^3(z^3) \\&amp;= f^3(\mathbf{w}^3 a^2 + b^3) \\&amp;= f^3(\mathbf{w}^3 (f^2(z^2)) + b^3) \\&amp;= f^3(\mathbf{w}^3 (f^2(\mathbf{w}^2 a^1 + b^2)) + b^3) \\&amp;= f^3(\mathbf{w}^3 (f^2(\mathbf{w}^2 (f^1(z^1)) + b^2)) + b^3) \\&amp;= f^3(\mathbf{w}^3 (f^2(\mathbf{w}^2 (f^1(\mathbf{w}^1 \mathbf{x} + b^1)) + b^2)) + b^3)\end{split}
\]</span></p>
<p>Se observa que <span class="math inline">\(f^3\)</span> representa la función de activación en la capa de salida, la cual comúnmente se elige como la identidad. Sin embargo, en algunos modelos de clasificación, la predicción puede ser más precisa si esta función es no lineal y limitadora.</p>
<p>Por otro lado, la última columna en la <a href="confirmados.html#fig-mlp" class="quarto-xref">Figura&nbsp;<span>7.11</span></a> constituye una capa adicional en la cual, a través de una función de pérdida, se evalúa el rendimiento de la red. Esta evaluación relaciona la información obtenida en la capa de salida con los datos esperados en un modelo de aprendizaje supervisado.</p>
</div>
</section>
</section>
<section id="perceptrón" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="perceptrón"><span class="header-section-number">6.3</span> Perceptrón</h2>
<div style="text-align: justify">
<p>En un principio, se establece un conjunto de datos a estudiar denominado <span class="math inline">\(\mathbf X \subseteq \mathbb R^{m+1}\)</span>. Este conjunto se particiona en dos clases linealmente separables, <span class="math inline">\(\mathscr C_1\)</span> y <span class="math inline">\(\mathscr C_2\)</span>. A los vectores <span class="math inline">\(\mathbf x = (x_1, x_2,...,x_m,1)^T\)</span> que pertenecen a <span class="math inline">\(\mathbf X\)</span>, se les denomina <em>entradas</em>.</p>
<p>A continuación, se introduce un conjunto <span class="math inline">\(\mathbf W \subseteq \mathbb R^{m+1}\)</span>, que contiene etiquetas para los nodos del perceptrón. Los elementos de este conjunto, denotados como <span class="math inline">\(\mathbf w = (w_1,w_2,...,w_m,b)^T\)</span>, se llaman <em>pesos sinápticos</em>. Aquí, <span class="math inline">\(b\)</span> es un número real fijo conocido como <em>sesgo</em>. Con el propósito de describir el algoritmo del Perceptrón, se presentan cuatro definiciones fundamentales:</p>
<div id="def-cls" class="theorem definition">
<p><span class="theorem-title"><strong>Definición 6.3 (Clases linealmente separables)</strong></span> Sean <span class="math inline">\(\mathscr C_1\)</span> y <span class="math inline">\(\mathscr C_2\)</span> dos clases en un espacio <span class="math inline">\(n-\)</span>dimensional. <span class="math inline">\(\mathscr C_1\)</span> y <span class="math inline">\(\mathscr C_2\)</span> se consideran clases linealmente separables si existe un vector <span class="math inline">\(\mathbf w \in \mathbb R^{m+1}\)</span> de pesos sinápticos que cumple con las siguientes condiciones: <span class="math display">\[
\begin{split}
\mathbf w^T \mathbf x_1 &amp;&gt; 0\text{ para cada vector de entrada } \mathbf x_1 \in \mathscr C_1.\\
\mathbf w^T \mathbf x_2 &amp;\leq 0\text{ para cada vector de entrada } \mathbf x_2 \in \mathscr C_2.
\end{split}
\]</span></p>
</div>
<div id="def-comlin" class="theorem definition">
<p><span class="theorem-title"><strong>Definición 6.4 (Combinador lineal)</strong></span> Dados <span class="math inline">\(\mathbf x = (x_1, x_2,..., x_m,1)^T\)</span> y <span class="math inline">\(\mathbf w = (w_1,w_2,...,w_m,b)^T\)</span>, se define la función <span class="math inline">\(\mathcal V: \mathbb R^{m+1}\times\mathbb R^{m+1} \rightarrow \mathbb R\)</span> como <span class="math inline">\(\mathcal V(\mathbf x, \mathbf w) = \mathbf w^T\mathbf x\)</span>, donde <span class="math inline">\(\mathcal V(\mathbf x, \mathbf w) = 0\)</span> representa el hiperplano de separación entre dos regiones de decisión.</p>
</div>
<div id="def-flim" class="theorem definition">
<p><span class="theorem-title"><strong>Definición 6.5 (Función limitadora)</strong></span> Sea <span class="math inline">\(\mathscr A\)</span> el conjunto de todas las combinaciones lineales <span class="math inline">\(\mathcal V(\mathbf x, \mathbf w)\)</span>. Considerando <span class="math inline">\(t \in \mathscr A\)</span>, se define la función limitadora <span class="math inline">\(g\)</span> como sigue: <span class="math display">\[
\begin{split}
g: \mathscr A&amp;\rightarrow \{1,-1\}\\
t &amp;\rightarrow g(t)= \left\{\begin{array}{lcc} 1 &amp; si &amp; t&gt; 0\\ \\-1 &amp; si &amp; t\leq 0\end{array}\right.
\end{split}
\]</span></p>
</div>
<div id="def-fper" class="theorem definition">
<p><span class="theorem-title"><strong>Definición 6.6 (Función perceptrón)</strong></span> Dadas <span class="math inline">\(\mathcal V(\mathbf x, \mathbf w)\)</span> y <span class="math inline">\(g(t)\)</span>, se define la aplicación clasificadora <span class="math inline">\(\mathscr P: \mathbb R^{m+1}\times \mathbb R^{m+1} \rightarrow \{1,-1\}\)</span> como <span class="math inline">\(\mathscr P(\mathbf x, \mathbf w)=g(\mathcal V(\mathbf x, \mathbf w))=\hat{y}\)</span>, donde <span class="math inline">\(\hat{y}\in \{-1,1\}\)</span> es la salida de la función perceptrón. Además, la aplicación perceptrón posee una representación gráfica mediante un dígrafo simple, como se muestra en la <a href="#fig-arqper" class="quarto-xref">Figura&nbsp;<span>6.5</span></a>.</p>
</div>
<p>A través de la función establecida en la <a href="#def-fper" class="quarto-xref">Definición&nbsp;<span>6.6</span></a>, se desarrolla un modelo de aprendizaje supervisado de clasificación binaria denominado <em>Perceptrón</em>. Este modelo involucra las funciones previamente definidas con el objetivo de clasificar correctamente un conjunto de entradas <span class="math inline">\(\mathbf X\)</span>, linealmente separables en dos clases. Se aplica una regla de aprendizaje adaptativa sobre cada uno de los pesos sinápticos <span class="math inline">\((\mathbf w)\)</span> en una cantidad finita de pasos <span class="math inline">\((n)\)</span>, proceso conocido como <em>algoritmo de aprendizaje del Perceptrón</em>.</p>
<div id="def-clp" class="theorem definition">
<p><span class="theorem-title"><strong>Definición 6.7 (Combinador lineal del perceptrón)</strong></span> Considerando las entradas y los pesos sinápticos en el perceptrón, <span class="math inline">\(\mathbf x(n) = (x_1(n), x_2(n),...,x_m(n),1)^T\)</span> y <span class="math inline">\(\mathbf w(n) = (w_1(n),w_2(n),...,w_m(n),b)^T\)</span>, se define el combinador lineal del perceptrón como</p>
<p><span class="math display">\[
\mathcal V=\mathbf w^T(n)\mathbf x(n),
\]</span></p>
<p>donde <span class="math inline">\(n\)</span> denota el número de iteraciones en la aplicación del algoritmo.</p>
</div>
<p>Se considera <span class="math inline">\(\mathscr H \subset \mathbf X\)</span> como el subsepacio vectorial de entrenamiento. <span class="math inline">\(\mathscr H_1\)</span> es el subespacio de vectores de entrenamiento <span class="math inline">\(\mathbf x_1(1),\mathbf x_1(2),...\)</span> que pertenecen a la clase <span class="math inline">\(\mathscr C_1\)</span>, y <span class="math inline">\(\mathscr H_2\)</span> es el espacio de vectores de entrenamiento <span class="math inline">\(\mathbf x_2(1),\mathbf x_2(2),...\)</span> que pertenecen a la clase <span class="math inline">\(\mathscr C_2\)</span>. Se define <span class="math inline">\(\mathscr H= \mathscr H_1\cup \mathscr H_2\)</span>. Con el fin de evitar un sobreentrenamiento en alguna de las dos clases, se garantiza que <span class="math inline">\(\mathscr H_1\)</span> y <span class="math inline">\(\mathscr H_2\)</span> tengan la misma cardinalidad.</p>
<p>Dado que el perceptrón es un modelo de aprendizaje supervisado, se establece <span class="math inline">\(y(k) \in \{-1,1\}\)</span> como la clase a la que realmente pertenece cada entrada <span class="math inline">\(x(k)\)</span> de <span class="math inline">\(\mathscr H\)</span>. Se observa que el valor <span class="math inline">\(y(k) - \hat{y}(k)\)</span> representa el error cometido por el Perceptrón en su clasificación, y de este error se deriva la siguiente definición:</p>
<div id="def-face" class="theorem definition">
<p><span class="theorem-title"><strong>Definición 6.8 (Función actualización por corrección del error)</strong></span> Se define la regla de actualización de los pesos sinápticos como sigue:</p>
<p><span class="math display">\[
\mathbf w(n+1)=\mathbf w(n)+\eta(n)[y(n)-\hat y(n)]x(n).
\]</span></p>
<p>De esta manera,</p>
<p><span class="math display">\[
\mathbf{w}(n+1) = \left\{\begin{array}{lcc} \mathbf w(n)+2\eta(n) x(n)&amp; si &amp; y(n)=1 \text{ y }\hat{y}=-1,\\ \\\mathbf w(n) &amp; si &amp; y(n)=\hat{y}(n),\\ \\ \mathbf w(n)-2\eta(n)x(n) &amp; si &amp; y(n)=-1 \text{ y }\hat{y}=1, \end{array}\right.
\]</span></p>
<p>donde <span class="math inline">\(\eta(n)=\eta&gt;0\)</span> es una regla de adaptación de incremento fijo llamada <em>tasa de aprendizaje</em>.</p>
</div>
</div>
<section id="teorema-de-convergencia-del-perceptrón" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="teorema-de-convergencia-del-perceptrón"><span class="header-section-number">6.3.1</span> Teorema de convergencia del perceptrón</h3>
<div style="text-align: justify">
<div id="thm-tcp" class="theorem">
<p><span class="theorem-title"><strong>Teorema 6.1</strong></span> Sean <span class="math inline">\(\mathscr H_1\)</span> y <span class="math inline">\(\mathscr H_2\)</span>, subconjuntos de vectores de entrenamiento linealmente separables. Considere las <span class="math inline">\(m\)</span> entradas presentadas al perceptrón, como elementos de estos dos subconjuntos. El perceptrón converge después de <span class="math inline">\(n_0\)</span> iteraciones, en el sentido que:</p>
<p><span class="math display">\[
\mathit w(n_0)=\mathit w(n_0+1)=\mathit w(n_0+2)=\cdots,
\]</span> es un vector solución para <span class="math inline">\(n_0\leq n_{\max}\)</span>.</p>
<div class="proof">
<p><span class="proof-title"><em>Prueba</em>. </span>Vea <span class="citation" data-cites="sosaestructura">Sosa Jerez, Zamora Alvarado, et&nbsp;al. (<a href="references.html#ref-sosaestructura" role="doc-biblioref">s.&nbsp;f.</a>)</span>.</p>
</div>
</div>
</div>
</section>
</section>
<section id="funciones-de-activación" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="funciones-de-activación"><span class="header-section-number">6.4</span> Funciones de activación</h2>
<div style="text-align: justify">
<p>La asignación entre las entradas y una capa oculta en una Red Neuronal Artificial (RNA) y una Red Neuronal Profunda (RNP) es determinada por funciones de activación. Dichas funciones propagan la información generada mediante la combinación lineal de los pesos y las entradas hacia la siguiente capa, incluyendo la capa de salida. Como se ha mencionado anteriormente, existe una analogía entre las neuronas biológicas y las redes neuronales artificiales; en este contexto, las funciones de activación son análogas a la tasa del potencial de acción disparado en el cerebro.</p>
<p>Las funciones de activación son transformaciones de funciones escalares a escalares que proporcionan una salida específica para cada neurona. Estas funciones introducen no linealidades en las capacidades de modelado de la red. La función de activación de una neurona (nodo) define la forma funcional de su activación. Por ejemplo, si se define una función de activación lineal como <span class="math inline">\(g(z) = z\)</span>, en este caso, el valor de la neurona sería la entrada cruda <span class="math inline">\(x\)</span> multiplicada por el peso aprendido, representando así un modelo lineal. A continuación, se describen las funciones de activación más populares.</p>
</div>
<section id="lineal" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="lineal"><span class="header-section-number">6.4.1</span> Lineal</h3>
<div style="text-align: justify">
<p>La <a href="#fig-fact-1" class="quarto-xref">Figura&nbsp;<span>6.8 (a)</span></a> exhibe una función de activación lineal que es esencialmente la función identidad. Esta se define como</p>
<p><span class="math display">\[
F(x)=Wx + b,
\]</span></p>
<p>donde la variable dependiente mantiene una relación directa y proporcional con la variable independiente. En términos prácticos, esto implica que la función transmite la señal sin cambios. Sin embargo, el inconveniente al utilizar funciones de activación lineales radica en que esto no permite aprender formas funcionales no lineales.</p>
</div>
</section>
<section id="sigmoide" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="sigmoide"><span class="header-section-number">6.4.2</span> Sigmoide</h3>
<div style="text-align: justify">
<p>La función de activación sigmoide desempeña el papel de un mecanismo que transforma variables independientes, abarcando un rango prácticamente infinito, en probabilidades situadas dentro del intervalo de <span class="math inline">\(0\)</span> a <span class="math inline">\(1\)</span>. La mayor concentración de su producción tiende a agruparse estrechamente alrededor de los valores <span class="math inline">\(0\)</span> o <span class="math inline">\(1\)</span>. Funcionando como una transformación logística, los sigmoides exhiben la capacidad de mitigar valores extremos o atípicos en los datos sin eliminarlos. Las ecuaciones que describen la función sigmoidal y su derivada son las siguientes:</p>
<p><span class="math display">\[\sigma(x) = \frac{1}{1+e^{-x}}, \quad \sigma'(x) = \frac{e^{-x}}{(1+e^{-x})^2}.\]</span></p>
<p>Ampliamente utilizada en la construcción de Redes Neuronales Artificiales (RNA) y Redes Neuronales Profundas (DNN), especialmente en escenarios donde el resultado deseado es una probabilidad o un resultado binario, la función de activación sigmoide representa uno de los tipos más frecuentemente empleados.</p>
<p>La función de activación <span class="math inline">\(\sigma(x):\mathbb R\to [0,1]\)</span> se caracteriza por ser una función suave y diferenciable en todo punto. Compacta cualquier valor entre <span class="math inline">\(0\)</span> y <span class="math inline">\(1\)</span> y destaca por su naturaleza estrictamente creciente, logrando un delicado equilibrio entre comportamiento lineal y no lineal. Sin embargo, es susceptible de experimentar “atascos”, un fenómeno en el cual los valores de salida convergen muy cerca de <span class="math inline">\(1\)</span> o <span class="math inline">\(0\)</span>, especialmente cuando los valores de entrada son muy positivos o negativos (consulte la <a href="#fig-fact-2" class="quarto-xref">Figura&nbsp;<span>6.8 (b)</span></a>). Al referirnos a que la función de activación se “atasca”, implicamos que el proceso de aprendizaje deja de mejorar debido al dominio de valores de salida grandes o pequeños dentro de esta función de activación.</p>
</div>
</section>
<section id="unidad-lineal-rectificadora-relu" class="level3" data-number="6.4.3">
<h3 data-number="6.4.3" class="anchored" data-anchor-id="unidad-lineal-rectificadora-relu"><span class="header-section-number">6.4.3</span> Unidad lineal rectificadora (ReLu)</h3>
<div style="text-align: justify">
<p>La función de activación de la unidad lineal rectificadora (ReLU) destaca como una de las más adoptadas. Exhibe una respuesta plana por debajo de un umbral especificado, normalmente establecido en cero, y luego se vuelve lineal. La activación en una ReLU se produce solo cuando la entrada supera un determinado umbral. Cuando la entrada está por debajo de cero, la salida sigue siendo cero, pero al exceder el umbral, como se ilustra en la <a href="#fig-fact-3" class="quarto-xref">Figura&nbsp;<span>6.8 (c)</span></a>., establece una relación lineal con la variable dependiente, de la siguiente manera</p>
<p><span class="math display">\[
F(x)=\max(0,x)
\]</span></p>
<p>A pesar de su aparente simplicidad, la función de activación de ReLU facilita las transformaciones no lineales, lo que permite la aproximación de funciones no lineales arbitrarias mediante el uso de rectificadores lineales suficientes. Esto contrasta con los escenarios en los que se emplean exclusivamente funciones de activación lineal.</p>
<p>En la actualidad, las ReLU representan el estado de la técnica, demostrando su eficacia en diversas situaciones. Sin embargo, debido a que el gradiente de la ReLU es cero o una constante, plantea desafíos en el control de problemas como la desaparición y la explosión de gradientes, comúnmente conocido como el problema de la “ReLU moribunda”. En particular, las funciones de activación de ReLU han mostrado un rendimiento de entrenamiento superior en la práctica en comparación con las funciones de activación sigmoide. Esta función de activación se emplea más comúnmente en capas ocultas y capas de salida cuando la variable de respuesta es continua y supera cero.</p>
</div>
</section>
<section id="relu-con-fugas" class="level3" data-number="6.4.4">
<h3 data-number="6.4.4" class="anchored" data-anchor-id="relu-con-fugas"><span class="header-section-number">6.4.4</span> ReLu con fugas</h3>
<div style="text-align: justify">
<p>Las ReLU con fugas sirven como medida correctiva para abordar el fenómeno de la “ReLU moribunda”. A diferencia de la ReLU convencional, que asigna un valor cero a la función cuando <span class="math inline">\(x &lt; 0\)</span>, la ReLU con fugas introduce una pequeña pendiente negativa, denotada como <span class="math inline">\(\alpha\)</span>, donde <span class="math inline">\(\alpha\)</span> es un valor escalar dentro del rango de <span class="math inline">\(0\)</span> a <span class="math inline">\(1\)</span> (consulte la <a href="#fig-fact-4" class="quarto-xref">Figura&nbsp;<span>6.8 (d)</span></a>). Si bien esta variación de ReLU ha demostrado cierto éxito en aplicaciones prácticas, los resultados no son uniformemente consistentes. La expresión matemática de esta función de activación se proporciona a continuación:</p>
<p><span class="math display">\[
F(x)=\begin{cases}x &amp; \text{si}\quad x&gt;0\\ \alpha x&amp; \text{otro caso}\end{cases}.
\]</span></p>
</div>
</section>
<section id="tangente-hiperbólica" class="level3" data-number="6.4.5">
<h3 data-number="6.4.5" class="anchored" data-anchor-id="tangente-hiperbólica"><span class="header-section-number">6.4.5</span> Tangente hiperbólica</h3>
<div style="text-align: justify">
<p>La función de activación tangente hiperbólica <span class="math inline">\((\tanh)\)</span> es una modificación de la función sigmoide y se define como</p>
<p><span class="math display">\[
\tanh(x)=\frac{e^x-e^{-x}}{e^{x}+e^{-x}}
\]</span></p>
<p>Cuyas gráficas se observan en la <a href="#fig-fact-5" class="quarto-xref">Figura&nbsp;<span>6.8 (e)</span></a>. La función de activación tangete hiperbólica <span class="math inline">\(\tanh(x):\mathbb R\to [-1,1]\)</span> es una función suave y diferenciable en todo punto. Similar a la función de activación sigmoide, produce una salida sigmoidal (en forma de “S”). Sin embargo, la función <span class="math inline">\(\tanh\)</span> tiene la ventaja de ser menos propensa al problema de “atascarse” en comparación con la función de activación sigmoide. Esto se atribuye a que los valores de salida de la función <span class="math inline">\(\tanh\)</span> se encuentran dentro del rango de <span class="math inline">\(-1\)</span> a <span class="math inline">\(1\)</span>. En consecuencia, a menudo se prefiere la función de activación <span class="math inline">\(\tanh\)</span> para capas ocultas. Una ventaja adicional de <span class="math inline">\(\tanh\)</span> es su capacidad para manejar los números negativos de manera más efectiva. Sin embargo, el gradiente de la función evaluado en valores muy alejados al origen será un valor muy pequeño, por lo que sigue generando un estancamiento en el proceso de retropropagación.</p>
</div>
</section>
<section id="softmax" class="level3" data-number="6.4.6">
<h3 data-number="6.4.6" class="anchored" data-anchor-id="softmax"><span class="header-section-number">6.4.6</span> Softmax</h3>
<div style="text-align: justify">
<p>La función Softmax se emplea predominantemente en redes neuronales dedicadas a abordar problemas de clasificación. Su resultado proporciona un porcentaje que indica la probabilidad de que los datos ingresados pertenezcan a cada una de las clases. Es habitual utilizar esta función de activación en las capas finales de la red neuronal. La expresión que la define es:</p>
<p><span class="math display">\[
S=\frac{e^{a_i^l}}{\sum_{k=1}^K (e^{a_k^l})}, \text{ para }i=1,\ldots, K
\]</span></p>
<p>donde <span class="math inline">\(a\)</span> es la salida de las capas ocultas y <span class="math inline">\(K\)</span> es el número de clases en el modelo. La <a href="#fig-fact-6" class="quarto-xref">Figura&nbsp;<span>6.8 (f)</span></a> ejemplifica esta función de activación.</p>
</div>
<div id="fig-fact" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fact-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fact" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-fact-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fact-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="redes_files/figure-html/fig-fact-1.png" class="img-fluid figure-img" data-ref-parent="fig-fact" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fact-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Lineal
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fact" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-fact-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fact-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="redes_files/figure-html/fig-fact-2.png" class="img-fluid figure-img" data-ref-parent="fig-fact" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fact-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Sigmoide
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fact" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-fact-3" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fact-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="redes_files/figure-html/fig-fact-3.png" class="img-fluid figure-img" data-ref-parent="fig-fact" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fact-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) ReLu
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fact" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-fact-4" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fact-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="redes_files/figure-html/fig-fact-4.png" class="img-fluid figure-img" data-ref-parent="fig-fact" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fact-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d) ReLu con fugas
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fact" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-fact-5" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fact-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="redes_files/figure-html/fig-fact-5.png" class="img-fluid figure-img" data-ref-parent="fig-fact" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fact-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(e) Tangente hiperbólica
</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-fact" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-fact-6" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-fact-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="redes_files/figure-html/fig-fact-6.png" class="img-fluid figure-img" data-ref-parent="fig-fact" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-fact-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(f) Softmax
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fact-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6.8: Funciones de activación
</figcaption>
</figure>
</div>
</section>
</section>
<section id="funciones-de-coste" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="funciones-de-coste"><span class="header-section-number">6.5</span> Funciones de coste</h2>
<div style="text-align: justify">
<p>Las funciones de costo, pérdida u objetivo desempeñan un papel fundamental al medir la disparidad entre los resultados obtenidos y los valores deseados. En el contexto del descenso del gradiente, estas funciones son cruciales, ya que buscan minimizar la salida de la función de costo, lo que lleva a que los valores generados por la red neuronal sean cercanos a los valores deseados.</p>
<p>Para ser empleada en el proceso de retropropagación, la función de costo debe cumplir con dos propiedades fundamentales:</p>
<ol type="1">
<li>La función de costo <span class="math inline">\(C\)</span> debe expresarse como un promedio:</li>
</ol>
<p><span class="math display">\[C = \frac{1}{n} \sum_{x} \mathcal L_x, \]</span></p>
<p>donde <span class="math inline">\(\mathcal L_x\)</span> representa las funciones de pérdida para ejemplos individuales <span class="math inline">\(x\)</span> en el conjunto de entrenamiento.</p>
<ol start="2" type="1">
<li>La función de costo <span class="math inline">\(C\)</span> no debe depender de ningún valor de activación, excepto los valores de salida <span class="math inline">\({a}^L\)</span>. Si la función de costo depende de otras capas de activación además de la capa de salida, la retropropagación no será válida, ya que la idea de propagación hacia atrás dejará de funcionar.</li>
</ol>
<div class="proof remark">
<p><span class="proof-title"><em>Observación</em>. </span>Es importante destacar que la función de costo y la función de pérdida son conceptos distintos. La función de costo representa el promedio de las pérdidas de todas las muestras o datos de entrenamiento, mientras que la función de pérdida se refiere a las pérdidas individuales para cada ejemplo. A pesar de esta diferencia, es común observar el uso de ambos términos de manera intercambiable o con propósitos similares en la literatura.</p>
</div>
</div>
</section>
<section id="gradiente-descendente" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="gradiente-descendente"><span class="header-section-number">6.6</span> Gradiente descendente</h2>
<div style="text-align: justify">
<p>El gradiente o vector gradiente se presenta como una generalización de la derivada en varias variables, su definición formal se muestra a continuación.</p>
<div id="def-Vgrad" class="theorem definition">
<p><span class="theorem-title"><strong>Definición 6.9 (Vector gradiente)</strong></span> Sea <span class="math inline">\(f : U \subseteq \mathbb{R}^n \rightarrow \mathbb{R}\)</span> una función diferenciable definida en el conjunto abierto <span class="math inline">\(U\in \mathbb R^n\)</span>. Se define el vector gradiente de la función <span class="math inline">\(f\)</span> en el punto <span class="math inline">\(x_0\)</span> de <span class="math inline">\(U\)</span>, denotado por <span class="math inline">\(\nabla f(x_0)\)</span>, como el vector en <span class="math inline">\(\mathbb{R}^n\)</span> dado por</p>
<p><span class="math display">\[\nabla f(x_0) = \left( \frac{\partial f}{\partial x_1}(x_0), \frac{\partial f}{\partial x_2}(x_0), \ldots, \frac{\partial f}{\partial x_n}(x_0) \right).\]</span></p>
</div>
<p>Adicionalmente, el vector gradiente señala la dirección en la cual la función <span class="math inline">\(f\)</span> experimenta el crecimiento más rápido. Este resultado se formaliza mediante el siguiente teorema</p>
<div id="thm-B" class="theorem">
<p><span class="theorem-title"><strong>Teorema 6.2</strong></span> Sea <span class="math inline">\(f : X \subseteq \mathbb{R}^n \rightarrow \mathbb{R}\)</span> diferenciable en <span class="math inline">\(x_0 \in X\)</span>, el gradiente apunta hacia la dirección de mayor crecimiento de <span class="math inline">\(f\)</span>.</p>
<div class="proof">
<p><span class="proof-title"><em>Prueba</em>. </span>Vea <span class="citation" data-cites="stewart2017cálculo">Stewart (<a href="references.html#ref-stewart2017cálculo" role="doc-biblioref">2017</a>)</span>.</p>
</div>
</div>
<p>El método de descenso del gradiente desempeña un papel fundamental en el entrenamiento de las redes neuronales. A través de este método, se logra considerar los valores más óptimos y eficaces, específicamente los pesos <span class="math inline">\(w\)</span> de la red neuronal. Este enfoque permite estimar cada nuevo parámetro basándose en el anterior, teniendo en cuenta la derivada de la función de coste. Además, el proceso presenta ventajas como la simplicidad y la rapidez de convergencia.</p>
</div>
<section id="algoritmo-gradiente-descendente" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1" class="anchored" data-anchor-id="algoritmo-gradiente-descendente"><span class="header-section-number">6.6.1</span> Algoritmo gradiente descendente</h3>
<div style="text-align: justify">
<p>Considere una función de costo <span class="math inline">\(\mathcal C\)</span> definida como <span class="math inline">\(\mathcal C : \Omega \subseteq \mathbb{R}^n \rightarrow \mathbb{R}\)</span>. El algoritmo de gradiente descendente es utilizado para encontrar un valor <span class="math inline">\(w\)</span> en <span class="math inline">\(\Omega\)</span> tal que <span class="math inline">\(\mathcal C(w)\)</span> alcance un mínimo (extremo local).</p>
<p>Las actualizaciones de <span class="math inline">\(w\)</span> se realizan de la siguiente manera:</p>
<p><span class="math display">\[w_{k+1} = w_k - \alpha \nabla\mathcal C(w_k),\]</span></p>
<p>donde <span class="math inline">\(\alpha\)</span> es la tasa de aprendizaje y <span class="math inline">\(k\)</span> es el número de iteraciones. Se elige inicialmente un valor inicial <span class="math inline">\(w_0\)</span> (puede ser seleccionado de forma aleatoria o elegido manualmente). El algoritmo comienza en este punto con el propósito de ajustar el valor del peso inicial hasta situarlo en el mínimo de la función.</p>
</div>
</section>
</section>
<section id="perceptrón-multicapa" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="perceptrón-multicapa"><span class="header-section-number">6.7</span> Perceptrón Multicapa</h2>
<div style="text-align: justify">
<p>Como se expuso previamente en la <a href="#sec-arqmlp" class="quarto-xref"><span>Sección 6.2.2</span></a>, se pueden representar mediante un diagrama simple, que incluye nodos ponderados y un conjunto de atributos que las caracterizan. En esta sección, la estructura de la red será formalizada junto con sus definiciones correspondientes (<span class="citation" data-cites="sosaestructura">Sosa Jerez, Zamora Alvarado, et&nbsp;al. (<a href="references.html#ref-sosaestructura" role="doc-biblioref">s.&nbsp;f.</a>)</span>).</p>
</div>
<div id="def-mlp" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.10 (Perceptrón Multicapa (MLP))</strong></span> Una red neuronal artificial MLP se define formalmente como una tripla <span class="math inline">\(&lt;\mathscr D, \{f\}, \mathscr A&gt;\)</span>, donde;</p>
<ul>
<li><p><span class="math inline">\(\mathscr D\)</span> es un dígrafo contable, localmente finito, con nodos etiquetados. Sus vértices corresponden a los nodos de procesamiento (neuronas), mientras que las etiquetas de los nodos, denominadas <em>pesos</em>, representan las intensidades de las conexiones sinápticas. Dichas intensidades se denotan por <span class="math inline">\(w_{ij}\)</span>, indicando el peso de la conexión entre la neurona <span class="math inline">\(j\)</span>-ésima y la <span class="math inline">\(i\)</span>-ésima.</p></li>
<li><p><span class="math inline">\(\mathscr A\)</span> es el conjunto que contiene los elementos de “entrada” de las unidades o nodos de procesamiento, generalmente representado por <span class="math inline">\(A =\mathbb R\)</span>.</p></li>
<li><p><span class="math inline">\(\{f: \mathscr A\to\mathscr A\},\)</span> es una colección de funciones de activación.</p></li>
</ul>
</div>
<div style="text-align: justify">
<p>En el dígrafo <span class="math inline">\(\mathscr D\)</span>, se definen las capas como las columnas de vértices en <span class="math inline">\(\mathscr D\)</span>. Cada una de estas columnas puede ser representada matemáticamente a través de un vector, de la siguiente manera:</p>
<ol type="1">
<li><p><strong>Capa de entrada:</strong> corresponde a la primera columna de vértices de <span class="math inline">\(\mathscr D\)</span>, cuya representación matemática se expresa como: <span class="math display">\[\mathbf x = (x_1, \ldots, x_{d_0})^T \text{ donde } \mathbf x \in \mathbb{R}^{(d_0 \times 1)}\]</span></p></li>
<li><p><strong>Capa de salida</strong>: corresponde a la última columna de vértices de <span class="math inline">\(\mathscr D\)</span>, cuya representación matemática se describe como: <span class="math display">\[\hat{\mathbf y} = (\hat{y}_1, \ldots, \hat{y}_{d_L})^T \text{ donde } \hat{y}\in\mathbb{R}^{(d_L\times 1)}\]</span></p></li>
<li><p><strong>Capas ocultas</strong>: corresponden a las columnas intermedias entre la capa de entrada y la de salida. Su representación matemática está dada por: <span class="math display">\[\begin{split}
\mathbf a^l &amp;= (a_{1}^l, \ldots, a_{d_l}^l)^T \text{ donde } a^l\in\mathbb{R}^{(d_l\times 1)}\\ &amp;= f^l(z^l)\text{ con } l = 1, \ldots, L - 1
\end{split}.\]</span></p></li>
</ol>
<p>Cabe destacar que cada <span class="math inline">\(\mathbf a^l\)</span> corresponde a una columna de vértices en <span class="math inline">\(\mathscr D\)</span>, donde <span class="math inline">\(L\)</span> denotará la totalidad de capas en la red. <span class="math inline">\(f^l\)</span> será una función de activación vectorial y <span class="math inline">\(z^l\)</span> será el combinador lineal matricial, ambos en la capa <span class="math inline">\(l\)</span>. De esta manera, la capa de salida también puede representarse como el vector <span class="math inline">\(\mathbf a^L\)</span>, y la capa de entrada como el vector <span class="math inline">\(\mathbf a^0\)</span>.</p>
</div>
<div id="def-nodos" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.11 (Neuronas o nodos de procesamiento)</strong></span> Las neuronas de la red MLP son los vértices de las capas ocultas en <span class="math inline">\(\mathscr D\)</span>, es decir, las componentes de <span class="math inline">\(\mathbf a^l\)</span> se denotarán como <span class="math inline">\(a_i^l\)</span>, donde:</p>
<p><span class="math display">\[
a_i^l=f^l(z_i^l).
\]</span></p>
</div>
<div id="def-funac" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.12 (Función de activación)</strong></span> Se define <span class="math inline">\(f^l\)</span> como una función de activación vectorial, de modo que:</p>
<p><span class="math display">\[
f^l: \mathbb R^{(d_1\times 1)}\rightarrow \mathbb R^{(d_1\times 1)}.
\]</span></p>
</div>
<div id="def-Mpesos" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.13 (Matriz de pesos)</strong></span> Para cada capa <span class="math inline">\(l\)</span> en <span class="math inline">\(\mathscr D\)</span>, se define <span class="math inline">\(\mathbf w^l\)</span> como una matriz de dimensiones <span class="math inline">\(d_l \times d_{l-1}\)</span>, donde <span class="math inline">\(d_l\)</span> representa la cantidad de neuronas en la capa <span class="math inline">\(l\)</span>, de la siguiente manera:</p>
<p><span class="math display">\[
\mathbf w^l=\begin{bmatrix}w_{11}^l &amp; \cdots &amp; w_{1j}^l&amp;\cdots&amp;w_{1d_{l-1}}^l\\ \vdots &amp;\cdots&amp;\vdots&amp;\cdots&amp;\vdots\\ w_{i1}^l &amp; \cdots &amp; w_{ij}^l&amp;\cdots&amp;w_{id_{l-1}}^l\\ \vdots &amp;\cdots&amp;\vdots&amp;\cdots&amp;\vdots\\ w_{d_l1}^l &amp; \cdots &amp; w_{d_lj}^l&amp;\cdots&amp;w_{d_ld_{l-1}}^l \end{bmatrix}
\]</span></p>
</div>
<div id="def-sesgo" class="theorem definition" style="text-alig: justify">
<p><span class="theorem-title"><strong>Definición 6.14 (Sesgo)</strong></span> Se define el sesgo como el vector</p>
<p><span class="math display">\[
\mathbf b^l=(b_1^l,\ldots,b_{d_l}^l)^T\quad\text{con }\mathbf b^l\in\mathbb R^{(d_1\times 1)}
\]</span></p>
<p>correspondiente a la capa <span class="math inline">\(l\)</span>, cuyas entradas son el parámetro de sesgo de cada neurona.</p>
</div>
<div id="def-clm" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.15 (Combinador lineal matricial)</strong></span> Dados <span class="math inline">\(\mathbf a^{l-1}, \mathbf w^l\)</span> y <span class="math inline">\(\mathbf b^l\)</span> se define el combinador lineal como</p>
<p><span class="math display">\[
\begin{split}
\mathbf z^l&amp;=(z_1^l,\ldots,z_{d_l}^l)^T\\
&amp;=\mathbf w\mathbf a^{l-1}+\mathbf b^l,
\end{split}
\]</span></p>
<p>donde</p>
<p><span id="eq-clm"><span class="math display">\[
z_i^l=\sum_{j=1}^{d_{l-1}}w_{ij}^la_j^{l-1}+b_i.
\tag{6.2}\]</span></span></p>
</div>
<div style="text-align: justify">
<p>Se observa que la ecuación <a href="#eq-clm" class="quarto-xref">Ecuación&nbsp;<span>6.2</span></a> guarda una fuerte relación con la <a href="#def-comlin" class="quarto-xref">Definición&nbsp;<span>6.4</span></a>. No obstante, en el caso de <span class="math inline">\(\mathbf{z}^l\)</span>, se ha incorporado el vector de parámetros de sesgo <span class="math inline">\(\mathbf{b}^l\)</span>.</p>
</div>
<div id="def-fperdida" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.16 (Función de pérdida)</strong></span> Se define <span class="math inline">\(\mathcal L: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> de manera que</p>
<p><span class="math display">\[\begin{split}\mathcal L(\mathbf y,\mathbf{\hat{y}}) &amp;= \frac{1}{2}\|\mathbf y - \mathbf{\hat{y}}\|^2\\ &amp;= \frac{1}{2} \|\mathbf y - \mathbf a^L\|^2\\ &amp;= \frac{1}{2} \sum_{r=1}^{d_L} (y_r - a_r^L)^2,\end{split}\]</span> como la función de pérdida de la red MLP.</p>
</div>
<div id="def-cde" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.17 (Conjunto de datos de entrenamiento)</strong></span> Sea <span class="math inline">\(\mathbf X = (\mathbf x(1), \ldots, \mathbf x(n))\)</span>, donde <span class="math inline">\(\mathbf x(k)\)</span>, con <span class="math inline">\(k = 1, \ldots, n\)</span>, representa el <span class="math inline">\(k\)</span>-ésimo dato en el conjunto <span class="math inline">\(\mathbf X\)</span>, siendo este el vector de entradas de la red neuronal en la <span class="math inline">\(k\)</span>-ésima etapa.</p>
</div>
<div id="def-csr" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.18 (Conjunto de salidas de la red)</strong></span> Se define <span class="math inline">\(\hat{\mathbf Y} = (\hat{\mathbf y}(1), \ldots, \hat{\mathbf y}(n))\)</span>, donde <span class="math inline">\(\hat{\mathbf y}(k)\)</span>, con <span class="math inline">\(k = 1, \ldots, n\)</span>, representa el <span class="math inline">\(k\)</span>-ésimo dato en el conjunto <span class="math inline">\(\hat{\mathbf Y}\)</span>, siendo este el vector de salidas de la red neuronal en la <span class="math inline">\(k\)</span>-ésima etapa.</p>
</div>
<div id="def-re" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.19 (Resultados esperados)</strong></span> Se define <span class="math inline">\(\mathbf Y = (\mathbf y(1), \ldots, \mathbf y(n))\)</span>, donde <span class="math inline">\(\mathbf y(k)\)</span>, con <span class="math inline">\(k = 1, \ldots, n\)</span>, representa el <span class="math inline">\(k\)</span>-ésimo dato en el conjunto <span class="math inline">\(\mathbf Y\)</span>, siendo este el vector de resultados esperados correspondiente al dato <span class="math inline">\(\mathbf x(k)\)</span>.</p>
</div>
<section id="entrenamiento-y-aprendizaje-del-perceptrón-multicapa" class="level3" data-number="6.7.1">
<h3 data-number="6.7.1" class="anchored" data-anchor-id="entrenamiento-y-aprendizaje-del-perceptrón-multicapa"><span class="header-section-number">6.7.1</span> Entrenamiento y aprendizaje del Perceptrón Multicapa</h3>
<div style="text-align: justify">
<p>El proceso de aprendizaje de una red neuronal se configura como un modelo de aprendizaje supervisado. En este proceso, se establece un algoritmo que, a partir de un conjunto de datos de entrenamiento que incluye entradas y resultados esperados, permite el entrenamiento gradual de la red. El objetivo principal es que la red pueda calcular de manera autónoma los valores óptimos de pesos y sesgos para clasificar las entradas en salidas, minimizando la discrepancia con respecto a los resultados esperados.</p>
<p>Al concluir este proceso de entrenamiento, se espera que la red neuronal desarrolle la capacidad de clasificar cualquier dato, incluso aquellos no presentes en el conjunto de entrenamiento inicial (datos de prueba), generando salidas con un error de clasificación mínimo. Este proceso de entrenamiento se compone de dos etapas esenciales: la propagación hacia adelante o <em>feedforward</em>, y la retropropagación, también conocida como <em>back-propagation</em>.</p>
</div>
<section id="propagación-hacia-adelante" class="level4" data-number="6.7.1.1">
<h4 data-number="6.7.1.1" class="anchored" data-anchor-id="propagación-hacia-adelante"><span class="header-section-number">6.7.1.1</span> Propagación hacia adelante</h4>
<div style="text-alig: justify">
<p>El proceso de prealimentación constituye la base del entrenamiento y aprendizaje de la red, considerando los siguientes pasos:</p>
<ol type="1">
<li><p>Se elige un vector de datos <span class="math inline">\(\mathbf x \in \mathbf X\)</span> como entrada de la red neuronal MLP.</p></li>
<li><p>Se establecen matrices <span class="math inline">\(\mathbf w^l\)</span> de pesos y vectores <span class="math inline">\(\mathbf b^l\)</span> de sesgo, cuyas componentes tienen entradas aleatorias que pertenecen a un umbral prefijado.</p></li>
<li><p>Se “alimenta” la red neuronal en una única dirección. Para ello, se inicia estableciendo lo que se tendrá en la primera capa de procesamiento y luego se generaliza el proceso:</p>
<ul>
<li><p><strong>Alimentación primera capa:</strong> Se establecen los productos matriciales en cada nodo de procesamiento, dados por:</p>
<p><span class="math display">\[
\begin{split}\mathbf z^1&amp;=(\mathbf w^1\mathbf x)+\mathbf b^1\\ \mathbf a^1&amp;=f^1(\mathbf z^1).\end{split}
\]</span></p></li>
<li><p><strong>Generalización:</strong> Considerando cómo se “alimenta” la red en la primera capa, se repite el mismo proceso para cada capa siguiente:</p>
<p><span class="math display">\[
\begin{split}\mathbf z^l&amp;=(\mathbf w^l\mathbf a^{l-1})+\mathbf b^l\\\mathbf a^l&amp;= f^l(\mathbf z^l).\end{split}
\]</span></p></li>
</ul>
<p>Se observa que en este paso, lo que en la primera capa era <span class="math inline">\(\mathbf x\)</span>, en cualquier capa diferente será <span class="math inline">\(a^{l-1}\)</span>. Esto se debe a que la red es un dígrafo <span class="math inline">\(\mathscr D\)</span>, donde la salida de la capa anterior <span class="math inline">\((l - 1)\)</span> se convierte en el vector de entrada para la capa siguiente <span class="math inline">\((l)\)</span>.</p></li>
</ol>
</div>
</section>
<section id="retropropagación" class="level4" data-number="6.7.1.2">
<h4 data-number="6.7.1.2" class="anchored" data-anchor-id="retropropagación"><span class="header-section-number">6.7.1.2</span> Retropropagación</h4>
<div style="text-align: justify">
<p>La retropropagación se emplea en las redes neuronales como algoritmo de aprendizaje, y su objetivo es ajustar de manera eficiente los pesos de la red. Este proceso consiste en establecer inicialmente de manera aleatoria los pesos requeridos en la red para obtener una salida, la cual se compara mediante la función de pérdida <span class="math inline">\(\mathcal L\)</span> con el resultado esperado. De esta manera, se calcula el error de aproximación de la red con el objetivo de minimizar dicho error a través de la optimización de la función <span class="math inline">\(\mathcal L\)</span>. La optimización se realiza mediante una generalización del algoritmo de descenso del gradiente, utilizando la regla de la cadena y recorriendo la red de atrás hacia adelante.</p>
<p>De forma iterativa, la red aprende a establecer los pesos y sesgos adecuados para cada neurona, con el fin de obtener una salida que se aproxime al resultado esperado. Para comprender el funcionamiento del algoritmo de retropropagación, es necesario comenzar calculando las derivadas respecto a los parámetros de pesos y sesgos de la función de coste en la red prealimentada.</p>
<p>Se inicia calculando la derivada de <span class="math inline">\(\mathcal L\)</span> respecto a uno de los pesos que afectan a la última capa:</p>
<p><span id="eq-18"><span class="math display">\[\begin{split}\frac{\partial \mathcal L}{\partial w_{ij}^L} &amp;= \frac{1}{2} \sum_{r=1}^{d_L} \frac{\partial}{\partial w_{ij}^L} (y_r - a_{r}^L)^2\\
&amp;= \sum_{r=1}^{d_L} (a_{r}^L - y_r) \left(\frac{\partial a_r^L}{\delta w_{ij}^L}\right)\\
&amp;=\sum_{r=1}^{d_L} (a_{r}^L - y_r) \frac{\partial}{\partial w_{ij}^L}f^L(z_{r}^L)\\
&amp;= \sum_{r=1}^{d_L} (a_{r}^L - y_r) \frac{\partial}{\partial w_{ij}^L}f^L\left(\sum_{t=1}^{d_L}w_{rt}^La_t^{L-1}+b_r^L\right),\end{split} \tag{6.3}\]</span></span></p>
<p>Esta expresión se anula en todos los valores en los que <span class="math inline">\(r\neq i\)</span> o <span class="math inline">\(t\neq j\)</span>. Si <span class="math inline">\(r = i\)</span> y <span class="math inline">\(t = j\)</span>, se tiene:</p>
<p><span id="eq-retrop"><span class="math display">\[\frac{\partial \mathcal L}{\partial w_{ij}^L} = (a_{i}^L - y_i) f^{(1)L}(z_{i}^L) a_j^{L-1} \tag{6.4}\]</span></span></p>
<p>Esta ecuación proporciona la derivada particular de la función de pérdida respecto a un único peso. Para generalizar esta situación y calcular <span class="math inline">\(\frac{\partial \mathcal L}{\partial \mathbf w^{L}}\)</span>, se deben tener en cuenta las dimensiones y definir una nueva operación matricial.</p>
</div>
<div id="def-pHada" class="theorem definition" style="text-align: justify">
<p><span class="theorem-title"><strong>Definición 6.20 (Producto Hadamard)</strong></span> Dadas <span class="math inline">\(A, B\)</span> dos matrices de dimensión <span class="math inline">\((m\times n)\)</span>, el producto de Hadamard <span class="math inline">\((A\odot B)\)</span> es una matriz de dimensión <span class="math inline">\((m\times n)\)</span> tal que:</p>
<p><span class="math display">\[
(A\odot B)_{ij}=[a_{ij}b_{ij}].
\]</span></p>
</div>
<div style="text-align: justify">
<p>Generalizando la <a href="#eq-retrop" class="quarto-xref">Ecuación&nbsp;<span>6.4</span></a> y haciendo uso de la definición previa, se puede expresar la derivada parcial de la función de pérdida respecto a los pesos en la última capa como:</p>
<p><span id="eq-20"><span class="math display">\[\begin{split}\frac{\partial \mathcal L}{\partial \mathbf w^L} &amp;= \frac{\partial \mathcal L}{\partial \mathbf a^L}\frac{\partial \mathbf a^L}{\partial \mathbf z^L}\frac{\partial \mathbf z^L}{\partial \mathbf w^L}\\&amp;= \left[(\mathbf a^L - y)\odot f^{(1)L}(\mathbf z^L)\right] (\mathbf a^{L-1})^T,\end{split} \tag{6.5}\]</span></span></p>
<p>Donde el error en la última capa se denota como <span class="math inline">\((\mathbf a^L - y)\)</span> y se representa como <span class="math inline">\(\mathbf e^L\)</span>. También se introduce la notación <span class="math inline">\(\delta^L\)</span> para referirse al producto de Hadamard <span class="math inline">\([(\mathbf a^L - y)\odot f^{(1)L}(\mathbf z^L)]\)</span>. La expresión se simplifica como:</p>
<p><span id="eq-21"><span class="math display">\[\frac{\partial \mathcal L}{\partial \mathbf w^L} = \delta^L (a^{L-1})^T. \tag{6.6}\]</span></span></p>
<p>Al extender este proceso desde la <a href="#eq-18" class="quarto-xref">Ecuación&nbsp;<span>6.3</span></a> hasta la <a href="#eq-21" class="quarto-xref">Ecuación&nbsp;<span>6.6</span></a> para calcular <span class="math inline">\(\frac{\partial \mathcal L}{\partial \mathbf b^L}\)</span>, se obtiene:</p>
<p><span id="eq-22"><span class="math display">\[\frac{\partial \mathcal L}{\partial \mathbf b^L} = \delta. \tag{6.7}\]</span></span></p>
<p>Se reconoce que la función de pérdida <span class="math inline">\(\mathcal L\)</span> en el conjunto de datos <span class="math inline">\(\mathscr D\)</span> depende de las matrices de pesos y los vectores de sesgo de cada capa. Por lo tanto, se busca minimizar la función de pérdida en cada capa <span class="math inline">\(l\)</span>. Al considerar las derivadas en la capa <span class="math inline">\(L-1\)</span>, se obtiene:</p>
<p><span id="eq-23"><span class="math display">\[
\begin{split}\frac{\partial \mathcal L}{\partial \mathbf w^{L-1}}&amp;= \frac{\partial \mathcal L}{\partial \mathbf a^{L}}\frac{\partial \mathbf a^L}{\partial \mathbf z^{L}}\frac{\partial \mathbf z^L}{\partial \mathbf a^{L-1}}\frac{\partial \mathbf a^{L-1}}{\partial \mathbf z^{L-1}}\frac{\partial \mathbf z^{L-1}}{\partial \mathbf w^{L-1}}\\
&amp;= [((\mathbf w^L)^T \delta^L)\odot f^{L-1(1)}(\mathbf z^{L-1})](\mathbf a^{L-2})^T\\
&amp;= \delta^{L-1}(\mathbf a^{L-2})^T,\end{split}
\tag{6.8}\]</span></span></p>
<p>Donde <span class="math inline">\(((\mathbf w^L)^T \delta^L) = \mathbf e^{L-1}\)</span> y <span class="math inline">\([((\mathbf w^L)^T \delta^L)\odot f^{L-1}(\mathbf z^{L-1})] = \delta^{L-1}\)</span>.</p>
<p>De manera análoga, la derivada parcial de la función de pérdida con respecto al sesgo en la capa <span class="math inline">\(l-1\)</span> se expresa como:</p>
<p><span id="eq-24"><span class="math display">\[\frac{\partial \mathcal L}{\partial \mathbf b^{L-1}} = \delta^{L-1}. \tag{6.9}\]</span></span></p>
<p>Al generalizar este proceso, se obtiene la relación recurrente para <span class="math inline">\(\delta^l\)</span>:</p>
<p><span class="math display">\[\delta^l = \left[((\mathbf w^{l+1})^T \delta^{l+1})\odot f^l(\mathbf z^l) \right], \quad \text{para } l = L-1, \ldots, 1.\]</span></p>
<p>De esta forma, las derivadas parciales de la función de pérdida respecto a los pesos y sesgos en cada capa se expresan como:</p>
<p><span id="eq-25"><span class="math display">\[\frac{\partial \mathcal L}{\partial \mathbf w^l} = \delta^l (a^{l-1})^T,\quad \frac{\partial \mathcal L}{\partial \mathbf b^l} = \delta^l. \tag{6.10}\]</span></span></p>
<p>Con estas expresiones, se define el proceso iterativo de retropropagación en los siguientes pasos:</p>
<ol type="1">
<li><p>Calcular el error <span class="math inline">\(\mathbf e^L\)</span> y <span class="math inline">\(\delta^L\)</span> en la última capa, como se muestra en la <a href="#eq-20" class="quarto-xref">Ecuación&nbsp;<span>6.5</span></a> y <a href="#eq-21" class="quarto-xref">Ecuación&nbsp;<span>6.6</span></a>.</p></li>
<li><p>Calcular <span class="math inline">\(\mathbf e^l\)</span> y <span class="math inline">\(\delta^l\)</span> en cada capa <span class="math inline">\(l\)</span> mediante las relaciones:</p>
<p><span class="math display">\[
\begin{cases}\mathbf e^l&amp;= (\mathbf w^{l+1})^T\delta^{l+1}\\ \delta^l &amp;= (f^{l(1)}(\mathbf z^l))\odot \mathbf e^l.\end{cases}
\]</span></p></li>
<li><p>Proceder a la actualización de pesos y sesgos. Para ello, se introduce la función de coste <span class="math inline">\(\mathcal C\)</span> aplicada a la pérdida <span class="math inline">\(\mathcal L\)</span> y se calculan las derivadas con respecto a los pesos y sesgos:</p>
<p><span class="math display">\[
\mathcal C=\frac{1}{n}\sum_{k=1}^n \mathcal L(\mathbf y, \mathbf{\hat{y}})(k)
\]</span></p>
<p>Estas derivadas son equivalentes a las obtenidas en la <a href="#eq-21" class="quarto-xref">Ecuación&nbsp;<span>6.6</span></a>, <a href="#eq-22" class="quarto-xref">Ecuación&nbsp;<span>6.7</span></a> y <a href="#eq-25" class="quarto-xref">Ecuación&nbsp;<span>6.10</span></a>. Luego, se aplica el algoritmo de descenso del gradiente para actualizar las matrices de pesos y sesgos:</p>
<p><span id="eq-26"><span class="math display">\[
\begin{split}\frac{\partial \mathcal C}{\partial \mathbf w^l}&amp;=\frac{1}{n}\sum_{k=1}^n \frac{\partial}{\partial \mathbf w^l}\mathcal L(\mathbf y, \hat{\mathbf y})(k)\\ &amp;=\nabla_{\mathbf w^l}\mathcal C\\
\frac{\partial\mathcal C}{\partial\mathbf b^l}&amp;= \frac{1}{n}\sum_{k=1}^n \frac{\partial}{\partial \mathbf b^l}\mathcal L(\mathbf y, \hat{\mathbf y})(k)=\nabla_{\mathbf b^l}\mathcal C,\end{split}
\tag{6.11}\]</span></span></p>
<p>Note que en la <a href="#eq-26" class="quarto-xref">Ecuación&nbsp;<span>6.11</span></a>, las derivadas con respecto a <span class="math inline">\(\mathbf w^L\)</span> y <span class="math inline">\(\mathbf b^L\)</span>, son las mismas que se dedujeron en la <a href="#eq-25" class="quarto-xref">Ecuación&nbsp;<span>6.10</span></a>, con estos últimos parámetros obtenidos, se puede aplicar el algoritmo del descenso del gradiente, para actualizar las matrices de pesos y sesgos, así:</p>
<p><span class="math display">\[
\begin{cases}\mathbf w^l(t)&amp;:= \mathbf w^{l-1}(t-1)-\eta\nabla_{\mathbf w^l}\mathcal C,\\ \mathbf b^l(t)&amp;:= \mathbf b^{l-1}(t-1)-\eta\nabla_{\mathbf b^l}\mathcal C,\end{cases}
\]</span></p>
<p>donde <span class="math inline">\(t\)</span> representa el iterador de épocas asignadas a la red.</p></li>
</ol>
<p>Al aplicar estos algoritmos (Feed-Forward y Backpropagation), se puede construir una red neuronal que, a partir de un conjunto de datos (ya sea de prueba o entrenamiento), se entrena para lograr una clasificación precisa de los datos. Es importante destacar que antes de aplicar el conjunto de prueba a la red, se debe realizar un proceso de preprocesamiento de datos, que incluye la eliminación de datos atípicos y la normalización del conjunto de entrenamiento, con el fin de evitar confusiones en la clasificación.</p>
</div>
</section>
</section>
</section>
<section id="evaluación-de-modelos-de-aprendizaje-automático" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="evaluación-de-modelos-de-aprendizaje-automático"><span class="header-section-number">6.8</span> Evaluación de modelos de aprendizaje automático</h2>
<div style="text-align: justify">
<p>Una vez entrenado un modelo de Machine Learning con datos etiquetados, se espera que funcione correctamente con nuevos datos. Sin embargo, es crucial asegurar la precisión de las predicciones del modelo en condiciones de producción.</p>
<p>Para lograr este objetivo, es imprescindible validar el modelo. Este procedimiento implica determinar si los resultados digitales que cuantifican las relaciones hipotéticas entre las variables son adecuados como descripciones de los datos.</p>
<p>Con el propósito de evaluar el rendimiento de un modelo de Machine Learning, es necesario ponerlo a prueba con datos nuevos. A partir del desempeño del modelo con datos desconocidos, se puede determinar si requiere ajustes adicionales, si ha sido sobreajustado o si está generalizado de manera adecuada.</p>
<p>Una de las técnicas más utilizadas para evaluar la eficacia de un modelo de Machine Learning es la validación cruzada. Este método, que también se considera un procedimiento de re-muestreo, permite evaluar un modelo incluso cuando se cuenta con datos limitados.</p>
<p>Para llevar a cabo la validación cruzada, es necesario reservar previamente una parte de los datos de entrenamiento. Estos datos no se emplearán durante el proceso de entrenamiento del modelo, sino que se utilizarán posteriormente para probarlo y validar sus resultados.</p>
<p>Frecuentemente en el ámbito del Machine Learning, la validación cruzada se emplea para comparar diferentes modelos y seleccionar aquel que sea más apropiado para un problema específico. Esta técnica, además de ser fácil de comprender e implementar, presenta menos sesgos que otros métodos. A continuación se exploran las principales técnicas de validación cruzada.</p>
</div>
<section id="división-de-datos-en-entrenamiento-y-prueba" class="level3" data-number="6.8.1">
<h3 data-number="6.8.1" class="anchored" data-anchor-id="división-de-datos-en-entrenamiento-y-prueba"><span class="header-section-number">6.8.1</span> División de datos en entrenamiento y prueba</h3>
<div style="text-align: justify">
<p>El enfoque denominado división datos en entrenamiento y prueba se basa en la aleatoria división de una serie de datos en dos conjuntos. Uno de estos conjuntos se destina al entrenamiento del modelo de Machine Learning, mientras que el otro se reserva para la validación del mismo.</p>
<p>Generalmente, se asigna entre un <span class="math inline">\(70\%\)</span> y un <span class="math inline">\(80\%\)</span> de los datos totales para el entrenamiento, dejando el <span class="math inline">\(20-30\%\)</span> restante para llevar a cabo la validación cruzada.</p>
<p>Aunque esta técnica suele ser efectiva, su utilidad puede verse comprometida en casos de disponibilidad limitada de datos. En tales situaciones, existe la posibilidad de que se pierda información relevante durante el entrenamiento, lo que podría resultar en sesgos significativos en los resultados obtenidos.</p>
<p>No obstante, en escenarios donde la cantidad de datos es suficientemente amplia y la distribución entre los conjuntos es equilibrada, este enfoque se muestra completamente apropiado.</p>
</div>
</section>
<section id="sec-validación-cruzada-de-k-pliegues" class="level3" data-number="6.8.2">
<h3 data-number="6.8.2" class="anchored" data-anchor-id="sec-validación-cruzada-de-k-pliegues"><span class="header-section-number">6.8.2</span> Validación cruzada de <span class="math inline">\(K\)</span> pliegues</h3>
<div style="text-align: justify">
<p>La técnica validación cruzada de <span class="math inline">\(K\)</span> pliegues se caracteriza por su accesibilidad y su reconocimiento generalizado en el ámbito de la validación cruzada. En comparación con otros métodos de validación cruzada, tiende a proporcionar modelos con un menor sesgo (<span class="citation" data-cites="d83becf2-a410-3aa1-b0e0-e01af0f94b99">Zhang (<a href="references.html#ref-d83becf2-a410-3aa1-b0e0-e01af0f94b99" role="doc-biblioref">1993</a>)</span>).</p>
<p>Esta técnica asegura que todas las observaciones originales de la serie de datos tengan la oportunidad de formar parte tanto del conjunto de entrenamiento como del conjunto de prueba. Es especialmente valiosa en situaciones donde los datos de entrada son limitados.</p>
<p>El proceso comienza al dividir de manera aleatoria la serie de datos en <span class="math inline">\(K\)</span> pliegues. El parámetro <span class="math inline">\(K\)</span> determina el número de grupos en los que se dividirá la muestra.</p>
<p>Es fundamental elegir un valor adecuado para <span class="math inline">\(K\)</span>, evitando que sea demasiado bajo o demasiado alto. Usualmente, se selecciona un valor entre <span class="math inline">\(5\)</span> y <span class="math inline">\(10\)</span> dependiendo del tamaño de la serie de datos. Por ejemplo, si <span class="math inline">\(K=10\)</span>, la serie de datos se divide en <span class="math inline">\(10\)</span> partes iguales.</p>
<p>Un valor de <span class="math inline">\(K\)</span> más alto reduce el sesgo del modelo, pero una varianza excesiva puede conducir al sobreajuste. Un valor más bajo equivale prácticamente al enfoque de división de datos en entrenamiento y prueba.</p>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-mcculloch1943logical" class="csl-entry" role="listitem">
McCulloch, Warren S, y Walter Pitts. 1943. <span>«A logical calculus of the ideas immanent in nervous activity»</span>. <em>The bulletin of mathematical biophysics</em> 5: 115-33.
</div>
<div id="ref-MontesinosLópez2022" class="csl-entry" role="listitem">
Montesinos López, Osval Antonio, Abelardo Montesinos López, y Jose Crossa. 2022. <span>«Fundamentals of Artificial Neural Networks and Deep Learning»</span>. En <em>Multivariate Statistical Machine Learning Methods for Genomic Prediction</em>, 379-425. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-89010-0_10">https://doi.org/10.1007/978-3-030-89010-0_10</a>.
</div>
<div id="ref-rosenblatt1960perceptron" class="csl-entry" role="listitem">
Rosenblatt, Frank. 1960. <span>«Perceptron simulation experiments»</span>. <em>Proceedings of the IRE</em> 48 (3): 301-9.
</div>
<div id="ref-sosaestructura" class="csl-entry" role="listitem">
Sosa Jerez, Lexly Vanessa, Laura Camila Zamora Alvarado, et&nbsp;al. s.&nbsp;f. <span>«Estructura de redes neuronales (MLP) y su aplicaci<span>ó</span>n como aproximador universal»</span>. {B.S.} thesis.
</div>
<div id="ref-stewart2017cálculo" class="csl-entry" role="listitem">
Stewart, J. 2017. <em>C<span>á</span>lculo de varias variables: trascendentes tempranas</em>. Cengage Learning. <a href="https://books.google.com.mx/books?id=bKSvtAEACAAJ">https://books.google.com.mx/books?id=bKSvtAEACAAJ</a>.
</div>
<div id="ref-d83becf2-a410-3aa1-b0e0-e01af0f94b99" class="csl-entry" role="listitem">
Zhang, Ping. 1993. <span>«Model Selection Via Multifold Cross Validation»</span>. <em>The Annals of Statistics</em> 21 (1): 299-313. <a href="http://www.jstor.org/stable/3035592">http://www.jstor.org/stable/3035592</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = true;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./series.html" class="pagination-link" aria-label="Series de Tiempo">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Series de Tiempo</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./estudio.html" class="pagination-link" aria-label="Estudio de caso">
        <span class="nav-page-text">Estudio de caso</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/Jennlg/Tesis/edit/main/book/redes.qmd" class="toc-action"><i class="bi bi-github"></i>Editar esta página</a></li><li><a href="https://github.com/Jennlg/Tesis/issues/new" class="toc-action"><i class="bi empty"></i>Informar de un problema</a></li><li><a href="https://github.com/Jennlg/Tesis/blob/main/book/redes.qmd" class="toc-action"><i class="bi empty"></i>Ver el código</a></li></ul></div></div></div></footer></body></html>